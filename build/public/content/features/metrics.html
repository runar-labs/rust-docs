<h1>Kagi Node Metrics System</h1>
<p>The Metrics module provides a robust framework for collecting, managing, and exporting metrics in distributed systems. It is designed to be scalable, efficient, and interoperable with modern observability tools, supporting both standard and custom metrics with aggregation across nodes.</p>
<h2>Table of Contents</h2>
<ol>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#metric-types">Metric Types</a></li>
<li><a href="#metric-registry">Metric Registry</a></li>
<li><a href="#standard-metrics">Standard Metrics</a></li>
<li><a href="#custom-metrics">Custom Metrics</a></li>
<li><a href="#event-based-metrics">Event-based Metrics</a></li>
<li><a href="#metric-collection">Metric Collection</a></li>
<li><a href="#metric-export">Metric Export</a></li>
<li><a href="#configuration">Configuration</a></li>
<li><a href="#declarative-metrics">Declarative Metrics</a></li>
<li><a href="#observability-integration">Observability Integration</a></li>
<li><a href="#performance-considerations">Performance Considerations</a></li>
<li><a href="#security">Security</a></li>
</ol>
<h2>Introduction</h2>
<p>The Metrics module provides a robust framework for collecting, managing, and exporting metrics in distributed systems. It is designed to be scalable, efficient, and interoperable with modern observability tools, supporting both standard and custom metrics with aggregation across nodes.</p>
<h2>Metric Types</h2>
<ul>
<li><p><strong>Counter</strong>: Monotonically increasing (e.g., total requests)</p>
<ul>
<li>Operations: increment, add</li>
</ul>
</li>
<li><p><strong>Gauge</strong>: Fluctuating value (e.g., memory usage)</p>
<ul>
<li>Operations: set, increment, decrement</li>
</ul>
</li>
<li><p><strong>Histogram</strong>: Distribution of values (e.g., latency)</p>
<ul>
<li>Operation: observe</li>
</ul>
</li>
<li><p><strong>Summary</strong>: Quantiles over a window (e.g., 95th percentile)</p>
<ul>
<li>Operation: observe</li>
</ul>
</li>
<li><p><strong>Rate</strong>: Rate of change (e.g., requests/sec)</p>
<ul>
<li>Derived from counters</li>
</ul>
</li>
<li><p><strong>Timer</strong>: Duration measurement (e.g., processing time)</p>
<ul>
<li>Operations: start, stop</li>
</ul>
</li>
</ul>
<h2>Metric Registry</h2>
<ul>
<li><p><strong>Distributed Registry</strong>: Manages metrics across nodes/services</p>
</li>
<li><p><strong>Unique Identification</strong>: Name, labels, and node/service IDs</p>
</li>
<li><p><strong>Methods</strong>:</p>
<ul>
<li>Register new metrics</li>
<li>Retrieve metrics for updates or readings</li>
</ul>
</li>
</ul>
<h2>Standard Metrics</h2>
<ul>
<li><p><strong>System Metrics</strong>:</p>
<ul>
<li>CPU usage (per core)</li>
<li>Memory usage (heap, non-heap)</li>
<li>Network I/O (bytes sent/received)</li>
<li>Disk usage (read/write operations)</li>
</ul>
</li>
<li><p><strong>P2P Metrics</strong>:</p>
<ul>
<li>Connection metrics</li>
<li>Network metrics</li>
<li>Gateway metrics</li>
</ul>
</li>
</ul>
<h3>P2P Metrics</h3>
<p><strong>Connection Metrics</strong>:</p>
<pre><code class="language-rust">/// P2P connection metrics
pub struct P2PMetrics {
    // Connection counts
    active_connections: Gauge,
    total_connections: Counter,
    failed_connections: Counter,
    
    // Network metrics
    active_networks: Gauge,
    peers_per_network: Histogram,
    
    // Message metrics
    messages_sent: Counter,
    messages_received: Counter,
    message_size: Histogram,
    
    // DHT metrics
    dht_operations: Counter,
    dht_latency: Histogram,
    dht_storage_size: Gauge,
    
    // Token metrics
    token_validations: Counter,
    token_validation_failures: Counter,
}

impl P2PMetrics {
    pub fn record_connection(&amp;self, success: bool) {
        self.total_connections.inc();
        if success {
            self.active_connections.inc();
        } else {
            self.failed_connections.inc();
        }
    }
    
    pub fn record_message(&amp;self, size: usize, is_outbound: bool) {
        self.message_size.observe(size as f64);
        if is_outbound {
            self.messages_sent.inc();
        } else {
            self.messages_received.inc();
        }
    }
    
    pub fn record_dht_operation(&amp;self, op_type: &amp;str, duration: Duration) {
        self.dht_operations.inc_by(1, &amp;[(&quot;type&quot;, op_type)]);
        self.dht_latency.observe(duration.as_secs_f64());
    }
}
</code></pre>
<p><strong>Network Metrics</strong>:</p>
<pre><code class="language-rust">/// Network-specific metrics
pub struct NetworkMetrics {
    // Peer metrics
    active_peers: Gauge,
    peer_message_rates: Histogram,
    peer_latencies: Histogram,
    
    // Bandwidth metrics
    bytes_sent: Counter,
    bytes_received: Counter,
    bandwidth_usage: Histogram,
    
    // Discovery metrics
    discovery_attempts: Counter,
    discovery_successes: Counter,
    discovery_time: Histogram,
}

impl NetworkMetrics {
    pub fn record_peer_message(&amp;self, peer_id: &amp;PeerId, size: usize, duration: Duration) {
        self.peer_message_rates.observe(1.0);
        self.peer_latencies.observe(duration.as_secs_f64());
        self.bytes_sent.inc_by(size as u64);
    }
    
    pub fn record_discovery(&amp;self, success: bool, duration: Duration) {
        self.discovery_attempts.inc();
        if success {
            self.discovery_successes.inc();
            self.discovery_time.observe(duration.as_secs_f64());
        }
    }
}
</code></pre>
<h3>Gateway Metrics</h3>
<ul>
<li><strong>Distributed Metrics</strong>:<ul>
<li>Total active connections</li>
<li>Aggregated request and error rates</li>
</ul>
</li>
</ul>
<h2>Custom Metrics</h2>
<ul>
<li><strong>Label Support</strong>: Enhanced with cardinality limits</li>
<li><strong>Metadata</strong>: Descriptions and units</li>
</ul>
<h2>Event-based Metrics</h2>
<ul>
<li><strong>Distributed Event Tracking</strong>: Aggregate events across services</li>
<li><strong>Event Latency</strong>: Time from emission to processing</li>
</ul>
<h2>Metric Collection</h2>
<ul>
<li><p><strong>Efficient Collection</strong>:</p>
<ul>
<li>Lock-free structures</li>
<li>Batch updates</li>
</ul>
</li>
<li><p><strong>Sampling</strong>:</p>
<ul>
<li>Configurable rates</li>
<li>Adaptive sampling</li>
</ul>
</li>
<li><p><strong>Aggregation</strong>:</p>
<ul>
<li>Sum, average, percentiles across nodes</li>
</ul>
</li>
</ul>
<h2>Metric Export</h2>
<ul>
<li><p><strong>Formats</strong>:</p>
<ul>
<li>OpenMetrics</li>
<li>JSON, Protobuf</li>
</ul>
</li>
<li><p><strong>Protocols</strong>:</p>
<ul>
<li>HTTP/HTTPS (pull)</li>
<li>gRPC (push)</li>
<li>UDP (StatsD)</li>
</ul>
</li>
<li><p><strong>Distributed Export</strong>:</p>
<ul>
<li>Independent node export</li>
<li>Central aggregator option</li>
</ul>
</li>
</ul>
<h2>Configuration</h2>
<ul>
<li><p><strong>Global</strong>:</p>
<ul>
<li>Enable/disable metrics</li>
<li>Default sampling rates</li>
</ul>
</li>
<li><p><strong>Per-Metric</strong>:</p>
<ul>
<li>Enable/disable specific metrics</li>
<li>Labels and aggregation rules</li>
</ul>
</li>
<li><p><strong>Export</strong>:</p>
<ul>
<li>Exporter type</li>
<li>Intervals, batch sizes, security settings</li>
</ul>
</li>
</ul>
<h2>Declarative Metrics</h2>
<p>The metrics system supports a declarative approach using macros to reduce boilerplate code. This makes it easy to add metrics to services, actions, and events without manually creating and managing metric instances.</p>
<blockquote>
<p><strong>Implementation Note</strong>: Kagi macros work with both compile-time (using distributed slices) and runtime registration approaches. This means metrics can be easily applied in both production and testing environments without requiring unstable Rust features.</p>
</blockquote>
<h3>Service-Level Metrics</h3>
<p>Apply metrics to an entire service using the <code>#[metrics]</code> macro:</p>
<pre><code class="language-rust">use kagi_node::prelude::*;

// Define service with automatic metrics collection
#[kagi::service]
#[metrics]
struct UserService {
    #[inject]
    db_connection: DatabaseConnection,
}
</code></pre>
<p>This macro automatically creates and registers the following metrics for the service:</p>
<ul>
<li>Request counter (<code>service_requests_total</code>)</li>
<li>Active requests gauge (<code>service_active_requests</code>)</li>
<li>Error counter (<code>service_errors_total</code>)</li>
<li>Response time histogram (<code>service_response_time_seconds</code>)</li>
</ul>
<p>All metrics are labeled with the service name for easy filtering and aggregation.</p>
<h3>Action-Level Metrics</h3>
<p>Apply metrics to specific actions using the <code>#[metered]</code> attribute or combined with the <code>#[action]</code> macro:</p>
<pre><code class="language-rust">impl UserService {
    // Add metrics to this action using the dedicated metered macro
    #[action]
    #[metered]
    async fn get_user(&amp;self, context: &amp;RequestContext, id: u64) -&gt; Result&lt;User&gt; {
        // Implementation...
        let user = self.db_connection.query_one(&quot;SELECT * FROM users WHERE id = ?&quot;, &amp;[id]).await?;
        Ok(user)
    }
    
    // Alternative syntax with action attributes
    #[action(metrics = true)]
    async fn update_user(&amp;self, context: &amp;RequestContext, id: u64, data: UserData) -&gt; Result&lt;User&gt; {
        // Implementation...
        Ok(user)
    }
    
    // With custom metric configuration
    #[action]
    #[metered(
        histogram_buckets = [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0],
        labels = [&quot;priority&quot;, &quot;user_type&quot;]
    )]
    async fn process_complex_operation(&amp;self, context: &amp;RequestContext, data: ComplexData) -&gt; Result&lt;OperationResult&gt; {
        // Implementation...
        Ok(result)
    }
}
</code></pre>
<p>The <code>#[metered]</code> macro automatically wraps the action with metric collection:</p>
<ol>
<li>Increments a request counter specific to the action</li>
<li>Records the duration of the action</li>
<li>Tracks successes and failures</li>
<li>Adds context-aware labels if specified</li>
</ol>
<h3>Event-Based Metrics</h3>
<p>Automatically track metrics for events:</p>
<pre><code class="language-rust">#[event_handler]
#[metered(event = &quot;user.updated&quot;)]
async fn handle_user_updated(&amp;self, context: &amp;EventContext, event: UserUpdatedEvent) -&gt; Result&lt;()&gt; {
    // Event handling...
    Ok(())
}
</code></pre>
<p>This creates:</p>
<ol>
<li>Event counter (<code>event_received_total{event=&quot;user.updated&quot;}</code>)</li>
<li>Event processing time histogram (<code>event_processing_time_seconds{event=&quot;user.updated&quot;}</code>)</li>
<li>Event failure counter (<code>event_failures_total{event=&quot;user.updated&quot;}</code>)</li>
</ol>
<h3>Custom Metric Definitions</h3>
<p>Define custom metrics with the <code>#[metric]</code> macro:</p>
<pre><code class="language-rust">#[metric(
    type = &quot;counter&quot;,
    name = &quot;user_registration_total&quot;,
    description = &quot;Total number of user registrations&quot;,
    labels = [&quot;source&quot;, &quot;account_type&quot;]
)]
struct UserRegistrationMetric;

impl UserService {
    #[action]
    async fn register_user(&amp;self, context: &amp;RequestContext, user_data: UserRegistrationData) -&gt; Result&lt;User&gt; {
        // Implementation...
        
        // Increment the custom metric with labels
        metrics::increment!(&quot;user_registration_total&quot;, labels: {
            &quot;source&quot; =&gt; user_data.source,
            &quot;account_type&quot; =&gt; user_data.account_type
        });
        
        Ok(user)
    }
}
</code></pre>
<h3>Macro-Based Helper Functions</h3>
<p>The macros also provide convenient helper functions for common metric operations:</p>
<pre><code class="language-rust">// Increment a counter
metrics::increment!(&quot;custom_counter&quot;);

// Increment with a specific value
metrics::increment!(&quot;custom_counter&quot;, value: 5);

// Increment with labels
metrics::increment!(&quot;custom_counter&quot;, labels: {&quot;label1&quot; =&gt; &quot;value1&quot;});

// Observe a value on a histogram
metrics::observe!(&quot;response_time&quot;, value: duration);

// Set a gauge
metrics::set!(&quot;active_connections&quot;, value: count);

// Start a timer and automatically record when dropped
let _timer = metrics::timer!(&quot;operation_duration&quot;);
</code></pre>
<h3>Automatic Metrics Collection</h3>
<p>All metrics are automatically registered with the metric registry and included in exports. This removes the need to manually create, register, and update metric instances.</p>
<h3>Comprehensive Service Example</h3>
<p>Here&#39;s a complete example demonstrating how to use metric macros in a real-world service:</p>
<pre><code class="language-rust">use kagi_node::prelude::*;

// Define a service with automatic metrics
#[kagi::service]
#[metrics(prefix = &quot;api_gateway_&quot;)]  // Optional prefix for all metrics
struct ApiGatewayService {
    #[inject]
    db: Database,
    
    #[inject]
    cache_manager: CacheManager,
    
    // Custom metrics can still be defined manually when needed
    #[metric_field]
    cache_hit_ratio: Gauge,
    
    #[metric_field]
    request_size: Histogram,
}

impl ApiGatewayService {
    // Constructor to set up any custom metrics not handled by macros
    fn new() -&gt; Self {
        // The #[metrics] macro will automatically set up common metrics,
        // but we can still manually define specialized ones
        let cache_hit_ratio = Gauge::new(
            &quot;api_gateway_cache_hit_ratio&quot;,
            &quot;Ratio of cache hits to total requests&quot;
        ).register();
        
        let request_size = Histogram::new(
            &quot;api_gateway_request_size_bytes&quot;,
            &quot;Size of API requests in bytes&quot;
        )
        .with_buckets(vec![64.0, 256.0, 1024.0, 4096.0, 16384.0, 65536.0])
        .register();
        
        Self {
            db: Database::default(),
            cache_manager: CacheManager::default(),
            cache_hit_ratio,
            request_size,
        }
    }

    // Standard action with default metrics
    #[action]
    #[metered]
    async fn get_user(&amp;self, context: &amp;RequestContext, id: String) -&gt; Result&lt;User&gt; {
        // Implementation...
        let user = self.db.find_user(&amp;id).await?;
        Ok(user)
    }
    
    // Action with both caching and metrics
    #[action(cache(enabled = true, ttl = 60))]
    #[metered(
        buckets = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5],  // Custom time buckets
        labels = [&quot;user_tier&quot;]                           // Custom labels
    )]
    async fn get_user_profile(&amp;self, context: &amp;RequestContext, id: String) -&gt; Result&lt;UserProfile&gt; {
        // Implementation...
        // The caching layer handles cache hits automatically
        // The metrics layer tracks execution time and counts
        
        // Add the user_tier label value from context
        metrics::add_label!(&quot;user_tier&quot;, context.user_tier().unwrap_or(&quot;free&quot;));
        
        let profile = self.db.find_user_profile(&amp;id).await?;
        Ok(profile)
    }
    
    // Action with custom metric tracking
    #[action]
    async fn process_order(&amp;self, context: &amp;RequestContext, order: Order) -&gt; Result&lt;OrderConfirmation&gt; {
        // Start a timer for this specific operation
        let timer = metrics::timer!(&quot;order_processing_time&quot;, labels: {
            &quot;order_type&quot; =&gt; order.type_name(),
            &quot;priority&quot; =&gt; order.priority().to_string()
        });
        
        // Record the order amount
        metrics::observe!(&quot;order_amount&quot;, value: order.total_amount(), labels: {
            &quot;currency&quot; =&gt; order.currency()
        });
        
        // Process the order
        let result = process_order_internal(&amp;order).await;
        
        // Track success/failure
        if result.is_ok() {
            metrics::increment!(&quot;orders_processed&quot;);
        } else {
            metrics::increment!(&quot;orders_failed&quot;);
        }
        
        // Timer automatically stops when dropped
        drop(timer);
        
        result
    }
    
    // Event handler with metrics
    #[event_handler(&quot;payment.completed&quot;)]
    #[metered(event = &quot;payment.completed&quot;)]
    async fn handle_payment_completed(&amp;self, context: &amp;EventContext, event: PaymentCompletedEvent) -&gt; Result&lt;()&gt; {
        // Implementation...
        
        // Track payment amount
        metrics::observe!(&quot;payment_amount&quot;, value: event.amount, labels: {
            &quot;payment_method&quot; =&gt; event.payment_method,
            &quot;currency&quot; =&gt; event.currency
        });
        
        // Event processing...
        Ok(())
    }
    
    // Background job with metrics
    #[job(schedule = &quot;*/5 * * * *&quot;)]  // Run every 5 minutes
    #[metered(name = &quot;cleanup_job&quot;)]  // Custom metric name
    async fn cleanup_expired_sessions(&amp;self, context: &amp;JobContext) -&gt; Result&lt;CleanupReport&gt; {
        let start_time = Instant::now();
        
        // Implementation...
        let expired_count = cleanup_sessions().await?;
        
        // Record custom metrics about the cleanup
        metrics::set!(&quot;expired_sessions_count&quot;, value: expired_count as f64);
        
        // Duration is automatically recorded by the metered macro
        Ok(CleanupReport { removed_count: expired_count })
    }
}

// Event publisher with automatic metrics
#[publisher]
#[metrics(events = true)]  // Track metrics for all published events
struct EventPublisher {
    #[inject]
    event_bus: EventBus,
}

impl EventPublisher {
    #[action]
    async fn publish_user_event(&amp;self, context: &amp;RequestContext, event: UserEvent) -&gt; Result&lt;()&gt; {
        // The metrics macro automatically tracks:
        // - Number of events published
        // - Publication latency
        // - Success/failure rates
        self.event_bus.publish(&quot;user&quot;, event).await
    }
}
</code></pre>
<p>This example demonstrates how to:</p>
<ol>
<li>Apply metrics to an entire service</li>
<li>Add automatic metrics to individual actions</li>
<li>Combine metrics with other features like caching</li>
<li>Use custom metric configuration</li>
<li>Add metrics to event handlers and background jobs</li>
<li>Use the helper functions for manual metric tracking when needed</li>
</ol>
<h3>P2P and DHT Metric Integration</h3>
<p>The metrics system seamlessly integrates with P2P networking and DHT operations through macros, enabling automatic collection of performance and operational data without manual tracking code.</p>
<h4>Automatic P2P Metrics</h4>
<p>Apply metrics to P2P transport operations:</p>
<pre><code class="language-rust">use kagi_node::p2p::prelude::*;

// P2P service with automatic metrics
#[p2p_service]
#[metrics(prefix = &quot;p2p_&quot;)]
struct P2PService {
    #[inject]
    transport: P2PTransport,
    
    #[inject]
    dht: DHTService,
}

impl P2PService {
    // DHT operation with automatic metrics
    #[dht_operation]
    #[metered(
        prefix = &quot;dht_&quot;,
        buckets = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5]
    )]
    async fn store_value(&amp;self, context: &amp;RequestContext, key: String, value: Vec&lt;u8&gt;) -&gt; Result&lt;()&gt; {
        // Network ID is automatically retrieved from context
        let network_id = context.network_id();
        
        // Store the value in DHT
        self.dht.put(network_id, key, value).await
    }
    
    // Peer discovery with metrics
    #[action]
    #[metered(name = &quot;peer_discovery&quot;)]
    async fn discover_peers(&amp;self, context: &amp;RequestContext, network_id: String) -&gt; Result&lt;Vec&lt;PeerInfo&gt;&gt; {
        let start = Instant::now();
        
        // Discover peers
        let peers = self.transport.discover_peers(network_id).await?;
        
        // Record peer count
        metrics::set!(&quot;discovered_peers_count&quot;, value: peers.len() as f64, labels: {
            &quot;network&quot; =&gt; network_id
        });
        
        Ok(peers)
    }
    
    // Message broadcasting with metrics
    #[action]
    #[metered(name = &quot;broadcast&quot;)]
    async fn broadcast_message(&amp;self, context: &amp;RequestContext, network_id: String, message: Message) -&gt; Result&lt;BroadcastStats&gt; {
        // Implementation...
        
        // Record message size
        metrics::observe!(&quot;message_size_bytes&quot;, value: message.size() as f64);
        
        // Broadcast is automatically metered
        let stats = self.transport.broadcast(network_id, message).await?;
        
        // Record delivery stats
        metrics::set!(&quot;message_delivery_ratio&quot;, value: stats.successful_deliveries as f64 / stats.total_targets as f64);
        
        Ok(stats)
    }
}
</code></pre>
<h4>DHT Service with Metrics</h4>
<p>Define a DHT service with comprehensive metrics:</p>
<pre><code class="language-rust">use kagi_node::dht::prelude::*;

#[dht_service]
#[metrics]
struct DHTService {
    #[inject]
    storage: DHTStorage,
    
    #[metric_field]
    storage_size: Gauge,
    
    #[metric_field]
    replication_factor: Gauge,
}

impl DHTService {
    // Get operation with metrics
    #[action]
    #[metered(name = &quot;dht_get&quot;)]
    async fn get_value(&amp;self, context: &amp;RequestContext, key: String) -&gt; Result&lt;Option&lt;Vec&lt;u8&gt;&gt;&gt; {
        // Network ID from context
        let network_id = context.network_id();
        
        // Record DHT operation
        let _operation = metrics::timer!(&quot;dht_operation&quot;, labels: {
            &quot;operation&quot; =&gt; &quot;get&quot;,
            &quot;network&quot; =&gt; network_id
        });
        
        // Implementation...
        let result = self.storage.get(network_id, key.clone()).await?;
        
        // Record hit/miss
        if result.is_some() {
            metrics::increment!(&quot;dht_hits&quot;, labels: {&quot;network&quot; =&gt; network_id});
        } else {
            metrics::increment!(&quot;dht_misses&quot;, labels: {&quot;network&quot; =&gt; network_id});
        }
        
        Ok(result)
    }
    
    // Put operation with metrics
    #[action]
    #[metered(name = &quot;dht_put&quot;)]
    async fn put_value(&amp;self, context: &amp;RequestContext, key: String, value: Vec&lt;u8&gt;, ttl: Option&lt;Duration&gt;) -&gt; Result&lt;()&gt; {
        let network_id = context.network_id();
        
        // Record value size
        metrics::observe!(&quot;dht_value_size_bytes&quot;, value: value.len() as f64, labels: {
            &quot;network&quot; =&gt; network_id
        });
        
        // Implementation...
        self.storage.put(network_id, key, value, ttl).await?;
        
        // Update storage size metric
        self.update_storage_metrics(network_id).await;
        
        Ok(())
    }
    
    // Internal method to update storage metrics
    async fn update_storage_metrics(&amp;self, network_id: &amp;str) {
        if let Ok(stats) = self.storage.get_statistics(network_id).await {
            self.storage_size.set(stats.size_bytes as f64, &amp;[(&quot;network&quot;, network_id)]);
            self.replication_factor.set(stats.replication_factor as f64, &amp;[(&quot;network&quot;, network_id)]);
        }
    }
}
</code></pre>
<h4>Network Metrics Dashboard</h4>
<p>The declarative metrics approach makes it easy to create comprehensive dashboards for P2P and DHT operations, including:</p>
<ul>
<li>Network health (connections, latency, message delivery)</li>
<li>DHT performance (gets, puts, hit ratio)</li>
<li>Storage utilization (size, distribution)</li>
<li>Peer statistics (count, churn rate)</li>
</ul>
<p>The collected metrics can be exported to monitoring systems like Prometheus and visualized in Grafana or other dashboarding tools without requiring custom integration code.</p>
<h2>Observability Integration</h2>
<ul>
<li><strong>OpenTelemetry</strong>: Export compatibility</li>
<li><strong>Tracing</strong>: Link with distributed traces</li>
</ul>
<h2>Performance Considerations</h2>
<ul>
<li><p><strong>Low Overhead</strong>:</p>
<ul>
<li>Efficient data structures</li>
<li>Minimal synchronization</li>
</ul>
</li>
<li><p><strong>Cardinality Management</strong>:</p>
<ul>
<li>Limit label combinations</li>
<li>Monitor high-cardinality metrics</li>
</ul>
</li>
</ul>
<h2>Security</h2>
<ul>
<li><p><strong>Secure Export</strong>:</p>
<ul>
<li>TLS/SSL</li>
<li>Authentication (API keys, tokens)</li>
</ul>
</li>
<li><p><strong>Data Privacy</strong>:</p>
<ul>
<li>Exclude sensitive data</li>
</ul>
</li>
</ul>
<h2>Implementation Example</h2>
<pre><code class="language-rust">use kagi_node::metrics::prelude::*;

// Create a simple counter
let requests_counter = Counter::new(&quot;http_requests_total&quot;, &quot;Total HTTP requests&quot;)
    .with_label(&quot;service&quot;, &quot;api_gateway&quot;)
    .register();

// Increment the counter
requests_counter.increment();

// Create a histogram for response time
let response_time = Histogram::new(
    &quot;http_response_time_seconds&quot;, 
    &quot;HTTP response time in seconds&quot;
)
    .with_buckets(vec![0.01, 0.05, 0.1, 0.5, 1.0, 5.0])
    .register();

// Observe a value
response_time.observe(0.42);

// Create a gauge for concurrent connections
let connections = Gauge::new(
    &quot;active_connections&quot;,
    &quot;Number of active connections&quot;
)
    .register();

// Set the gauge value
connections.set(42.0);

// Create a timer for measuring operation duration
let operation_timer = Timer::new(
    &quot;operation_duration_seconds&quot;,
    &quot;Time to complete operation&quot;
)
    .register();

// Use the timer
let timer_handle = operation_timer.start();
// ... perform operation ...
timer_handle.stop(); // Automatically records the duration

// Export metrics
MetricsExporter::new()
    .format(ExportFormat::OpenMetrics)
    .protocol(ExportProtocol::Http)
    .interval(Duration::from_secs(15))
    .start();
</code></pre>
<h2>Service Integration Example</h2>
<pre><code class="language-rust">use kagi_node::prelude::*;
use kagi_node::metrics::prelude::*;

struct MyService {
    name: String,
    path: String,
    // Service fields...
    request_counter: Counter,
    active_requests: Gauge,
    response_time: Histogram,
}

impl MyService {
    fn new(name: &amp;str) -&gt; Self {
        // Create metrics
        let request_counter = Counter::new(&quot;service_requests_total&quot;, &quot;Total service requests&quot;)
            .with_label(&quot;service&quot;, name)
            .register();
            
        let active_requests = Gauge::new(&quot;service_active_requests&quot;, &quot;Active service requests&quot;)
            .with_label(&quot;service&quot;, name)
            .register();
            
        let response_time = Histogram::new(&quot;service_response_time_seconds&quot;, &quot;Service response time&quot;)
            .with_label(&quot;service&quot;, name)
            .with_buckets(vec![0.01, 0.05, 0.1, 0.5, 1.0])
            .register();
            
        Self {
            name: name.to_string(),
            path: name.to_string(),
            // Initialize other fields...
            request_counter,
            active_requests,
            response_time,
        }
    }
    
    async fn handle_request(&amp;self, request: &amp;ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {
        // Increment request counter
        self.request_counter.increment();
        
        // Increment active requests
        self.active_requests.increment();
        
        // Create timer for response time
        let timer = self.response_time.start_timer();
        
        // Process the request
        let result = self.process_request_internal(request).await;
        
        // Stop timer
        timer.stop();
        
        // Decrement active requests
        self.active_requests.decrement();
        
        result
    }
    
    async fn process_request_internal(&amp;self, request: &amp;ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {
        // Actual request processing logic...
        // ...
        
        Ok(ServiceResponse {
            status: ResponseStatus::Success,
            message: &quot;Request processed&quot;.to_string(),
            data: None,
        })
    }
}

#[async_trait]
impl AbstractService for MyService {
    // AbstractService implementation...
    
    async fn process_request(&amp;self, request: ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {
        self.handle_request(&amp;request).await
    }
}
</code></pre>
<h2>Integration</h2>
<h3>P2P Integration</h3>
<p>The metrics system integrates with the P2P transport layer to collect:</p>
<ul>
<li>Connection statistics</li>
<li>Message flow metrics</li>
<li>DHT operation metrics</li>
<li>Network-specific metrics</li>
</ul>
<p><strong>Example Integration</strong>:</p>
<pre><code class="language-rust">impl P2PTransport {
    async fn handle_message(&amp;self, message: Message) -&gt; Result&lt;(), Error&gt; {
        let start = Instant::now();
        let result = self.process_message(message).await;
        let duration = start.elapsed();
        
        // Record metrics
        self.metrics.record_p2p_message(
            &amp;message.network_id,
            &amp;message.peer_id,
            message.size(),
            duration
        );
        
        result
    }
}
</code></pre>
<h2>Examples</h2>
<p>This section will be expanded with practical examples.</p>
