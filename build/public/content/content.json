{
  "documentation_updates": {
    "html": "<h1>Documentation Updates for Macros System</h1>\n<p>This document summarizes the documentation updates made to reflect the improvements to Kagi&#39;s macros system, particularly the successful implementation of the runtime registration approach.</p>\n<h2>Updates Made</h2>\n<h3>Main Documentation Files</h3>\n<ol>\n<li><p><strong><code>/docs/development/macros.md</code></strong></p>\n<ul>\n<li>Added information about the two implementation approaches (distributed slices and runtime registration)</li>\n<li>Added a new &quot;Testing with Macros&quot; section with practical examples</li>\n<li>Included detailed explanations about how macros work in testing environments</li>\n</ul>\n</li>\n<li><p><strong><code>/docs/index.md</code></strong></p>\n<ul>\n<li>Updated the link to macros documentation to indicate testing support</li>\n</ul>\n</li>\n<li><p><strong><code>/docs/features/caching.md</code></strong></p>\n<ul>\n<li>Added a note about macros supporting both compile-time and runtime registration approaches</li>\n<li>Explained compatibility with testing environments</li>\n</ul>\n</li>\n<li><p><strong><code>/docs/features/metrics.md</code></strong></p>\n<ul>\n<li>Added an implementation note about the dual registration approaches</li>\n<li>Mentioned compatibility with testing environments</li>\n</ul>\n</li>\n</ol>\n<h3>Support Documentation</h3>\n<ol>\n<li><p><strong><code>/kagi_macros/README.md</code></strong></p>\n<ul>\n<li>Substantially updated with information about the implementation approaches</li>\n<li>Added a &quot;Testing with Macros&quot; section with code examples</li>\n<li>Updated the development status to reflect successful testing</li>\n<li>Added links to the proper documentation</li>\n</ul>\n</li>\n<li><p><strong><code>/kagi_macros/CHANGELOG.md</code></strong></p>\n<ul>\n<li>Added entries for the runtime registration system implementation</li>\n<li>Added entries for fixed methods in the service registry</li>\n<li>Added entries for other fixes and improvements</li>\n</ul>\n</li>\n<li><p><strong><code>/kagi_macros/DEBUGGING.md</code></strong></p>\n<ul>\n<li>Added section on debugging registration approaches</li>\n<li>Added tips for debugging in test environments</li>\n<li>Added more comprehensive troubleshooting steps</li>\n</ul>\n</li>\n<li><p><strong><code>/kagi_macros/IMPLEMENTATION_PLAN.md</code></strong></p>\n<ul>\n<li>Updated to mark completed items</li>\n<li>Added key achievements section</li>\n<li>Updated status of implementation phases</li>\n</ul>\n</li>\n</ol>\n<h2>Key Improvements Highlighted</h2>\n<ol>\n<li><p><strong>Runtime Registration Alternative</strong></p>\n<ul>\n<li>The macros now work without requiring unstable Rust features</li>\n<li>Testing is fully supported without special configuration</li>\n</ul>\n</li>\n<li><p><strong>Comprehensive Testing Support</strong></p>\n<ul>\n<li>End-to-end tests now pass with macros</li>\n<li>Test examples are included in documentation</li>\n</ul>\n</li>\n<li><p><strong>Improved Error Handling</strong></p>\n<ul>\n<li>Better error messages and diagnostic information</li>\n<li>More robust handling of edge cases</li>\n</ul>\n</li>\n<li><p><strong>P2P Communication</strong></p>\n<ul>\n<li>Fixed issues with message handling between peers</li>\n<li>Improved subscription handling</li>\n</ul>\n</li>\n</ol>\n<h2>Next Steps for Documentation</h2>\n<ol>\n<li>Add more examples to the documentation</li>\n<li>Create inline documentation for macro implementations</li>\n<li>Develop more comprehensive tutorials for common use cases</li>\n<li>Add diagrams explaining how the macros system works internally</li>\n</ol>\n<h1>Documentation Updates for Core Systems</h1>\n<p>This document summarizes the documentation updates made to reflect the core systems in Kagi, including the Context System, ValueMap (VMap), and Logging System.</p>\n<h2>Updates Made</h2>\n<h3>New Core Documentation Files</h3>\n<ol>\n<li><p><strong><code>/docs/core/context.md</code></strong></p>\n<ul>\n<li>Comprehensive documentation of the Context System</li>\n<li>Explanation of RequestContext and LifecycleContext</li>\n<li>Usage examples for creating and using contexts</li>\n<li>Mermaid diagram illustrating request context flow</li>\n</ul>\n</li>\n<li><p><strong><code>/docs/core/vmap.md</code></strong></p>\n<ul>\n<li>Detailed explanation of the ValueMap (VMap) abstraction</li>\n<li>Before and after comparisons showing code simplification</li>\n<li>Advanced usage examples for complex types and nested parameters</li>\n<li>Mermaid diagram showing VMap data flow</li>\n</ul>\n</li>\n<li><p><strong><code>/docs/core/logging.md</code></strong></p>\n<ul>\n<li>Documentation of the unified logging system</li>\n<li>Examples for both async and sync contexts</li>\n<li>Explanation of context-aware logging</li>\n<li>Mermaid diagram illustrating the logging flow</li>\n</ul>\n</li>\n<li><p><strong><code>/docs/core/request_handling.md</code></strong></p>\n<ul>\n<li>Comprehensive documentation of best practices for service request handling</li>\n<li>Guidelines for implementing the <code>handle_request</code> method</li>\n<li>Best practices for minimizing conversions between JSON and VMap</li>\n<li>Examples of good and bad practices for data format handling</li>\n<li>Integration with context-aware logging</li>\n<li>New section on subscription handling anti-patterns and best practices</li>\n<li>Detailed explanation of why subscriptions should be set up during initialization only</li>\n</ul>\n</li>\n<li><p><strong><code>/docs/core/lifecycle.md</code></strong></p>\n<ul>\n<li>Detailed description of the service lifecycle states and transitions</li>\n<li>Best practices for each lifecycle method (constructor, init, start, stop)</li>\n<li>Comprehensive guidance on subscription setup during initialization</li>\n<li>Common anti-patterns to avoid in service implementation</li>\n<li>Mermaid diagram illustrating the service state transitions</li>\n<li>Examples of proper event handler implementation</li>\n</ul>\n</li>\n<li><p><strong><code>/docs/core/README.md</code></strong></p>\n<ul>\n<li>Overview of the core documentation</li>\n<li>Links to individual core system documents</li>\n<li>Explanation of how the core systems relate to each other</li>\n</ul>\n</li>\n</ol>\n<h3>Updated Documentation Files</h3>\n<ol>\n<li><strong><code>/docs/index.md</code></strong><ul>\n<li>Added links to new core documentation files</li>\n<li>Updated the logging reference to point to the new core documentation</li>\n</ul>\n</li>\n</ol>\n<h3>Supporting Assets</h3>\n<ol>\n<li><strong><code>/docs/assets/images/</code></strong><ul>\n<li>Created Mermaid diagram source files for:<ul>\n<li><code>request-context-flow.txt</code></li>\n<li><code>vmap-flow.txt</code></li>\n<li><code>logging-flow.txt</code></li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h2>Key Improvements Highlighted</h2>\n<ol>\n<li><p><strong>Comprehensive Core Documentation</strong></p>\n<ul>\n<li>Detailed explanations of fundamental Kagi abstractions</li>\n<li>Clear examples showing proper usage patterns</li>\n<li>Visual diagrams to aid understanding</li>\n</ul>\n</li>\n<li><p><strong>Improved Navigation</strong></p>\n<ul>\n<li>Better organization of documentation</li>\n<li>Clear links between related documents</li>\n<li>README file to guide readers</li>\n</ul>\n</li>\n<li><p><strong>Consistent Format</strong></p>\n<ul>\n<li>Uniform structure across all core documentation</li>\n<li>Consistent use of examples, diagrams, and best practices</li>\n<li>Standardized sections for easy reference</li>\n</ul>\n</li>\n<li><p><strong>Documentation Integration</strong></p>\n<ul>\n<li>Enhanced cross-referencing between related documents</li>\n<li>New &quot;Core Concepts Relationships&quot; section in README</li>\n<li>Clear explanation of how components interact with each other</li>\n<li>ASCII diagram showing relationships between core components</li>\n</ul>\n</li>\n</ol>\n<h2>Next Steps for Core Documentation</h2>\n<ol>\n<li>Add more detailed implementation examples</li>\n<li>Create tutorials showing how the core systems work together</li>\n<li>Add API reference documentation for each core system</li>\n<li>Develop troubleshooting guides for common issues</li>\n</ol>\n<h1>Documentation Updates for Request Handling</h1>\n<p>This document summarizes the documentation updates made to reflect the best practices for request handling in Kagi, including the transition from <code>process_request</code> to <code>handle_request</code> and guidelines for JSON/VMap usage.</p>\n<h2>Updates Made</h2>\n<h3>New Core Documentation Files</h3>\n<ol>\n<li><strong><code>/docs/core/request_handling.md</code></strong><ul>\n<li>Comprehensive documentation of best practices for service request handling</li>\n<li>Guidelines for implementing the <code>handle_request</code> method</li>\n<li>Best practices for minimizing conversions between JSON and VMap</li>\n<li>Examples of good and bad practices for data format handling</li>\n<li>Integration with context-aware logging</li>\n<li><strong>New section on subscription handling anti-patterns and best practices</strong></li>\n<li>Detailed explanation of why subscriptions should be set up during initialization only</li>\n</ul>\n</li>\n</ol>\n<h3>Updated Documentation Files</h3>\n<ol>\n<li><p><strong><code>/docs/index.md</code></strong></p>\n<ul>\n<li>Added link to the new request handling best practices document</li>\n<li>Updated Core Concepts section to include request handling</li>\n</ul>\n</li>\n<li><p><strong><code>/docs/core/README.md</code></strong></p>\n<ul>\n<li>Added information about the request handling documentation</li>\n<li>Updated Core Components section</li>\n</ul>\n</li>\n</ol>\n<h3>Updated Test Files</h3>\n<ol>\n<li><p><strong><code>node/tests/p2p_services_test.rs</code></strong></p>\n<ul>\n<li>Updated service implementations to follow best practices</li>\n<li>Removed unnecessary conversions between JSON and VMap</li>\n<li>Implemented proper <code>handle_request</code> methods that delegate to specialized methods</li>\n<li>Replaced println calls with context-aware logging</li>\n<li>Removed redundant <code>process_any_operation</code> method</li>\n</ul>\n</li>\n<li><p><strong><code>node/tests/sqlite_mixin_tests.rs</code></strong></p>\n<ul>\n<li>Updated <code>QueryableStoreService</code> to follow best practices</li>\n<li>Added specialized methods for different operations</li>\n<li>Implemented proper <code>handle_request</code> method that delegates to specialized methods</li>\n<li>Replaced println calls with context-aware logging</li>\n</ul>\n</li>\n</ol>\n<h2>Key Improvements Highlighted</h2>\n<ol>\n<li><p><strong>Clean Service Implementation</strong></p>\n<ul>\n<li>Clear separation between request handling and business logic</li>\n<li>Simplified <code>handle_request</code> methods that focus on delegation</li>\n<li>Specialized methods for each operation</li>\n</ul>\n</li>\n<li><p><strong>Efficient Data Handling</strong></p>\n<ul>\n<li>Guidelines for minimizing conversions between data formats</li>\n<li>Examples of working directly with JSON or VMap based on input format</li>\n<li>Improved performance by avoiding unnecessary serialization/deserialization</li>\n</ul>\n</li>\n<li><p><strong>Context-Aware Logging</strong></p>\n<ul>\n<li>Integration with Kagi&#39;s logging system</li>\n<li>Structured logging for better traceability</li>\n<li>Appropriate log levels for different operation stages</li>\n</ul>\n</li>\n<li><p><strong>Service Lifecycle Management</strong></p>\n<ul>\n<li>Documented anti-patterns in subscription handling</li>\n<li>Clear guidance on when to set up subscriptions (during init)</li>\n<li>Performance and reliability improvements through proper lifecycle management</li>\n</ul>\n</li>\n</ol>\n<h2>Best Practices Established</h2>\n<ol>\n<li><p><strong><code>handle_request</code> Method</strong></p>\n<ul>\n<li>Should be simple and focused on routing requests</li>\n<li>Should delegate to specialized methods</li>\n<li>Should not contain complex business logic</li>\n<li>Should provide appropriate logging</li>\n</ul>\n</li>\n<li><p><strong>Data Format Handling</strong></p>\n<ul>\n<li>Minimize conversions between JSON and VMap</li>\n<li>Preserve original format where possible</li>\n<li>Choose appropriate tools based on input format</li>\n</ul>\n</li>\n<li><p><strong>Subscription Management</strong></p>\n<ul>\n<li>Always set up subscriptions during the <code>init</code> lifecycle method</li>\n<li>Never check or set up subscriptions during request handling</li>\n<li>Avoid using locks to track subscription setup state</li>\n</ul>\n</li>\n<li><p><strong>Backward Compatibility</strong></p>\n<ul>\n<li>Maintain backward compatibility with <code>process_request</code></li>\n<li>Delegate from <code>process_request</code> to <code>handle_request</code></li>\n</ul>\n</li>\n</ol>\n<h2>Documentation Improvements for Publication</h2>\n<p>To prepare the documentation for publication, we&#39;ve made the following key improvements:</p>\n<h3>1. Enhanced Cross-Referencing</h3>\n<ul>\n<li>Added &quot;Related Documentation&quot; sections to all core documentation files</li>\n<li>Ensured consistent linking between related concepts</li>\n<li>Provided context for why related documents are relevant</li>\n</ul>\n<h3>2. Clarified Relationships Between Components</h3>\n<ul>\n<li>Added a comprehensive &quot;Core Concepts Relationships&quot; section to the README</li>\n<li>Created a visual ASCII diagram showing how components interact</li>\n<li>Explained the dependencies and information flow between components</li>\n</ul>\n<h3>3. Documentation Structure Standardization</h3>\n<ul>\n<li>Ensured consistent formatting across all documentation files</li>\n<li>Standardized section headings for easier navigation</li>\n<li>Added clear introduction and overview sections in each document</li>\n</ul>\n<h3>4. Contributing Guidelines</h3>\n<ul>\n<li>Created comprehensive documentation contribution guidelines</li>\n<li>Outlined standard section requirements</li>\n<li>Provided guidance on cross-referencing, visual elements, and code examples</li>\n</ul>\n<h3>5. Anti-Pattern Documentation</h3>\n<ul>\n<li>Documented common anti-patterns to help developers avoid pitfalls</li>\n<li>Provided clear examples of what not to do</li>\n<li>Contrasted anti-patterns with best practices to reinforce good habits</li>\n</ul>\n<p>These improvements have significantly enhanced the quality and usability of the Kagi documentation, making it ready for publication and ensuring it will serve as a valuable resource for developers using the framework. </p>\n",
    "path": "/documentation_updates"
  },
  "services/api": {
    "html": "<h1>Kagi Node API Documentation</h1>\n<p>This document describes the API for developing services in the Kagi Node system, including service creation, action implementation, event publishing, and event subscription patterns.</p>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#introduction\">Introduction</a></li>\n<li><a href=\"#service-definition\">Service Definition</a><ul>\n<li><a href=\"#creating-a-service\">Creating a Service</a></li>\n<li><a href=\"#service-lifecycle\">Service Lifecycle</a></li>\n<li><a href=\"#service-state-management\">Service State Management</a></li>\n</ul>\n</li>\n<li><a href=\"#action-implementation\">Action Implementation</a><ul>\n<li><a href=\"#implementing-operations\">Implementing Operations</a></li>\n<li><a href=\"#request-response-pattern\">Request-Response Pattern</a></li>\n<li><a href=\"#service-to-service-communication\">Service-to-Service Communication</a></li>\n</ul>\n</li>\n<li><a href=\"#event-system\">Event System</a><ul>\n<li><a href=\"#publishing-events\">Publishing Events</a></li>\n<li><a href=\"#subscribing-to-events\">Subscribing to Events</a></li>\n<li><a href=\"#event-handler-lifecycle\">Event Handler Lifecycle</a></li>\n<li><a href=\"#advanced-subscription-options\">Advanced Subscription Options</a></li>\n</ul>\n</li>\n<li><a href=\"#best-practices\">Best Practices</a><ul>\n<li><a href=\"#service-implementation-best-practices\">Service Implementation</a></li>\n<li><a href=\"#subscription-management-best-practices\">Subscription Management</a></li>\n<li><a href=\"#error-handling\">Error Handling</a></li>\n</ul>\n</li>\n</ol>\n<h2>Introduction</h2>\n<p>The Kagi Node system follows a modular, service-oriented architecture where each component is implemented as a service. This document explains how to develop services, implement actions/operations, and work with the event-driven pub/sub system.</p>\n<p>Services in Kagi are isolated components that communicate with each other only through well-defined interfaces (request/response and publish/subscribe patterns). The system is designed to be extensible and to support distributed deployment.</p>\n<h2>Service Definition</h2>\n<h3>Creating a Service</h3>\n<p>To create a service, you need to:</p>\n<ol>\n<li>Define a struct that represents your service</li>\n<li>Implement the <code>AbstractService</code> trait for your struct</li>\n</ol>\n<p>Here&#39;s a minimal example:</p>\n<pre><code class=\"language-rust\">use anyhow::Result;\nuse async_trait::async_trait;\nuse kagi_node::services::{\n    AbstractService, ServiceRequest, ServiceResponse, RequestContext, ResponseStatus, ValueType\n};\nuse std::sync::Mutex;\n\nstruct MyService {\n    name: String,\n    path: String,\n    state: Mutex&lt;ServiceState&gt;,\n}\n\nimpl MyService {\n    fn new(name: &amp;str) -&gt; Self {\n        MyService {\n            name: name.to_string(),\n            path: name.to_string(),\n            state: Mutex::new(ServiceState::Created),\n        }\n    }\n    \n    // Service-specific methods go here\n    \n    // Implementation of operation1\n    async fn operation1(&amp;self, _request: &amp;ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n        // Implement action here...\n        Ok(ServiceResponse {\n            status: ResponseStatus::Success,\n            message: &quot;Operation completed successfully&quot;.to_string(),\n            data: None,\n        })\n    }\n    \n    // Implementation of operation2\n    async fn operation2(&amp;self, request: &amp;ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n        // Implement action here...\n        let param = request\n            .get_param(&quot;param&quot;)\n            .and_then(|v| v.as_str().map(|s| s.to_string()))\n            .unwrap_or_default();\n            \n        Ok(ServiceResponse {\n            status: ResponseStatus::Success,\n            message: format!(&quot;Operation2 with param: {}&quot;, param),\n            data: None,\n        })\n    }\n}\n\n#[async_trait]\nimpl AbstractService for MyService {\n    fn name(&amp;self) -&gt; &amp;str {\n        &amp;self.name\n    }\n\n    fn path(&amp;self) -&gt; &amp;str {\n        &amp;self.path\n    }\n\n    fn state(&amp;self) -&gt; ServiceState {\n        *self.state.lock().unwrap()\n    }\n\n    async fn init(&amp;self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n        // Initialize the service\n        let mut state = self.state.lock().unwrap();\n        *state = ServiceState::Initialized;\n        Ok(())\n    }\n\n    async fn start(&amp;self) -&gt; Result&lt;()&gt; {\n        // Start the service\n        let mut state = self.state.lock().unwrap();\n        *state = ServiceState::Running;\n        Ok(())\n    }\n\n    async fn stop(&amp;self) -&gt; Result&lt;()&gt; {\n        // Stop the service\n        let mut state = self.state.lock().unwrap();\n        *state = ServiceState::Stopped;\n        Ok(())\n    }\n\n    async fn process_request(&amp;self, request: ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n        // Delegate to operation-specific methods\n        match request.operation.as_str() {\n            &quot;operation1&quot; =&gt; self.operation1(&amp;request).await,\n            &quot;operation2&quot; =&gt; self.operation2(&amp;request).await,\n            _ =&gt; Ok(ServiceResponse {\n                status: ResponseStatus::Error,\n                message: format!(&quot;Unknown operation: {}&quot;, request.operation),\n                data: None,\n            }),\n        }\n    }\n\n    fn description(&amp;self) -&gt; String {\n        &quot;My custom service&quot;.to_string()\n    }\n}\n\n### Service Lifecycle\n\nServices in Kagi go through a well-defined lifecycle:\n\n1. **Creation**: The service object is instantiated.\n2. **Initialization**: The `init` method is called, allowing the service to set up resources, establish subscriptions, etc.\n3. **Starting**: The `start` method is called when the service is ready to begin operation.\n4. **Running**: The service processes requests while in the Running state.\n5. **Stopping**: The `stop` method is called when the service is being shut down.\n\n### Service State Management\n\nServices have a state property that reflects their current lifecycle stage:\n\n```rust\npub enum ServiceState {\n    Created,       // Service is created but not initialized\n    Initialized,   // Service is initialized but not running\n    Running,       // Service is running\n    Paused,        // Service is paused\n    Stopped,       // Service is stopped\n    Failed,        // Service has failed\n}\n</code></pre>\n<p>It&#39;s recommended to use a <code>Mutex</code> or similar synchronization primitive to manage the service state safely in a concurrent environment.</p>\n<h2>Action Implementation</h2>\n<h3>Implementing Operations</h3>\n<p>Operations (also called actions) are implemented in the <code>process_request</code> method of your service by delegating to separate methods:</p>\n<pre><code class=\"language-rust\">// In impl MyService block:\n\n// Implementation methods for each operation\nasync fn get_data(&amp;self, request: &amp;ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n    // Extract parameters\n    let id = request\n        .get_param(&quot;id&quot;)\n        .and_then(|v| v.as_str().map(String::from))\n        .ok_or_else(|| anyhow!(&quot;Missing required parameter: id&quot;))?;\n        \n    // Implement action here...\n    \n    Ok(ServiceResponse {\n        status: ResponseStatus::Success,\n        message: &quot;Data retrieved successfully&quot;.to_string(),\n        data: None,\n    })\n}\n\nasync fn update_data(&amp;self, request: &amp;ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n    // Extract parameters\n    let id = request\n        .get_param(&quot;id&quot;)\n        .and_then(|v| v.as_str().map(String::from))\n        .ok_or_else(|| anyhow!(&quot;Missing required parameter: id&quot;))?;\n        \n    let value = request\n        .get_param(&quot;value&quot;)\n        .and_then(|v| v.as_str().map(String::from))\n        .ok_or_else(|| anyhow!(&quot;Missing required parameter: value&quot;))?;\n    \n    // Implement action here...\n    \n    Ok(ServiceResponse {\n        status: ResponseStatus::Success,\n        message: &quot;Data updated successfully&quot;.to_string(),\n        data: None,\n    })\n}\n\n// In AbstractService implementation:\nasync fn process_request(&amp;self, request: ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n    // Delegate to operation-specific methods\n    match request.operation.as_str() {\n        &quot;get_data&quot; =&gt; self.get_data(&amp;request).await,\n        &quot;update_data&quot; =&gt; self.update_data(&amp;request).await,\n        &quot;delete_data&quot; =&gt; self.delete_data(&amp;request).await,\n        _ =&gt; Ok(ServiceResponse {\n            status: ResponseStatus::Error,\n            message: format!(&quot;Unknown operation: {}&quot;, request.operation),\n            data: None,\n        }),\n    }\n}\n</code></pre>\n<p>Following the architecture guidelines, each operation should be delegated to a separate method for better organization and testability. This improves code readability, maintainability, and allows for more focused unit testing of each operation.</p>\n<h3>Request-Response Pattern</h3>\n<p>The request-response pattern is the primary way services communicate:</p>\n<ol>\n<li>A client (or another service) sends a request to a service</li>\n<li>The service processes the request</li>\n<li>The service returns a response</li>\n</ol>\n<p>Requests are directed using a path in the format <code>serviceName/operation</code>. Parameters are passed as a ValueType (which can be a String, Number, Boolean, Array, Map, or Json).</p>\n<pre><code class=\"language-rust\">// Example of making a request from a service to another service\nasync fn call_another_service(&amp;self, context: &amp;RequestContext, param: &amp;str) -&gt; Result&lt;ServiceResponse&gt; {\n    // Create parameters\n    let params = vmap! {\n        &quot;param1&quot; =&gt; param,\n        &quot;param2&quot; =&gt; 42\n    };\n    \n    // Make the request\n    let response = context.request(&quot;anotherService/someOperation&quot;, params).await?;\n    \n    // Handle the response\n    if response.status == ResponseStatus::Success {\n        // Process successful response\n    } else {\n        // Handle error\n    }\n    \n    Ok(response)\n}\n</code></pre>\n<h3>Service-to-Service Communication</h3>\n<p>Services can communicate with each other through actions using a service registry. This enables loose coupling between services and promotes a modular architecture.</p>\n<p>The following diagram illustrates how service-to-service communication works:</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant C as Client\n    participant G as Gateway\n    participant SR as ServiceRegistry\n    participant S as Service\n\n    C-&gt;&gt;G: HTTP Request\n    G-&gt;&gt;SR: Lookup Service\n    SR--&gt;&gt;G: Return Service Reference\n    G-&gt;&gt;S: Forward Request\n    Note over S: Process Request\n    S--&gt;&gt;G: Return Response\n    G--&gt;&gt;C: HTTP Response\n</code></pre>\n<pre><code class=\"language-rust\">async fn call_other_service(&amp;self, context: &amp;RequestContext) -&gt; Result&lt;ServiceResponse&gt; {\n    // Get a reference to another service through the service registry\n    let other_service = context.service_registry.get_service(&quot;other_service&quot;)?;\n    \n    // Call a method on the other service\n    let params = vmap! {\n        &quot;key&quot; =&gt; &quot;value&quot;\n    };\n    \n    let response = other_service.handle_request(&quot;action_name&quot;, params).await?;\n    \n    Ok(response)\n}\n</code></pre>\n<p>This pattern ensures services remain isolated and only communicate through well-defined interfaces.</p>\n<h3>Remote Service Communication</h3>\n<p>Kagi also supports calling services that are running on remote nodes through the P2P network:</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant C as Client\n    participant G as Gateway\n    participant SR as ServiceRegistry\n    participant P2P as P2P Transport\n    participant RSR as Remote ServiceRegistry\n    participant RS as Remote Service\n\n    C-&gt;&gt;G: HTTP Request\n    G-&gt;&gt;SR: Lookup Service\n    SR--&gt;&gt;G: Not Found Locally\n    G-&gt;&gt;P2P: Find Remote Service\n    P2P-&gt;&gt;RSR: Lookup Service\n    RSR--&gt;&gt;P2P: Return Service Reference\n    P2P-&gt;&gt;RS: Forward Request\n    Note over RS: Process Request\n    RS--&gt;&gt;P2P: Return Response\n    P2P--&gt;&gt;G: Forward Response\n    G--&gt;&gt;C: HTTP Response\n</code></pre>\n<p>Remote service calls are transparent to the client - the system automatically routes requests to the appropriate node.</p>\n<h3>Service Communication Flow</h3>\n<p>The following diagram illustrates the complete service communication flow:</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Client Request] --&gt; B[Gateway Receives Request]\n    B --&gt; C[Parse Request]\n    C --&gt; D[Extract Service and Action]\n    D --&gt; E[Create Service Request]\n    E --&gt; F[Get Service from Registry]\n    F --&gt; G{Service Found?}\n    G --&gt;|No| H[Check Remote Services]\n    G --&gt;|Yes| I[Call Local Service]\n    H --&gt; J{Remote Service Found?}\n    J --&gt;|No| K[Return Service Not Found]\n    J --&gt;|Yes| L[Forward to Remote Service]\n    I --&gt; M[Process Request]\n    L --&gt; N[Process Request Remotely]\n    M --&gt; O[Return Response]\n    N --&gt; P[Return Response via P2P]\n    O --&gt; Q[Gateway Returns Response]\n    P --&gt; Q\n    K --&gt; R[Return Error Response]\n    R --&gt; Q\n</code></pre>\n<h2>Event System</h2>\n<p>Kagi includes a distributed event system that allows services to publish and subscribe to events. The event system provides a way for services to communicate asynchronously.</p>\n<h3>Event Distribution</h3>\n<p>The following diagram illustrates how events are published and distributed across the network:</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant P as Publisher\n    participant ESM as EventSystem (Main Node)\n    participant S as Subscriber\n    participant ESR as EventSystem (Remote Node)\n    participant RS as Remote Subscriber\n\n    P-&gt;&gt;ESM: Publish Event\n    ESM-&gt;&gt;S: Deliver Event\n    Note over S: Process Event\n    ESM-&gt;&gt;ESR: Forward Event (P2P)\n    ESR-&gt;&gt;RS: Deliver Event\n    Note over RS: Process Event\n</code></pre>\n<p>The following flow diagram shows the event distribution process in more detail:</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Event Published] --&gt; B[Event System Receives Event]\n    B --&gt; C[Check Local Subscribers]\n    C --&gt; D{Local Subscribers?}\n    D --&gt;|Yes| E[Deliver to Local Subscribers]\n    D --&gt;|No| F[Skip Local Delivery]\n    B --&gt; G[Check Remote Networks]\n    G --&gt; H{Remote Networks?}\n    H --&gt;|Yes| I[Forward to Remote Event Systems]\n    H --&gt;|No| J[Skip Remote Delivery]\n    I --&gt; K[Remote Event System Receives]\n    K --&gt; L[Deliver to Remote Subscribers]\n    E --&gt; M[Event Processing Complete]\n    F --&gt; M\n    J --&gt; M\n    L --&gt; M\n</code></pre>\n<h3>Publishing Events</h3>\n<p>Services can publish events to notify other services of state changes or important occurrences:</p>\n<pre><code class=\"language-rust\">// Example of publishing an event\nasync fn publish_user_created(&amp;self, context: &amp;RequestContext, user_data: &amp;UserData) -&gt; Result&lt;()&gt; {\n    // Create event payload\n    let event_data = json!({\n        &quot;user_id&quot;: user_data.id,\n        &quot;username&quot;: user_data.username,\n        &quot;timestamp&quot;: chrono::Utc::now().to_rfc3339(),\n    });\n    \n    // Publish to the user/created topic\n    context.publish(&quot;user/created&quot;, event_data).await?;\n    \n    Ok(())\n}\n</code></pre>\n<p>From the test example:</p>\n<pre><code class=\"language-rust\">async fn publish_event(&amp;self, context: &amp;RequestContext, topic: &amp;str, data: &amp;str) -&gt; Result&lt;()&gt; {\n    // Ensure topic includes service name\n    let full_topic = if topic.starts_with(&amp;format!(&quot;{}/&quot;, self.name)) {\n        topic.to_string()\n    } else {\n        format!(&quot;{}/{}&quot;, self.name, topic)\n    };\n\n    let event_data = json!({\n        &quot;topic&quot;: full_topic,\n        &quot;data&quot;: data,\n        &quot;timestamp&quot;: chrono::Utc::now().to_rfc3339(),\n    });\n\n    context.publish(&amp;full_topic, event_data).await?;\n    \n    Ok(())\n}\n</code></pre>\n<h3>Subscribing to Events</h3>\n<p>Services subscribe to events during the initialization phase:</p>\n<pre><code class=\"language-rust\">async fn init(&amp;self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n    // Subscribe to events\n    let self_clone = Arc::new(self.clone());\n    \n    context\n        .subscribe(&quot;user/created&quot;, move |payload| {\n            let self_ref = self_clone.clone();\n            \n            if let ValueType::Json(json_value) = payload {\n                // Spawn a task to handle the event asynchronously\n                tokio::spawn(async move {\n                    self_ref.handle_user_created(json_value).await;\n                });\n            }\n            \n            Ok(())\n        })\n        .await?;\n        \n    // Set service state\n    let mut state = self.state.lock().unwrap();\n    *state = ServiceState::Initialized;\n    \n    Ok(())\n}\n\n// Event handler method\nasync fn handle_user_created(&amp;self, payload: serde_json::Value) {\n    // Extract data from payload\n    let user_id = payload[&quot;user_id&quot;].as_str().unwrap_or(&quot;unknown&quot;);\n    let username = payload[&quot;username&quot;].as_str().unwrap_or(&quot;unknown&quot;);\n    \n    // Process the event\n    // ...\n}\n</code></pre>\n<p>From the test example:</p>\n<pre><code class=\"language-rust\">async fn setup_subscriptions(&amp;self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n    // Create clones for the closures\n    let self_clone = Arc::new(self.clone());\n\n    // Subscribe to valid events\n    let self_valid = self_clone.clone();\n    context\n        .subscribe(&quot;publisher/valid&quot;, move |payload| {\n            let self_valid = self_valid.clone();\n            \n            if let ValueType::Json(json_value) = payload {\n                // Spawn a task to handle the event asynchronously\n                tokio::spawn(async move {\n                    self_valid.handle_valid_event(json_value).await;\n                });\n            }\n            \n            Ok(())\n        })\n        .await?;\n\n    // Subscribe to invalid events\n    let self_invalid = self_clone.clone();\n    context\n        .subscribe(&quot;publisher/invalid&quot;, move |payload| {\n            let self_invalid = self_invalid.clone();\n            \n            if let ValueType::Json(json_value) = payload {\n                // Spawn a task to handle the event asynchronously\n                tokio::spawn(async move {\n                    self_invalid.handle_invalid_event(json_value).await;\n                });\n            }\n            \n            Ok(())\n        })\n        .await?;\n\n    Ok(())\n}\n</code></pre>\n<h3>Event Handler Lifecycle</h3>\n<p>Event handlers remain active until explicitly unregistered:</p>\n<ul>\n<li><code>context.unsubscribe(topic, [handler_id])</code>: Unsubscribe from a topic</li>\n<li><code>context.once(topic, callback)</code>: Subscribe to an event that will automatically unsubscribe after being triggered once</li>\n</ul>\n<pre><code class=\"language-rust\">// Example of using once for a one-time subscription\nasync fn wait_for_service_ready(&amp;self, context: &amp;RequestContext, service_name: &amp;str) -&gt; Result&lt;()&gt; {\n    let (tx, rx) = tokio::sync::oneshot::channel();\n    \n    context\n        .once(&amp;format!(&quot;{}/ready&quot;, service_name), move |_payload| {\n            tx.send(()).unwrap_or_default();\n            Ok(())\n        })\n        .await?;\n        \n    // Wait for the event or timeout\n    let _ = tokio::time::timeout(\n        std::time::Duration::from_secs(10),\n        rx\n    ).await;\n    \n    Ok(())\n}\n</code></pre>\n<h3>Advanced Subscription Options</h3>\n<p>For more control over subscriptions, you can use <code>subscribe_with_options</code>:</p>\n<pre><code class=\"language-rust\">// Example of a subscription with TTL and max triggers\nasync fn setup_temporary_subscription(&amp;self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n    let self_clone = Arc::new(self.clone());\n    \n    let options = SubscriptionOptions {\n        ttl: Some(std::time::Duration::from_secs(60)),  // Auto-unsubscribe after 60 seconds\n        max_triggers: Some(5),                          // Auto-unsubscribe after 5 triggers\n        // Other options...\n    };\n    \n    context\n        .subscribe_with_options(&quot;some/topic&quot;, move |payload| {\n            let self_ref = self_clone.clone();\n            // Handle event...\n            Ok(())\n        }, options)\n        .await?;\n        \n    Ok(())\n}\n</code></pre>\n<h2>Best Practices</h2>\n<h3>Service Implementation Best Practices</h3>\n<ol>\n<li><strong>Single Responsibility</strong>: Each service should have a clearly defined responsibility.</li>\n<li><strong>Operation Delegation</strong>: Delegate complex operations to separate methods.</li>\n<li><strong>State Management</strong>: Properly manage service state transitions.</li>\n<li><strong>Error Handling</strong>: Use anyhow::Result for consistent error handling.</li>\n<li><strong>Service Independence</strong>: Services should be independent and not directly reference other services.</li>\n</ol>\n<h3>Subscription Management Best Practices</h3>\n<ol>\n<li><strong>Init-Time Subscriptions</strong>: Set up subscriptions during service initialization, not during request processing.</li>\n<li><strong>Proper Cleanup</strong>: Unsubscribe when the service stops.</li>\n<li><strong>Async Event Handling</strong>: Spawn async tasks for handling events to avoid blocking.</li>\n<li><strong>Clone Context</strong>: Don&#39;t store the RequestContext beyond the lifetime of the method.</li>\n</ol>\n<h3>Error Handling</h3>\n<p>Use Result<T> for error handling and propagate errors appropriately:</p>\n<pre><code class=\"language-rust\">async fn some_operation(&amp;self, request: &amp;ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n    // Try to get a required parameter\n    let param = request\n        .get_param(&quot;required_param&quot;)\n        .ok_or_else(|| anyhow!(&quot;Missing required parameter: required_param&quot;))?;\n        \n    // Do something that might fail\n    let result = self.do_something_risky(param).await?;\n    \n    // Return a successful response\n    Ok(ServiceResponse {\n        status: ResponseStatus::Success,\n        message: &quot;Operation completed successfully&quot;.to_string(),\n        data: Some(ValueType::String(result)),\n    })\n}\n</code></pre>\n<p>When errors occur, return appropriate error responses:</p>\n<pre><code class=\"language-rust\">// Handle specific error conditions\nmatch self.validate_input(request) {\n    Ok(validated) =&gt; {\n        // Process the validated input\n    }\n    Err(e) =&gt; {\n        Ok(ServiceResponse {\n            status: ResponseStatus::Error,\n            message: format!(&quot;Validation error: {}&quot;, e),\n            data: None,\n        })\n    }\n}\n</code></pre>\n<h2>Examples</h2>\n<p>This section will be expanded with practical examples.</p>\n",
    "path": "/services/api"
  },
  "services/gateway": {
    "html": "<h1>Gateway Module Specification</h1>\n<p>The Gateway module serves as an entry point for external clients to interact with backend services. It processes HTTP requests, directs them to the appropriate services, and provides additional features like authentication, routing, and real-time communication support.</p>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#core-features\">Core Features</a><ul>\n<li><a href=\"#http-server\">HTTP Server</a></li>\n<li><a href=\"#routing\">Routing</a></li>\n<li><a href=\"#authentication\">Authentication</a></li>\n<li><a href=\"#authorization\">Authorization</a></li>\n</ul>\n</li>\n<li><a href=\"#protection-features\">Protection Features</a><ul>\n<li><a href=\"#rate-limiting\">Rate Limiting</a></li>\n<li><a href=\"#cors\">CORS</a></li>\n<li><a href=\"#security\">Security</a></li>\n</ul>\n</li>\n<li><a href=\"#communication-features\">Communication Features</a><ul>\n<li><a href=\"#websocket-support\">WebSocket Support</a></li>\n<li><a href=\"#static-file-serving\">Static File Serving</a></li>\n</ul>\n</li>\n<li><a href=\"#observability\">Observability</a><ul>\n<li><a href=\"#logging\">Logging</a></li>\n<li><a href=\"#metrics\">Metrics</a></li>\n<li><a href=\"#error-handling\">Error Handling</a></li>\n</ul>\n</li>\n<li><a href=\"#integration\">Integration</a><ul>\n<li><a href=\"#service-discovery\">Service Discovery</a></li>\n<li><a href=\"#request-processing\">Request Processing</a></li>\n<li><a href=\"#response-handling\">Response Handling</a></li>\n</ul>\n</li>\n<li><a href=\"#configuration\">Configuration</a></li>\n<li><a href=\"#programmatic-configuration\">Programmatic Configuration</a><ul>\n<li><a href=\"#gateway-macro\">Gateway Macro</a></li>\n<li><a href=\"#route-configuration\">Route Configuration</a></li>\n<li><a href=\"#middleware-configuration\">Middleware Configuration</a></li>\n<li><a href=\"#yaml-integration\">YAML Integration</a></li>\n</ul>\n</li>\n<li><a href=\"#implementation-examples\">Implementation Examples</a></li>\n</ol>\n<h2>Overview</h2>\n<p>The Gateway module provides:</p>\n<ul>\n<li>HTTP/HTTPS request handling and routing</li>\n<li>Authentication and authorization</li>\n<li>Real-time communication via WebSockets</li>\n<li>Protection against abuse and attacks</li>\n<li>Integration with Kagi node services</li>\n<li>Monitoring and observability features</li>\n</ul>\n<h2>Core Features</h2>\n<h3>HTTP Server</h3>\n<p><strong>Capabilities</strong>:</p>\n<ul>\n<li>HTTP/1.1 and HTTP/2 support</li>\n<li>TLS/SSL encryption</li>\n<li>Configurable listening ports and interfaces</li>\n<li>Keep-alive connection support</li>\n<li>Request pipelining</li>\n<li>Graceful shutdown</li>\n</ul>\n<p><strong>Configuration Example</strong>:</p>\n<pre><code class=\"language-yaml\">server:\n  host: &quot;0.0.0.0&quot;\n  port: 8080\n  ssl:\n    enabled: true\n    cert_file: &quot;/path/to/cert.pem&quot;\n    key_file: &quot;/path/to/key.pem&quot;\n  keep_alive: true\n  shutdown_timeout: 30s\n</code></pre>\n<h3>Routing</h3>\n<p><strong>Features</strong>:</p>\n<ul>\n<li>Path-based routing</li>\n<li>Method-based routing</li>\n<li>Parameter extraction</li>\n<li>Query string parsing</li>\n<li>Middleware support</li>\n<li>Nested routes</li>\n</ul>\n<p><strong>Example Configuration</strong>:</p>\n<pre><code class=\"language-yaml\">routes:\n  - path: &quot;/api/v1/users&quot;\n    service: &quot;users&quot;\n    methods: [&quot;GET&quot;, &quot;POST&quot;]\n    middleware: [&quot;auth&quot;, &quot;rate_limit&quot;]\n    \n  - path: &quot;/api/v1/users/:id&quot;\n    service: &quot;users&quot;\n    methods: [&quot;GET&quot;, &quot;PUT&quot;, &quot;DELETE&quot;]\n    params:\n      - name: &quot;id&quot;\n        type: &quot;string&quot;\n        required: true\n</code></pre>\n<p><strong>Implementation Example</strong>:</p>\n<pre><code class=\"language-rust\">#[derive(Debug, Deserialize)]\npub struct RouteConfig {\n    path: String,\n    service: String,\n    methods: Vec&lt;String&gt;,\n    middleware: Option&lt;Vec&lt;String&gt;&gt;,\n    params: Option&lt;Vec&lt;ParamConfig&gt;&gt;,\n}\n\nimpl Gateway {\n    pub async fn handle_request(&amp;self, req: Request) -&gt; Result&lt;Response&gt; {\n        // Find matching route\n        let route = self.router.match_route(req.path(), req.method())?;\n        \n        // Extract parameters\n        let params = route.extract_params(&amp;req)?;\n\n        // Forward to service\n        let service_resp = self.context.request(route.service, params).await?;\n        \n        // Convert to HTTP response\n        Ok(service_resp.into_http_response())\n    }\n}\n</code></pre>\n<h3>Authentication</h3>\n<p><strong>Supported Methods</strong>:</p>\n<ul>\n<li>Basic Authentication</li>\n<li>Bearer Token (JWT)</li>\n<li>API Key</li>\n<li>OAuth 2.0</li>\n<li>Custom schemes</li>\n</ul>\n<p><strong>JWT Configuration Example</strong>:</p>\n<pre><code class=\"language-yaml\">auth:\n  jwt:\n    secret: &quot;${JWT_SECRET}&quot;\n    algorithms: [&quot;HS256&quot;]\n    issuer: &quot;kagi-gateway&quot;\n    audience: &quot;kagi-services&quot;\n    expiration: 3600  # 1 hour\n</code></pre>\n<p><strong>Implementation Example</strong>:</p>\n<pre><code class=\"language-rust\">#[async_trait]\nimpl Middleware for JwtAuthMiddleware {\n    async fn handle(&amp;self, req: Request, next: Next) -&gt; Result&lt;Response&gt; {\n        // Extract token from Authorization header\n        let token = self.extract_token(&amp;req)?;\n        \n        // Validate token\n        let claims = self.validate_token(token)?;\n        \n        // Add claims to request context\n        req.set_context(&quot;user&quot;, claims.user);\n        req.set_context(&quot;roles&quot;, claims.roles);\n        \n        // Continue processing\n        next.run(req).await\n    }\n}\n</code></pre>\n<h3>Authorization</h3>\n<p><strong>Features</strong>:</p>\n<ul>\n<li>Role-Based Access Control (RBAC)</li>\n<li>Attribute-Based Access Control (ABAC)</li>\n<li>Permission hierarchies</li>\n<li>Resource-level permissions</li>\n</ul>\n<p><strong>Configuration Example</strong>:</p>\n<pre><code class=\"language-yaml\">authorization:\n  roles:\n    admin:\n      - &quot;*&quot;\n    user:\n      - &quot;read:*&quot;\n      - &quot;write:own&quot;\n    guest:\n      - &quot;read:public&quot;\n      \n  resources:\n    users:\n      - action: &quot;read&quot;\n        roles: [&quot;admin&quot;, &quot;user&quot;]\n      - action: &quot;write&quot;\n        roles: [&quot;admin&quot;]\n</code></pre>\n<h2>Protection Features</h2>\n<h3>Rate Limiting</h3>\n<p><strong>Algorithms</strong>:</p>\n<ul>\n<li>Fixed Window</li>\n<li>Sliding Window</li>\n<li>Token Bucket</li>\n<li>Leaky Bucket</li>\n</ul>\n<p><strong>Configuration Example</strong>:</p>\n<pre><code class=\"language-yaml\">rate_limit:\n  default:\n    requests: 100\n    window: 60s\n  \n  rules:\n    - path: &quot;/api/v1/users&quot;\n      requests: 10\n      window: 60s\n      \n    - path: &quot;/api/v1/search&quot;\n      token_bucket:\n        rate: 5\n        burst: 10\n</code></pre>\n<p><strong>Implementation Example</strong>:</p>\n<pre><code class=\"language-rust\">pub struct TokenBucketLimiter {\n    rate: f64,\n    burst: u32,\n    tokens: AtomicF64,\n    last_update: AtomicI64,\n}\n\nimpl TokenBucketLimiter {\n    pub fn try_acquire(&amp;self) -&gt; bool {\n        let now = SystemTime::now()\n            .duration_since(UNIX_EPOCH)\n            .unwrap()\n            .as_secs_f64();\n            \n        let last = self.last_update.load(Ordering::Relaxed) as f64;\n        let elapsed = now - last;\n        \n        // Add new tokens based on elapsed time\n        let new_tokens = elapsed * self.rate;\n        let current = self.tokens.load(Ordering::Relaxed);\n        let updated = (current + new_tokens).min(self.burst as f64);\n        \n        // Try to take one token\n        if updated &gt;= 1.0 {\n            self.tokens.store(updated - 1.0, Ordering::Relaxed);\n            self.last_update.store(now as i64, Ordering::Relaxed);\n            true\n        } else {\n            false\n        }\n    }\n}\n</code></pre>\n<h3>CORS</h3>\n<p><strong>Features</strong>:</p>\n<ul>\n<li>Origin validation</li>\n<li>Method restrictions</li>\n<li>Header control</li>\n<li>Credential handling</li>\n<li>Preflight requests</li>\n</ul>\n<p><strong>Configuration Example</strong>:</p>\n<pre><code class=\"language-yaml\">cors:\n  allowed_origins: \n    - &quot;https://app.example.com&quot;\n    - &quot;https://*.example.com&quot;\n  allowed_methods: [&quot;GET&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;]\n  allowed_headers: [&quot;Content-Type&quot;, &quot;Authorization&quot;]\n  expose_headers: [&quot;X-Request-ID&quot;]\n  max_age: 3600\n  allow_credentials: true\n</code></pre>\n<h3>Security</h3>\n<p><strong>Features</strong>:</p>\n<ul>\n<li>TLS/SSL encryption</li>\n<li>XSS protection</li>\n<li>CSRF protection</li>\n<li>SQL injection prevention</li>\n<li>Request validation</li>\n</ul>\n<p><strong>Configuration Example</strong>:</p>\n<pre><code class=\"language-yaml\">security:\n  ssl:\n    enabled: true\n    cert_file: &quot;/path/to/cert.pem&quot;\n    key_file: &quot;/path/to/key.pem&quot;\n    \n  headers:\n    X-Frame-Options: &quot;DENY&quot;\n    X-XSS-Protection: &quot;1; mode=block&quot;\n    Content-Security-Policy: &quot;default-src &#39;self&#39;&quot;\n    \n  csrf:\n    enabled: true\n    methods: [&quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;]\n    token_header: &quot;X-CSRF-Token&quot;\n</code></pre>\n<h2>Communication Features</h2>\n<h3>WebSocket Support</h3>\n<p><strong>Features</strong>:</p>\n<ul>\n<li>Bidirectional real-time communication</li>\n<li>Connection upgrade handling</li>\n<li>Subprotocol negotiation</li>\n<li>Message routing</li>\n<li>Connection management</li>\n<li>Heartbeat monitoring</li>\n<li>Browser-to-backend RPC calls</li>\n<li>Server-sent events to frontend</li>\n</ul>\n<p><strong>Configuration Example</strong>:</p>\n<pre><code class=\"language-yaml\">websocket:\n  enabled: true\n  path: &quot;/ws&quot;\n  subprotocols: [&quot;kagi-v1&quot;]\n  heartbeat_interval: 30s\n  max_message_size: 65536\n  \n  routes:\n    - path: &quot;/ws/events&quot;\n      service: &quot;event_service&quot;\n      requires_auth: true\n</code></pre>\n<p><strong>Implementation Example</strong>:</p>\n<pre><code class=\"language-rust\">pub struct WebSocketHandler {\n    connections: Arc&lt;RwLock&lt;HashMap&lt;String, WebSocketConnection&gt;&gt;&gt;,\n    heartbeat: Duration,\n}\n\nimpl WebSocketHandler {\n    pub async fn handle_connection(&amp;self, socket: WebSocket, id: String) {\n        // Store connection\n        self.connections.write().await.insert(id.clone(), socket);\n        \n        // Start heartbeat\n        let heartbeat = self.heartbeat;\n        tokio::spawn(async move {\n            loop {\n                tokio::time::sleep(heartbeat).await;\n                if let Err(_) = socket.ping().await {\n                    break;\n                }\n            }\n        });\n        \n        // Handle messages\n        while let Some(msg) = socket.next().await {\n            match msg {\n                Ok(Message::Text(text)) =&gt; {\n                    self.handle_message(&amp;id, text).await;\n                }\n                Ok(Message::Close(_)) =&gt; break,\n                _ =&gt; continue,\n            }\n        }\n        \n        // Clean up\n        self.connections.write().await.remove(&amp;id);\n    }\n}\n</code></pre>\n<h3>WebSocket Frontend Integration</h3>\n<p><strong>Features</strong>:</p>\n<ul>\n<li>Real-time updates to UI</li>\n<li>Server-to-client push notifications</li>\n<li>Frontend action calls to backend services</li>\n<li>Subscription-based channel updates</li>\n<li>RPC-style request/response</li>\n<li>Authentication and authorization</li>\n<li>Connection resilience with automatic reconnection</li>\n</ul>\n<p><strong>Configuration Example</strong>:</p>\n<pre><code class=\"language-yaml\">websocket:\n  enabled: true\n  path: &quot;/ws&quot;\n  heartbeat_interval: 30s\n  authentication:\n    required: true\n    token_param: &quot;token&quot;\n  channels:\n    - name: &quot;notifications&quot;\n      service: &quot;notification_service&quot;\n    - name: &quot;chat&quot;\n      service: &quot;chat_service&quot;\n    - name: &quot;data-sync&quot;\n      service: &quot;sync_service&quot;\n</code></pre>\n<p><strong>Implementation Example</strong>:</p>\n<pre><code class=\"language-rust\">impl Gateway {\n    async fn handle_websocket_connection(\n        &amp;self,\n        ws: WebSocket,\n        token: Option&lt;String&gt;,\n        channels: Vec&lt;String&gt;\n    ) -&gt; Result&lt;(), Error&gt; {\n        // Validate token if required\n        if self.config.websocket.authentication.required {\n            if let Some(token) = token {\n                let valid = self.auth_service.validate_token(&amp;token).await?;\n                if !valid {\n                    return Err(Error::Unauthorized);\n                }\n            } else {\n                return Err(Error::Unauthorized);\n            }\n        }\n        \n        // Subscribe to requested channels\n        for channel in channels {\n            if let Some(service) = self.config.websocket.get_service_for_channel(&amp;channel) {\n                self.subscribe_to_channel(&amp;ws, &amp;channel, service).await?;\n            }\n        }\n        \n        // Process messages\n        self.process_websocket_messages(ws).await\n    }\n    \n    async fn subscribe_to_channel(\n        &amp;self, \n        ws: &amp;WebSocket,\n        channel: &amp;str,\n        service: &amp;str\n    ) -&gt; Result&lt;(), Error&gt; {\n        // Send subscription request to service\n        let response = self.context\n            .request(service, &quot;subscribe&quot;, { channel: channel.to_string() })\n            .await?;\n            \n        // Set up event handler for updates\n        self.event_bus.on(format!(&quot;{}.update&quot;, channel), move |data| {\n            ws.send(data).await\n        });\n        \n        Ok(())\n    }\n    \n    async fn handle_action_call(&amp;self, ws: &amp;WebSocket, id: &amp;str, action: &amp;str, params: Value) -&gt; Result&lt;(), Error&gt; {\n        // Call action on appropriate service\n        let result = self.context.request_with_meta(action, params, {}).await;\n        \n        // Send result back to client\n        match result {\n            Ok(data) =&gt; {\n                ws.send(json!({\n                    &quot;id&quot;: id,\n                    &quot;success&quot;: true,\n                    &quot;data&quot;: data\n                })).await?;\n            },\n            Err(err) =&gt; {\n                ws.send(json!({\n                    &quot;id&quot;: id,\n                    &quot;success&quot;: false,\n                    &quot;error&quot;: {\n                        &quot;message&quot;: err.to_string(),\n                        &quot;code&quot;: err.code(),\n                    }\n                })).await?;\n            }\n        }\n        \n        Ok(())\n    }\n}\n</code></pre>\n<p><strong>Client-side Integration Example</strong>:</p>\n<pre><code class=\"language-javascript\">// Frontend connection to WebSocket endpoint\nconst socket = new WebSocket(&#39;wss://api.example.com/ws?token=JWT_TOKEN&#39;);\n\n// Handle connection events\nsocket.onopen = () =&gt; {\n  console.log(&#39;Connected to server&#39;);\n  \n  // Subscribe to channels\n  socket.send(JSON.stringify({\n    type: &#39;subscribe&#39;,\n    channels: [&#39;notifications&#39;, &#39;chat&#39;]\n  }));\n  \n  // Call backend action\n  socket.send(JSON.stringify({\n    type: &#39;action&#39;,\n    id: &#39;1234&#39;,\n    action: &#39;users.profile&#39;,\n    params: { userId: &#39;current&#39; }\n  }));\n};\n\n// Handle incoming messages\nsocket.onmessage = (event) =&gt; {\n  const message = JSON.parse(event.data);\n  \n  if (message.type === &#39;event&#39;) {\n    // Handle event (server push)\n    console.log(&#39;Event received:&#39;, message.event, message.data);\n    updateUI(message.data);\n  } else if (message.id === &#39;1234&#39;) {\n    // Handle response to our action call\n    if (message.success) {\n      console.log(&#39;Action result:&#39;, message.data);\n    } else {\n      console.error(&#39;Action error:&#39;, message.error);\n    }\n  }\n};\n\n// Handle reconnection\nsocket.onclose = () =&gt; {\n  console.log(&#39;Connection closed, reconnecting...&#39;);\n  setTimeout(connectWebSocket, 1000);\n};\n</code></pre>\n<h3>Static File Serving</h3>\n<p><strong>Features</strong>:</p>\n<ul>\n<li>Serving static files from the file system</li>\n<li>Cache control</li>\n<li>Content type negotiation</li>\n<li>Directory listing</li>\n</ul>\n<p><strong>Configuration Example</strong>:</p>\n<pre><code class=\"language-yaml\">static_file_serving:\n  enabled: true\n  root_dir: &quot;/path/to/static&quot;\n  cache_control: &quot;public, max-age=3600&quot;\n</code></pre>\n<h2>Observability</h2>\n<h3>Logging</h3>\n<p><strong>Features</strong>:</p>\n<ul>\n<li>Structured logging</li>\n<li>Log levels</li>\n<li>Request/response logging</li>\n<li>Error logging</li>\n<li>Performance logging</li>\n</ul>\n<p><strong>Configuration Example</strong>:</p>\n<pre><code class=\"language-yaml\">logging:\n  level: &quot;info&quot;\n  format: &quot;json&quot;\n  output: &quot;stdout&quot;\n  \n  request_logging:\n    enabled: true\n    include_headers: true\n    include_body: false\n</code></pre>\n<h3>Metrics</h3>\n<p><strong>Features</strong>:</p>\n<ul>\n<li>Request counts</li>\n<li>Response times</li>\n<li>Error rates</li>\n<li>Connection stats</li>\n<li>Custom metrics</li>\n</ul>\n<p><strong>Implementation Example</strong>:</p>\n<pre><code class=\"language-rust\">#[derive(Default)]\npub struct Metrics {\n    requests_total: Counter,\n    request_duration: Histogram,\n    errors_total: Counter,\n    active_connections: Gauge,\n}\n\nimpl Metrics {\n    pub fn record_request(&amp;self, duration: Duration, status: u16) {\n        self.requests_total.inc();\n        self.request_duration.observe(duration.as_secs_f64());\n        \n        if status &gt;= 500 {\n            self.errors_total.inc();\n        }\n    }\n}\n</code></pre>\n<h2>Integration</h2>\n<h3>Service Discovery</h3>\n<p><strong>Methods</strong>:</p>\n<ul>\n<li>Static configuration</li>\n<li>Service registry</li>\n<li>DNS-based discovery</li>\n<li>Dynamic updates</li>\n<li>P2P network discovery</li>\n</ul>\n<p><strong>Configuration Example</strong>:</p>\n<pre><code class=\"language-yaml\">service_discovery:\n  type: &quot;registry&quot;\n  registry:\n    url: &quot;http://registry:8500&quot;\n    service_prefix: &quot;kagi-&quot;\n    refresh_interval: 30s\n  p2p:\n    enabled: true\n    networks:\n      - id: &quot;${NETWORK_ID}&quot;\n        bootstrap_peers:\n          - &quot;peer1.example.com:4433&quot;\n          - &quot;peer2.example.com:4433&quot;\n    authentication:\n      token_header: &quot;X-P2P-Token&quot;\n      network_header: &quot;X-Network-ID&quot;\n</code></pre>\n<h3>Request Processing</h3>\n<p>The following diagram illustrates the request processing flow in the Gateway:</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Client Request] --&gt; B[Gateway Receives Request]\n    B --&gt; C{Route Matching}\n    C --&gt;|Match Found| D[Apply Middleware]\n    C --&gt;|No Match| E[Return 404]\n    D --&gt; F[Authentication]\n    F --&gt;|Auth Success| G[Authorization]\n    F --&gt;|Auth Failure| H[Return 401]\n    G --&gt;|Authorized| I[Extract Parameters]\n    G --&gt;|Not Authorized| J[Return 403]\n    I --&gt; K[Create Service Request]\n    K --&gt; L[Forward to Service]\n    L --&gt; M{Service Available?}\n    M --&gt;|Yes| N[Process Service Response]\n    M --&gt;|No| O[Return 503]\n    N --&gt; P[Apply Response Middleware]\n    P --&gt; Q[Send HTTP Response]\n</code></pre>\n<ol>\n<li>Receive HTTP request</li>\n<li>Match route</li>\n<li>Apply middleware</li>\n<li>Extract parameters</li>\n<li>Create service request</li>\n<li>Forward to service</li>\n<li>Process response</li>\n<li>Send HTTP response</li>\n</ol>\n<p><strong>Implementation Example</strong>:</p>\n<pre><code class=\"language-rust\">impl Gateway {\n    pub async fn process_request(&amp;self, http_req: HttpRequest) -&gt; Result&lt;HttpResponse&gt; {\n        // Match route\n        let route = self.router.match_route(http_req.uri(), http_req.method())?;\n        \n        // Apply middleware\n        let (req, ctx) = self.apply_middleware(http_req, &amp;route.middleware).await?;\n        \n        // Create service request\n        let service_req = ServiceRequest::builder()\n            .operation(route.operation)\n            .params(route.extract_params(&amp;req)?)\n            .context(ctx)\n            .build()?;\n            \n        // Forward to service\n        let service_resp = self.service_client\n            .send_request(&amp;route.service, service_req)\n            .await?;\n            \n        // Convert to HTTP response\n        Ok(service_resp.into_http_response())\n    }\n}\n</code></pre>\n<h3>P2P Gateway Support</h3>\n<p><strong>Features</strong>:</p>\n<ul>\n<li>P2P request routing</li>\n<li>Network-specific access control</li>\n<li>DHT integration</li>\n</ul>\n<p><strong>Implementation Example</strong>:</p>\n<pre><code class=\"language-rust\">impl Gateway {\n    async fn handle_p2p_request(&amp;self, req: HttpRequest) -&gt; Result&lt;HttpResponse, Error&gt; {\n        // Extract P2P-specific headers\n        let peer_id = self.extract_peer_id(&amp;req)?;\n        let network_id = self.extract_network_id(&amp;req)?;\n        let token = self.extract_token(&amp;req)?;\n        \n        // Validate P2P access\n        if !self.p2p.validate_peer_token(peer_id, network_id, &amp;token).await? {\n            return Err(Error::Unauthorized);\n        }\n        \n        // Handle DHT operations if specified\n        if let Some(dht_op) = self.extract_dht_operation(&amp;req) {\n            return self.handle_dht_operation(dht_op, network_id).await;\n        }\n        \n        // Forward request to P2P network\n        let response = self.p2p\n            .send_to_peer(peer_id, req.into_inner())\n            .await?;\n            \n        Ok(response.into())\n    }\n    \n    async fn handle_dht_operation(\n        &amp;self,\n        operation: DHTOperation,\n        network_id: NetworkId\n    ) -&gt; Result&lt;HttpResponse, Error&gt; {\n        match operation {\n            DHTOperation::Get { key } =&gt; {\n                let value = self.p2p.dht_get(network_id, key).await?;\n                Ok(HttpResponse::Ok().json(value))\n            }\n            DHTOperation::Put { key, value } =&gt; {\n                self.p2p.dht_put(network_id, key, value).await?;\n                Ok(HttpResponse::Ok().finish())\n            }\n        }\n    }\n}\n</code></pre>\n<h2>Configuration</h2>\n<p>The Gateway is configured through YAML files and environment variables:</p>\n<pre><code class=\"language-yaml\">gateway:\n  server:\n    host: &quot;0.0.0.0&quot;\n    port: 8080\n    \n  services:\n    user_service:\n      url: &quot;http://user-service:8081&quot;\n      timeout: 5s\n      retry:\n        max_attempts: 3\n        backoff: 100ms\n        \n  auth:\n    jwt:\n      secret: &quot;${JWT_SECRET}&quot;\n      expiration: 3600\n      \n  rate_limit:\n    enabled: true\n    default_rate: 100\n    default_burst: 50\n    \n  cors:\n    allowed_origins: [&quot;https://*.example.com&quot;]\n    \n  metrics:\n    enabled: true\n    path: &quot;/metrics&quot;\n</code></pre>\n<h2>Programmatic Configuration</h2>\n<p>The Gateway can be configured programmatically using macros that integrate seamlessly with the Kagi node system. This approach allows for defining routes, middleware, and other gateway features directly in the application code.</p>\n<h3>Gateway Macro</h3>\n<p>The <code>#[gateway]</code> macro defines a new gateway service with configuration options. This macro can be applied to a struct that will serve as the gateway implementation.</p>\n<p><strong>Basic Gateway Definition</strong>:</p>\n<pre><code class=\"language-rust\">use kagi_macros::gateway;\n\n#[gateway(\n    host = &quot;0.0.0.0&quot;,\n    port = 8080,\n    services = [UserService, ProfileService, AuthService]\n)]\npub struct ApiGateway;\n\n#[init]\nimpl ApiGateway {\n    pub async fn new() -&gt; Result&lt;Self&gt; {\n        Ok(Self {})\n    }\n}\n</code></pre>\n<p><strong>Full Gateway Configuration</strong>:</p>\n<pre><code class=\"language-rust\">use kagi_macros::gateway;\n\n#[gateway(\n    host = &quot;0.0.0.0&quot;,\n    port = 8080,\n    services = [UserService, ProfileService, AuthService],\n    ssl = { enabled = true, cert_file = &quot;/path/to/cert.pem&quot;, key_file = &quot;/path/to/key.pem&quot; },\n    cors = { allowed_origins = [&quot;https://app.example.com&quot;], allow_credentials = true },\n    rate_limit = { default_rate = 100, default_burst = 50 },\n    auth = { jwt_secret = &quot;${JWT_SECRET}&quot;, expiration = 3600 }\n)]\npub struct ApiGateway;\n</code></pre>\n<p><strong>YAML-based Configuration</strong>:</p>\n<pre><code class=\"language-rust\">use kagi_macros::gateway;\n\n#[gateway(config_file = &quot;config/gateway.yml&quot;)]\npub struct ApiGateway;\n</code></pre>\n<h3>Route Configuration</h3>\n<p>Routes can be defined using the <code>#[route]</code> macro on gateway implementation methods. This allows for direct mapping of HTTP routes to service actions.</p>\n<p><strong>Basic Route Definition</strong>:</p>\n<pre><code class=\"language-rust\">use kagi_macros::{gateway, route};\n\n#[gateway(...)]\npub struct ApiGateway;\n\nimpl ApiGateway {\n    #[route(GET, &quot;/api/users&quot;)]\n    async fn get_users(&amp;self) -&gt; Result&lt;Vec&lt;User&gt;&gt; {\n        self.context.request(&quot;user_service&quot;, &quot;get_users&quot;, {}).await\n    }\n    \n    #[route(POST, &quot;/api/users&quot;)]\n    async fn create_user(&amp;self, user: User) -&gt; Result&lt;User&gt; {\n        self.context.request(&quot;user_service&quot;, &quot;create_user&quot;, { user }).await\n    }\n    \n    #[route(GET, &quot;/api/users/:id&quot;)]\n    async fn get_user(&amp;self, id: Uuid) -&gt; Result&lt;User&gt; {\n        self.context.request(&quot;user_service&quot;, &quot;get_user&quot;, { id }).await\n    }\n}\n</code></pre>\n<p><strong>Route with Middleware</strong>:</p>\n<pre><code class=\"language-rust\">impl ApiGateway {\n    #[route(GET, &quot;/api/profile&quot;, middleware = [auth])]\n    async fn get_profile(&amp;self, token: String) -&gt; Result&lt;Profile&gt; {\n        let user = self.context.request(&quot;auth_service&quot;, &quot;validate_token&quot;, { token }).await?;\n        self.context.request(&quot;profile_service&quot;, &quot;get_profile&quot;, { user_id: user.id }).await\n    }\n}\n</code></pre>\n<p><strong>REST API to Service Mapping</strong>:</p>\n<pre><code class=\"language-rust\">use kagi_macros::{gateway, rest_api};\n\n#[gateway(...)]\npub struct ApiGateway;\n\n#[rest_api(\n    prefix = &quot;/api/v1&quot;,\n    service = &quot;user_service&quot;\n)]\nimpl ApiGateway {\n    #[action(GET, &quot;/users&quot;)]\n    async fn get_users(&amp;self) -&gt; Result&lt;Vec&lt;User&gt;&gt; {\n        // Maps to user_service.get_users()\n    }\n    \n    #[action(POST, &quot;/users&quot;)]\n    async fn create_user(&amp;self, user: User) -&gt; Result&lt;User&gt; {\n        // Maps to user_service.create_user(user)\n    }\n    \n    #[action(GET, &quot;/users/:id&quot;)]\n    async fn get_user(&amp;self, id: Uuid) -&gt; Result&lt;User&gt; {\n        // Maps to user_service.get_user(id)\n    }\n    \n    #[action(PUT, &quot;/users/:id&quot;)]\n    async fn update_user(&amp;self, id: Uuid, user: User) -&gt; Result&lt;User&gt; {\n        // Maps to user_service.update_user(id, user)\n    }\n}\n</code></pre>\n<h3>Middleware Configuration</h3>\n<p>Middleware can be defined and configured using the <code>#[middleware]</code> macro. This allows for processing requests and responses in a chainable manner.</p>\n<p><strong>Basic Middleware Definition</strong>:</p>\n<pre><code class=\"language-rust\">use kagi_macros::middleware;\n\n#[middleware]\npub struct AuthMiddleware;\n\nimpl AuthMiddleware {\n    #[process]\n    async fn process(&amp;self, req: &amp;mut Request, next: Next) -&gt; Result&lt;Response&gt; {\n        // Extract token from request\n        let token = req.headers().get(&quot;Authorization&quot;)\n            .and_then(|h| h.to_str().ok())\n            .and_then(|s| s.strip_prefix(&quot;Bearer &quot;))\n            .ok_or_else(|| Error::Unauthorized(&quot;Missing token&quot;.into()))?;\n        \n        // Validate token\n        let user = self.context\n            .request(&quot;auth_service&quot;, &quot;validate_token&quot;, { token: token.to_string() })\n            .await?;\n        \n        // Add user to request context\n        req.set_context(&quot;user&quot;, user);\n        \n        // Continue processing\n        next.run(req).await\n    }\n}\n</code></pre>\n<p><strong>Middleware Registration</strong>:</p>\n<pre><code class=\"language-rust\">use kagi_macros::gateway;\n\n#[gateway(\n    host = &quot;0.0.0.0&quot;,\n    port = 8080,\n    middleware = [\n        AuthMiddleware::new(),\n        RateLimitMiddleware::new(100, 50),\n        LoggingMiddleware::new(&quot;info&quot;)\n    ]\n)]\npub struct ApiGateway;\n</code></pre>\n<h3>YAML Integration</h3>\n<p>The gateway can be configured to load specific settings from a YAML file while keeping others defined programmatically.</p>\n<p><strong>Mixed Configuration</strong>:</p>\n<pre><code class=\"language-rust\">use kagi_macros::gateway;\n\n#[gateway(\n    config_file = &quot;config/gateway.yml&quot;,\n    services = [UserService, ProfileService, AuthService]\n)]\npub struct ApiGateway;\n</code></pre>\n<p>With a corresponding YAML file:</p>\n<pre><code class=\"language-yaml\"># config/gateway.yml\nserver:\n  host: &quot;0.0.0.0&quot;\n  port: 8080\n  ssl:\n    enabled: true\n    cert_file: &quot;/path/to/cert.pem&quot;\n    key_file: &quot;/path/to/key.pem&quot;\n\ncors:\n  allowed_origins: [&quot;https://app.example.com&quot;]\n  allow_credentials: true\n\nauth:\n  jwt:\n    secret: &quot;${JWT_SECRET}&quot;\n    expiration: 3600\n</code></pre>\n<h2>Implementation Examples</h2>\n<h3>Complete Gateway Service Example</h3>\n<pre><code class=\"language-rust\">use kagi_macros::{gateway, route, middleware, init, service};\nuse anyhow::Result;\nuse uuid::Uuid;\n\n#[service]\n#[gateway(\n    host = &quot;0.0.0.0&quot;,\n    port = 8080,\n    services = [UserService, ProfileService, AuthService],\n    cors = { allowed_origins = [&quot;https://app.example.com&quot;] }\n)]\npub struct ApiGateway;\n\n#[init]\nimpl ApiGateway {\n    pub async fn new() -&gt; Result&lt;Self&gt; {\n        Ok(Self {})\n    }\n}\n\nimpl ApiGateway {\n    // Public endpoints\n    #[route(POST, &quot;/api/auth/login&quot;)]\n    async fn login(&amp;self) -&gt; Result&lt;AuthResponse&gt; {\n        self.context.request(&quot;auth_service&quot;, &quot;login&quot;, {}).await\n    }\n    \n    #[route(POST, &quot;/api/auth/register&quot;)]\n    async fn register(&amp;self, user_data: RegisterRequest) -&gt; Result&lt;AuthResponse&gt; {\n        self.context.request(&quot;auth_service&quot;, &quot;register&quot;, { user_data }).await\n    }\n    \n    // Protected endpoints\n    #[route(GET, &quot;/api/users&quot;, middleware = [auth])]\n    async fn get_users(&amp;self) -&gt; Result&lt;Vec&lt;User&gt;&gt; {\n        self.context.request(&quot;user_service&quot;, &quot;get_users&quot;, {}).await\n    }\n    \n    #[route(GET, &quot;/api/users/:id&quot;, middleware = [auth])]\n    async fn get_user(&amp;self, id: Uuid) -&gt; Result&lt;User&gt; {\n        self.context.request(&quot;user_service&quot;, &quot;get_user&quot;, { id }).await\n    }\n    \n    #[route(GET, &quot;/api/profile&quot;, middleware = [auth])]\n    async fn get_profile(&amp;self, #[from_context] user: User) -&gt; Result&lt;Profile&gt; {\n        self.context.request(&quot;profile_service&quot;, &quot;get_profile&quot;, { user_id: user.id }).await\n    }\n    \n    #[route(PATCH, &quot;/api/profile&quot;, middleware = [auth])]\n    async fn update_profile(&amp;self, #[from_context] user: User, data: UpdateProfileRequest) -&gt; Result&lt;Profile&gt; {\n        self.context.request(&quot;profile_service&quot;, &quot;update_profile&quot;, { user_id: user.id, data }).await\n    }\n}\n\n// Auth middleware\n#[middleware]\npub struct AuthMiddleware;\n\nimpl AuthMiddleware {\n    #[process]\n    async fn process(&amp;self, req: &amp;mut Request, next: Next) -&gt; Result&lt;Response&gt; {\n        let token = req.headers()\n            .get(&quot;Authorization&quot;)\n            .and_then(|h| h.to_str().ok())\n            .and_then(|s| s.strip_prefix(&quot;Bearer &quot;))\n            .ok_or_else(|| Error::Unauthorized(&quot;Missing token&quot;.into()))?;\n        \n        let user = self.context\n            .request(&quot;auth_service&quot;, &quot;validate_token&quot;, { token: token.to_string() })\n            .await?;\n        \n        req.set_context(&quot;user&quot;, user);\n        next.run(req).await\n    }\n}\n</code></pre>\n<h3>Main Application Entry Point</h3>\n<pre><code class=\"language-rust\">use kagi_macros::{main};\nuse kagi_node::Node;\n\nmod user_service;\nmod auth_service;\nmod profile_service;\nmod api_gateway;\n\nuse user_service::UserService;\nuse auth_service::AuthService;\nuse profile_service::ProfileService;\nuse api_gateway::ApiGateway;\n\n#[main]\nasync fn main() -&gt; Result&lt;()&gt; {\n    // Create and initialize node\n    let mut node = Node::new(kagi_node::NodeConfig {\n        node_id: &quot;api_node&quot;.to_string(),\n        data_dir: &quot;./data&quot;.to_string(),\n        db_path: &quot;./data/db&quot;.to_string(),\n        p2p_config: None, // Configure if P2P is needed\n    }).await?;\n    \n    // Initialize services\n    let user_service = UserService::new().await?;\n    let auth_service = AuthService::new().await?;\n    let profile_service = ProfileService::new().await?;\n    let api_gateway = ApiGateway::new().await?;\n    \n    // Register services with the node\n    node.register_service(&quot;user_service&quot;, user_service).await?;\n    node.register_service(&quot;auth_service&quot;, auth_service).await?;\n    node.register_service(&quot;profile_service&quot;, profile_service).await?;\n    node.register_service(&quot;api_gateway&quot;, api_gateway).await?;\n    \n    // Start the node which will manage all services\n    node.start().await?;\n    \n    // Wait for the node to complete (typically runs until interrupted)\n    node.wait_for_shutdown().await?;\n    \n    Ok(())\n}\n</code></pre>\n<p>This improved specification provides a comprehensive guide for implementing the Gateway module, with clear examples and implementation details that integrate well with the Kagi node system.</p>\n<h2>Examples</h2>\n<p>This section will be expanded with practical examples.</p>\n",
    "path": "/services/gateway"
  },
  "getting-started/installation": {
    "html": "<h1>Installing Kagi</h1>\n<p>This guide covers how to install the Kagi framework in various environments.</p>\n<h2>Prerequisites</h2>\n<p>Before installing Kagi, ensure you have the following prerequisites:</p>\n<ul>\n<li>Rust (1.65 or newer) with Cargo</li>\n<li>OpenSSL development libraries</li>\n<li>A C compiler (gcc, clang, etc.)</li>\n</ul>\n<h2>Installing Rust</h2>\n<p>If you don&#39;t have Rust installed, you can install it using rustup:</p>\n<pre><code class=\"language-bash\">curl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh\n</code></pre>\n<p>Follow the on-screen instructions to complete the installation.</p>\n<h2>As a Dependency in Your Project</h2>\n<p>To use Kagi in your Rust project, add it to your <code>Cargo.toml</code>:</p>\n<pre><code class=\"language-toml\">[dependencies]\nkagi_node = &quot;0.1.0&quot;\nkagi_macros = &quot;0.1.0&quot;  # For macro support\n</code></pre>\n<p>You can now import Kagi in your Rust code:</p>\n<pre><code class=\"language-rust\">use kagi_node::prelude::*;\nuse kagi_node::macros::*;  // For macro support\n</code></pre>\n<h2>As a Standalone Application</h2>\n<p>You can install the Kagi framework as a standalone application:</p>\n<h3>From Binary Releases</h3>\n<p>Download the latest release for your platform:</p>\n<pre><code class=\"language-bash\"># Download the latest release\ncurl -L https://github.com/kagi-framework/kagi/releases/latest/download/kagi-$(uname -s)-$(uname -m) -o kagi\n\n# Make it executable\nchmod +x kagi\n\n# Move it to a directory in your PATH\nsudo mv kagi /usr/local/bin/\n</code></pre>\n<h3>From Source</h3>\n<p>To build Kagi from source:</p>\n<pre><code class=\"language-bash\"># Clone the repository\ngit clone https://github.com/kagi-framework/kagi.git\ncd kagi\n\n# Build in release mode\ncargo build --release\n\n# The binary will be available at target/release/kagi\n</code></pre>\n<h3>Verifying Installation</h3>\n<p>Verify the installation by running:</p>\n<pre><code class=\"language-bash\">kagi --version\n</code></pre>\n<p>This should output the version number of the installed Kagi framework.</p>\n<h2>Platform-Specific Instructions</h2>\n<h3>Windows</h3>\n<p>On Windows, you can download the pre-built binary from the releases page or build from source using a similar approach as above. We recommend using Windows Subsystem for Linux (WSL) for the best experience.</p>\n<h3>macOS</h3>\n<p>On macOS, you can use Homebrew to install Kagi:</p>\n<pre><code class=\"language-bash\">brew tap kagi-framework/kagi\nbrew install kagi\n</code></pre>\n<h3>Docker</h3>\n<p>You can also run Kagi using Docker:</p>\n<pre><code class=\"language-bash\">docker pull kagi-framework/kagi:latest\ndocker run -it kagi-framework/kagi:latest\n</code></pre>\n<h2>Next Steps</h2>\n<p>Now that you have Kagi installed, you can:</p>\n<ul>\n<li>Follow the <a href=\"quickstart\">Quick Start Guide</a> to create your first Kagi application</li>\n<li>Explore the <a href=\"../services/api\">API Reference</a> to learn about available functionality</li>\n<li>Check out the <a href=\"getting-started/example\">Example Service</a> for a complete implementation</li>\n</ul>\n",
    "path": "/getting-started/installation"
  },
  "getting-started/overview": {
    "html": "<h1>Kagi Overview</h1>\n<h2>Introduction</h2>\n<p>Kagi is a powerful distributed system framework built in Rust. It provides a declarative, Actix-inspired approach to defining services, actions, and event subscriptions for building resilient peer-to-peer applications.</p>\n<h2>Key Features</h2>\n<ul>\n<li><strong>Distributed Architecture</strong>: Fully distributed with no central points of failure</li>\n<li><strong>End-to-End Encryption</strong>: Secure communication between nodes</li>\n<li><strong>Declarative API</strong>: Easy-to-use macros for defining services and handlers</li>\n<li><strong>Event-Based Communication</strong>: Publish-subscribe pattern for system events</li>\n<li><strong>Fault Tolerance</strong>: Resilient to network failures and node crashes</li>\n<li><strong>Extensible</strong>: Easy to add new services and functionality</li>\n</ul>\n<h2>Core Components</h2>\n<p>Kagi consists of several core components:</p>\n<ol>\n<li><strong>Node</strong>: The main runtime that hosts services and manages communication</li>\n<li><strong>Services</strong>: Independent modules that provide specific functionality</li>\n<li><strong>Actions</strong>: Request handlers that process incoming service requests</li>\n<li><strong>Events</strong>: Asynchronous messages for inter-service communication</li>\n<li><strong>Discovery</strong>: Mechanism for finding other nodes in the network</li>\n<li><strong>P2P Layer</strong>: Peer-to-peer communication layer</li>\n</ol>\n<h2>Architecture Overview</h2>\n<p>The following diagram illustrates the high-level architecture of a Kagi node:</p>\n<pre><code class=\"language-mermaid\">graph TD\n    Client[Client Applications] --&gt; Gateway\n    Gateway[Gateway Service] --&gt; Router\n    Router[Action Router] --&gt; S1[Service 1]\n    Router --&gt; S2[Service 2]\n    Router --&gt; S3[Service 3]\n    S1 &lt;--&gt; EventBus[Event Bus]\n    S2 &lt;--&gt; EventBus\n    S3 &lt;--&gt; EventBus\n    EventBus &lt;--&gt; P2P[P2P Layer]\n    P2P &lt;--&gt; Network[Network]\n</code></pre>\n<h2>Service Model</h2>\n<p>Services in Kagi are defined using a declarative approach with macros:</p>\n<pre><code class=\"language-rust\">#[kagi::service(name = &quot;example_service&quot;)]\nstruct ExampleService {\n    // Service state\n}\n\nimpl ExampleService {\n    #[action(&quot;perform_task&quot;)]\n    async fn perform_task(&amp;self, context: &amp;RequestContext, \n                         #[param(&quot;input&quot;)] input: String) -&gt; Result&lt;ServiceResponse&gt; {\n        // Handler implementation\n    }\n    \n    #[subscribe(&quot;event/type&quot;)]\n    async fn handle_event(&amp;self, payload: serde_json::Value) -&gt; Result&lt;()&gt; {\n        // Event handler implementation\n    }\n}\n</code></pre>\n<h2>Next Steps</h2>\n<ul>\n<li><a href=\"installation\">Installation Guide</a> - Install Kagi and its dependencies</li>\n<li><a href=\"quickstart\">Quick Start Guide</a> - Build your first Kagi application</li>\n<li><a href=\"../core/architecture\">Architecture</a> - Detailed architecture documentation</li>\n</ul>\n",
    "path": "/getting-started/overview"
  },
  "getting-started/quickstart": {
    "html": "<h1>Kagi Quick Start Guide</h1>\n<p>This guide will help you get started with Kagi by building a simple application.</p>\n<h2>Creating a New Project</h2>\n<p>Start by creating a new Rust project:</p>\n<pre><code class=\"language-bash\">cargo new kagi-hello-world\ncd kagi-hello-world\n</code></pre>\n<p>Add Kagi as a dependency in your <code>Cargo.toml</code> file:</p>\n<pre><code class=\"language-toml\">[dependencies]\nkagi_node = &quot;0.1.0&quot;\nkagi_macros = &quot;0.1.0&quot;\ntokio = { version = &quot;1&quot;, features = [&quot;full&quot;] }\nanyhow = &quot;1.0&quot;\nserde = { version = &quot;1.0&quot;, features = [&quot;derive&quot;] }\nserde_json = &quot;1.0&quot;\n</code></pre>\n<h2>Creating a Simple Service</h2>\n<p>Let&#39;s create a simple &quot;greeting&quot; service. Replace the contents of <code>src/main.rs</code> with the following code:</p>\n<pre><code class=\"language-rust\">use kagi_node::prelude::*;\nuse kagi_node::macros::*;\nuse anyhow::Result;\nuse serde_json::json;\n\n// Define a service\n#[kagi::service(name = &quot;greeter&quot;, description = &quot;A greeting service&quot;)]\nstruct GreeterService {\n    greeting_formats: std::collections::HashMap&lt;String, String&gt;,\n}\n\nimpl GreeterService {\n    // Constructor\n    fn new() -&gt; Self {\n        let mut greeting_formats = std::collections::HashMap::new();\n        greeting_formats.insert(&quot;standard&quot;.to_string(), &quot;Hello, {}!&quot;.to_string());\n        greeting_formats.insert(&quot;friendly&quot;.to_string(), &quot;Hey there, {}! How are you?&quot;.to_string());\n        greeting_formats.insert(&quot;formal&quot;.to_string(), &quot;Good day, {}. It&#39;s a pleasure to meet you.&quot;.to_string());\n        \n        Self { greeting_formats }\n    }\n    \n    // Action handler for generating greetings\n    #[action(&quot;greet&quot;)]\n    async fn greet(&amp;self, _context: &amp;RequestContext, \n                  #[param(&quot;name&quot;)] name: String,\n                  #[param(&quot;format&quot;, default = &quot;standard&quot;)] format: String) -&gt; Result&lt;ServiceResponse&gt; {\n        \n        // Get the greeting format (default to standard if not found)\n        let format_template = self.greeting_formats\n            .get(&amp;format)\n            .unwrap_or(&amp;self.greeting_formats[&quot;standard&quot;])\n            .clone();\n        \n        // Generate the greeting\n        let greeting = format_template.replace(&quot;{}&quot;, &amp;name);\n        \n        // Return the response\n        Ok(ServiceResponse {\n            status: ResponseStatus::Success,\n            message: greeting.clone(),\n            data: Some(vmap! {\n                &quot;greeting&quot; =&gt; greeting,\n                &quot;format_used&quot; =&gt; format\n            }),\n        })\n    }\n    \n    // Action handler for adding new greeting formats\n    #[action(&quot;add_format&quot;)]\n    async fn add_format(&amp;self, context: &amp;RequestContext,\n                       #[param(&quot;name&quot;)] name: String,\n                       #[param(&quot;template&quot;)] template: String) -&gt; Result&lt;ServiceResponse&gt; {\n        \n        // Add the new format\n        {\n            let mut formats = self.greeting_formats.clone();\n            formats.insert(name.clone(), template.clone());\n            self.greeting_formats = formats;\n        }\n        \n        // Publish event about the new format\n        let event_data = json!({\n            &quot;format_name&quot;: name,\n            &quot;template&quot;: template,\n            &quot;timestamp&quot;: chrono::Utc::now().to_rfc3339()\n        });\n        \n        context.publish(&quot;greeter/format_added&quot;, event_data).await?;\n        \n        // Return success response\n        Ok(ServiceResponse {\n            status: ResponseStatus::Success,\n            message: format!(&quot;Added new greeting format: {}&quot;, name),\n            data: Some(vmap! {\n                &quot;name&quot; =&gt; name,\n                &quot;template&quot; =&gt; template\n            }),\n        })\n    }\n    \n    // Event handler for demonstration\n    #[subscribe(&quot;greeter/format_added&quot;)]\n    async fn handle_format_added(&amp;self, payload: serde_json::Value) -&gt; Result&lt;()&gt; {\n        if let (Some(name), Some(template)) = (\n            payload.get(&quot;format_name&quot;).and_then(|v| v.as_str()),\n            payload.get(&quot;template&quot;).and_then(|v| v.as_str())\n        ) {\n            println!(&quot;EVENT: New greeting format added: {} with template: {}&quot;, name, template);\n        }\n        Ok(())\n    }\n}\n\n// Application entry point\n#[kagi::main]\nasync fn main() -&gt; Result&lt;()&gt; {\n    // Create configuration\n    let config = NodeConfig::new(\n        &quot;greeter_node&quot;,\n        &quot;./data&quot;,\n        &quot;./data/db&quot;,\n    );\n    \n    // Create service\n    let greeter_service = GreeterService::new();\n    \n    // Create and start the node\n    Node::builder()\n        .with_config(config)\n        .add_service(greeter_service)\n        .build_and_run()\n        .await\n}\n</code></pre>\n<h2>Running the Application</h2>\n<p>Build and run your application:</p>\n<pre><code class=\"language-bash\">cargo run\n</code></pre>\n<p>This will start a Kagi node with your greeting service.</p>\n<h2>Interacting with the Service</h2>\n<p>You can interact with your service using the Kagi CLI or by writing a client application.</p>\n<h3>Using the Kagi CLI</h3>\n<p>Install the Kagi CLI if you haven&#39;t already:</p>\n<pre><code class=\"language-bash\">cargo install kagi-cli\n</code></pre>\n<p>Send a request to your service:</p>\n<pre><code class=\"language-bash\">kagi-cli request greeter greet --param name=&quot;World&quot;\n</code></pre>\n<p>You should see a response with the greeting &quot;Hello, World!&quot;.</p>\n<p>Try different formats:</p>\n<pre><code class=\"language-bash\">kagi-cli request greeter greet --param name=&quot;World&quot; --param format=&quot;friendly&quot;\n</code></pre>\n<p>Add a new greeting format:</p>\n<pre><code class=\"language-bash\">kagi-cli request greeter add_format --param name=&quot;enthusiastic&quot; --param template=&quot;WOW!!! {} !!! AMAZING!!!&quot;\n</code></pre>\n<p>Test the new format:</p>\n<pre><code class=\"language-bash\">kagi-cli request greeter greet --param name=&quot;World&quot; --param format=&quot;enthusiastic&quot;\n</code></pre>\n<h2>Next Steps</h2>\n<p>You&#39;ve created a simple Kagi service! Here are some next steps to explore:</p>\n<ul>\n<li>Learn about <a href=\"../core/architecture\">Kagi&#39;s Architecture</a></li>\n<li>Understand <a href=\"../development/macros\">Service Definition</a></li>\n<li>Explore <a href=\"../services/api#action-handlers\">Action Handlers</a></li>\n<li>Set up <a href=\"../services/api#event-system\">Event Subscriptions</a></li>\n<li>Build a <a href=\"getting-started/example\">Complete Example Service</a></li>\n</ul>\n<p>Happy coding with Kagi!</p>\n",
    "path": "/getting-started/quickstart"
  },
  "getting-started/example": {
    "html": "<h1>Example Service Implementation</h1>\n<p>This document provides a complete example of a service implementation in the Kagi node system, demonstrating both request-response and publish-subscribe patterns.</p>\n<h2>Table of Contents</h2>\n<ul>\n<li><a href=\"#introduction\">Introduction</a></li>\n</ul>\n<h2>DataService Example</h2>\n<p>Below is an example of a <code>DataService</code> that manages data records, with operations to create, retrieve, update, and delete records, as well as publish events when records change.</p>\n<pre><code class=\"language-rust\">use anyhow::{anyhow, Result};\nuse async_trait::async_trait;\nuse chrono::Utc;\nuse kagi_node::services::{\n    AbstractService, RequestContext, ResponseStatus, ServiceRequest, ServiceResponse, ValueType,\n};\nuse kagi_node::services::abstract_service::ServiceState;\nuse kagi_node::vmap;\nuse serde_json::json;\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::Mutex;\nuse uuid::Uuid;\n\n/// A data record\n#[derive(Clone, Debug)]\nstruct DataRecord {\n    id: String,\n    name: String,\n    value: String,\n    created_at: String,\n    updated_at: String,\n}\n\nimpl DataRecord {\n    fn new(name: &amp;str, value: &amp;str) -&gt; Self {\n        let now = Utc::now().to_rfc3339();\n        Self {\n            id: Uuid::new_v4().to_string(),\n            name: name.to_string(),\n            value: value.to_string(),\n            created_at: now.clone(),\n            updated_at: now,\n        }\n    }\n\n    fn update(&amp;mut self, value: &amp;str) {\n        self.value = value.to_string();\n        self.updated_at = Utc::now().to_rfc3339();\n    }\n\n    fn to_value_type(&amp;self) -&gt; ValueType {\n        vmap! {\n            &quot;id&quot; =&gt; self.id.clone(),\n            &quot;name&quot; =&gt; self.name.clone(),\n            &quot;value&quot; =&gt; self.value.clone(),\n            &quot;created_at&quot; =&gt; self.created_at.clone(),\n            &quot;updated_at&quot; =&gt; self.updated_at.clone()\n        }\n    }\n}\n\n/// DataService manages a collection of data records\npub struct DataService {\n    name: String,\n    path: String,\n    records: Arc&lt;Mutex&lt;HashMap&lt;String, DataRecord&gt;&gt;&gt;,\n    state: Mutex&lt;ServiceState&gt;,\n}\n\nimpl DataService {\n    pub fn new(name: &amp;str) -&gt; Self {\n        DataService {\n            name: name.to_string(),\n            path: name.to_string(),\n            records: Arc::new(Mutex::new(HashMap::new())),\n            state: Mutex::new(ServiceState::Created),\n        }\n    }\n\n    // CRUD Operations\n    \n    // Create a new record\n    async fn create_record(&amp;self, context: &amp;RequestContext, name: &amp;str, value: &amp;str) -&gt; Result&lt;ServiceResponse&gt; {\n        let record = DataRecord::new(name, value);\n        let record_id = record.id.clone();\n        \n        // Store the record\n        {\n            let mut records = self.records.lock().await;\n            records.insert(record.id.clone(), record.clone());\n        }\n        \n        // Publish event that a record was created\n        self.publish_record_event(context, &quot;created&quot;, &amp;record).await?;\n        \n        // Return success response with the new record ID\n        Ok(ServiceResponse {\n            status: ResponseStatus::Success,\n            message: format!(&quot;Record created with ID: {}&quot;, record_id),\n            data: Some(vmap! {\n                &quot;id&quot; =&gt; record_id\n            }),\n        })\n    }\n    \n    // Get a record by ID\n    async fn get_record(&amp;self, _context: &amp;RequestContext, id: &amp;str) -&gt; Result&lt;ServiceResponse&gt; {\n        let records = self.records.lock().await;\n        \n        if let Some(record) = records.get(id) {\n            Ok(ServiceResponse {\n                status: ResponseStatus::Success,\n                message: &quot;Record found&quot;.to_string(),\n                data: Some(record.to_value_type()),\n            })\n        } else {\n            Ok(ServiceResponse {\n                status: ResponseStatus::Error,\n                message: format!(&quot;Record with ID {} not found&quot;, id),\n                data: None,\n            })\n        }\n    }\n    \n    // Update a record\n    async fn update_record(&amp;self, context: &amp;RequestContext, id: &amp;str, value: &amp;str) -&gt; Result&lt;ServiceResponse&gt; {\n        let mut updated_record: Option&lt;DataRecord&gt; = None;\n        \n        // Update the record\n        {\n            let mut records = self.records.lock().await;\n            \n            if let Some(record) = records.get_mut(id) {\n                record.update(value);\n                updated_record = Some(record.clone());\n            }\n        }\n        \n        // Check if record was found and updated\n        if let Some(record) = updated_record {\n            // Publish event that a record was updated\n            self.publish_record_event(context, &quot;updated&quot;, &amp;record).await?;\n            \n            Ok(ServiceResponse {\n                status: ResponseStatus::Success,\n                message: format!(&quot;Record with ID {} updated&quot;, id),\n                data: Some(record.to_value_type()),\n            })\n        } else {\n            Ok(ServiceResponse {\n                status: ResponseStatus::Error,\n                message: format!(&quot;Record with ID {} not found&quot;, id),\n                data: None,\n            })\n        }\n    }\n    \n    // Delete a record\n    async fn delete_record(&amp;self, context: &amp;RequestContext, id: &amp;str) -&gt; Result&lt;ServiceResponse&gt; {\n        let deleted_record: Option&lt;DataRecord&gt;;\n        \n        // Delete the record\n        {\n            let mut records = self.records.lock().await;\n            deleted_record = records.remove(id);\n        }\n        \n        // Check if record was found and deleted\n        if let Some(record) = deleted_record {\n            // Publish event that a record was deleted\n            self.publish_record_event(context, &quot;deleted&quot;, &amp;record).await?;\n            \n            Ok(ServiceResponse {\n                status: ResponseStatus::Success,\n                message: format!(&quot;Record with ID {} deleted&quot;, id),\n                data: None,\n            })\n        } else {\n            Ok(ServiceResponse {\n                status: ResponseStatus::Error,\n                message: format!(&quot;Record with ID {} not found&quot;, id),\n                data: None,\n            })\n        }\n    }\n    \n    // List all records\n    async fn list_records(&amp;self, _context: &amp;RequestContext) -&gt; Result&lt;ServiceResponse&gt; {\n        let records = self.records.lock().await;\n        \n        let records_array = records\n            .values()\n            .map(|record| record.to_value_type())\n            .collect::&lt;Vec&lt;ValueType&gt;&gt;();\n        \n        Ok(ServiceResponse {\n            status: ResponseStatus::Success,\n            message: format!(&quot;Found {} records&quot;, records_array.len()),\n            data: Some(ValueType::Array(records_array)),\n        })\n    }\n    \n    // Event Publishing\n    \n    // Publish an event for a record change\n    async fn publish_record_event(&amp;self, context: &amp;RequestContext, event_type: &amp;str, record: &amp;DataRecord) -&gt; Result&lt;()&gt; {\n        // Create the full topic with service name\n        let topic = format!(&quot;{}/{}&quot;, self.name, event_type);\n        \n        // Create event data\n        let event_data = json!({\n            &quot;event_type&quot;: event_type,\n            &quot;record&quot;: {\n                &quot;id&quot;: record.id,\n                &quot;name&quot;: record.name,\n                &quot;value&quot;: record.value,\n                &quot;created_at&quot;: record.created_at,\n                &quot;updated_at&quot;: record.updated_at\n            },\n            &quot;timestamp&quot;: Utc::now().to_rfc3339()\n        });\n        \n        // Publish the event\n        context.publish(&amp;topic, event_data).await?;\n        \n        Ok(())\n    }\n    \n    // Set up all event subscriptions\n    async fn setup_subscriptions(&amp;self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n        // No subscriptions needed for this service\n        // But this is where we would set them up if needed\n        Ok(())\n    }\n}\n\n#[async_trait]\nimpl AbstractService for DataService {\n    fn name(&amp;self) -&gt; &amp;str {\n        &amp;self.name\n    }\n\n    fn path(&amp;self) -&gt; &amp;str {\n        &amp;self.path\n    }\n\n    fn state(&amp;self) -&gt; ServiceState {\n        *self.state.lock().unwrap()\n    }\n\n    async fn init(&amp;self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n        // Set up event subscriptions\n        self.setup_subscriptions(context).await?;\n        \n        // Update service state\n        let mut state = self.state.lock().unwrap();\n        *state = ServiceState::Initialized;\n        \n        Ok(())\n    }\n\n    async fn start(&amp;self) -&gt; Result&lt;()&gt; {\n        // Update service state\n        let mut state = self.state.lock().unwrap();\n        *state = ServiceState::Running;\n        \n        Ok(())\n    }\n\n    async fn stop(&amp;self) -&gt; Result&lt;()&gt; {\n        // Update service state\n        let mut state = self.state.lock().unwrap();\n        *state = ServiceState::Stopped;\n        \n        Ok(())\n    }\n\n    async fn process_request(&amp;self, request: ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n        // Get the request context and operation\n        let context = &amp;request.request_context;\n        let operation = request.operation.as_str();\n        \n        // Delegate to operation-specific methods\n        match operation {\n            &quot;create&quot; =&gt; {\n                // Extract required parameters\n                let name = request\n                    .get_param(&quot;name&quot;)\n                    .and_then(|v| v.as_str().map(String::from))\n                    .ok_or_else(|| anyhow!(&quot;Missing required parameter: name&quot;))?;\n                \n                let value = request\n                    .get_param(&quot;value&quot;)\n                    .and_then(|v| v.as_str().map(String::from))\n                    .ok_or_else(|| anyhow!(&quot;Missing required parameter: value&quot;))?;\n                \n                self.create_record(context, &amp;name, &amp;value).await\n            }\n            &quot;get&quot; =&gt; {\n                // Extract required parameters\n                let id = request\n                    .get_param(&quot;id&quot;)\n                    .and_then(|v| v.as_str().map(String::from))\n                    .ok_or_else(|| anyhow!(&quot;Missing required parameter: id&quot;))?;\n                \n                self.get_record(context, &amp;id).await\n            }\n            &quot;update&quot; =&gt; {\n                // Extract required parameters\n                let id = request\n                    .get_param(&quot;id&quot;)\n                    .and_then(|v| v.as_str().map(String::from))\n                    .ok_or_else(|| anyhow!(&quot;Missing required parameter: id&quot;))?;\n                \n                let value = request\n                    .get_param(&quot;value&quot;)\n                    .and_then(|v| v.as_str().map(String::from))\n                    .ok_or_else(|| anyhow!(&quot;Missing required parameter: value&quot;))?;\n                \n                self.update_record(context, &amp;id, &amp;value).await\n            }\n            &quot;delete&quot; =&gt; {\n                // Extract required parameters\n                let id = request\n                    .get_param(&quot;id&quot;)\n                    .and_then(|v| v.as_str().map(String::from))\n                    .ok_or_else(|| anyhow!(&quot;Missing required parameter: id&quot;))?;\n                \n                self.delete_record(context, &amp;id).await\n            }\n            &quot;list&quot; =&gt; {\n                self.list_records(context).await\n            }\n            _ =&gt; Ok(ServiceResponse {\n                status: ResponseStatus::Error,\n                message: format!(&quot;Unknown operation: {}&quot;, operation),\n                data: None,\n            }),\n        }\n    }\n\n    fn description(&amp;self) -&gt; String {\n        &quot;Service for managing data records&quot;.to_string()\n    }\n}\n</code></pre>\n<h2>DataMonitorService Example</h2>\n<p>Below is an example of a <code>DataMonitorService</code> that subscribes to events from the <code>DataService</code> and keeps track of statistics:</p>\n<pre><code class=\"language-rust\">use anyhow::Result;\nuse async_trait::async_trait;\nuse kagi_node::services::{\n    AbstractService, RequestContext, ResponseStatus, ServiceRequest, ServiceResponse, ValueType,\n};\nuse kagi_node::services::abstract_service::ServiceState;\nuse kagi_node::vmap;\nuse serde_json::Value;\nuse std::collections::HashMap;\nuse std::sync::Arc;\nuse tokio::sync::Mutex;\n\n/// DataMonitorService listens to events from DataService and tracks statistics\npub struct DataMonitorService {\n    name: String,\n    path: String,\n    state: Mutex&lt;ServiceState&gt;,\n    // Statistics counters\n    stats: Arc&lt;Mutex&lt;HashMap&lt;String, usize&gt;&gt;&gt;,\n}\n\nimpl DataMonitorService {\n    pub fn new(name: &amp;str) -&gt; Self {\n        let mut stats = HashMap::new();\n        \n        // Initialize counters\n        stats.insert(&quot;created&quot;.to_string(), 0);\n        stats.insert(&quot;updated&quot;.to_string(), 0);\n        stats.insert(&quot;deleted&quot;.to_string(), 0);\n        stats.insert(&quot;total&quot;.to_string(), 0);\n        \n        DataMonitorService {\n            name: name.to_string(),\n            path: name.to_string(),\n            state: Mutex::new(ServiceState::Created),\n            stats: Arc::new(Mutex::new(stats)),\n        }\n    }\n    \n    // Get all statistics\n    async fn get_stats(&amp;self) -&gt; Result&lt;ServiceResponse&gt; {\n        let stats = self.stats.lock().await;\n        \n        let stats_map = stats\n            .iter()\n            .map(|(k, v)| (k.clone(), ValueType::Number(*v as f64)))\n            .collect::&lt;HashMap&lt;String, ValueType&gt;&gt;();\n        \n        Ok(ServiceResponse {\n            status: ResponseStatus::Success,\n            message: &quot;Statistics retrieved&quot;.to_string(),\n            data: Some(ValueType::Map(stats_map)),\n        })\n    }\n    \n    // Handle event from DataService\n    async fn handle_data_event(&amp;self, event_type: &amp;str, payload: Value) {\n        // Update statistics based on event type\n        let mut stats = self.stats.lock().await;\n        \n        // Increment the specific counter\n        if let Some(count) = stats.get_mut(event_type) {\n            *count += 1;\n        }\n        \n        // Increment total counter\n        if let Some(total) = stats.get_mut(&quot;total&quot;) {\n            *total += 1;\n        }\n        \n        // Log the event details\n        println!(\n            &quot;DataMonitorService: Received {} event for record ID: {}&quot;,\n            event_type,\n            payload[&quot;record&quot;][&quot;id&quot;].as_str().unwrap_or(&quot;&lt;unknown&gt;&quot;)\n        );\n    }\n    \n    // Set up all event subscriptions\n    async fn setup_subscriptions(&amp;self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n        let self_created = Arc::new(self.clone());\n        let self_updated = Arc::new(self.clone());\n        let self_deleted = Arc::new(self.clone());\n        \n        // Subscribe to &quot;created&quot; events from DataService\n        context\n            .subscribe(&quot;dataService/created&quot;, move |payload| {\n                let self_ref = self_created.clone();\n                \n                if let ValueType::Json(json_value) = payload {\n                    // Spawn a task to handle the event asynchronously\n                    tokio::spawn(async move {\n                        self_ref.handle_data_event(&quot;created&quot;, json_value).await;\n                    });\n                }\n                \n                Ok(())\n            })\n            .await?;\n        \n        // Subscribe to &quot;updated&quot; events from DataService\n        context\n            .subscribe(&quot;dataService/updated&quot;, move |payload| {\n                let self_ref = self_updated.clone();\n                \n                if let ValueType::Json(json_value) = payload {\n                    // Spawn a task to handle the event asynchronously\n                    tokio::spawn(async move {\n                        self_ref.handle_data_event(&quot;updated&quot;, json_value).await;\n                    });\n                }\n                \n                Ok(())\n            })\n            .await?;\n        \n        // Subscribe to &quot;deleted&quot; events from DataService\n        context\n            .subscribe(&quot;dataService/deleted&quot;, move |payload| {\n                let self_ref = self_deleted.clone();\n                \n                if let ValueType::Json(json_value) = payload {\n                    // Spawn a task to handle the event asynchronously\n                    tokio::spawn(async move {\n                        self_ref.handle_data_event(&quot;deleted&quot;, json_value).await;\n                    });\n                }\n                \n                Ok(())\n            })\n            .await?;\n        \n        Ok(())\n    }\n}\n\n// Implement Clone for DataMonitorService to support closures in subscriptions\nimpl Clone for DataMonitorService {\n    fn clone(&amp;self) -&gt; Self {\n        Self {\n            name: self.name.clone(),\n            path: self.path.clone(),\n            state: Mutex::new(*self.state.lock().unwrap()),\n            stats: self.stats.clone(),\n        }\n    }\n}\n\n#[async_trait]\nimpl AbstractService for DataMonitorService {\n    fn name(&amp;self) -&gt; &amp;str {\n        &amp;self.name\n    }\n\n    fn path(&amp;self) -&gt; &amp;str {\n        &amp;self.path\n    }\n\n    fn state(&amp;self) -&gt; ServiceState {\n        *self.state.lock().unwrap()\n    }\n\n    async fn init(&amp;self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n        // Set up event subscriptions\n        self.setup_subscriptions(context).await?;\n        \n        // Update service state\n        let mut state = self.state.lock().unwrap();\n        *state = ServiceState::Initialized;\n        \n        Ok(())\n    }\n\n    async fn start(&amp;self) -&gt; Result&lt;()&gt; {\n        // Update service state\n        let mut state = self.state.lock().unwrap();\n        *state = ServiceState::Running;\n        \n        Ok(())\n    }\n\n    async fn stop(&amp;self) -&gt; Result&lt;()&gt; {\n        // Update service state\n        let mut state = self.state.lock().unwrap();\n        *state = ServiceState::Stopped;\n        \n        Ok(())\n    }\n\n    async fn process_request(&amp;self, request: ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n        // Get the operation\n        let operation = request.operation.as_str();\n        \n        // Delegate to operation-specific methods\n        match operation {\n            &quot;get_stats&quot; =&gt; {\n                self.get_stats().await\n            }\n            _ =&gt; Ok(ServiceResponse {\n                status: ResponseStatus::Error,\n                message: format!(&quot;Unknown operation: {}&quot;, operation),\n                data: None,\n            }),\n        }\n    }\n\n    fn description(&amp;self) -&gt; String {\n        &quot;Service for monitoring data events&quot;.to_string()\n    }\n}\n</code></pre>\n<h2>Usage Example</h2>\n<p>Here&#39;s an example of how to use these services in a Kagi node:</p>\n<pre><code class=\"language-rust\">use anyhow::Result;\nuse kagi_node::node::{Node, NodeConfig};\nuse kagi_node::vmap;\nuse tokio;\n\n#[tokio::main]\nasync fn main() -&gt; Result&lt;()&gt; {\n    // Create and configure the node\n    let config = NodeConfig::new(\n        &quot;my_node&quot;,\n        &quot;./data&quot;,\n        &quot;./data/db&quot;,\n    );\n    let mut node = Node::new(config).await?;\n    \n    // Initialize the node\n    node.init().await?;\n    \n    // Create and add the services\n    let data_service = DataService::new(&quot;dataService&quot;);\n    let monitor_service = DataMonitorService::new(&quot;dataMonitor&quot;);\n    \n    node.add_service(data_service).await?;\n    node.add_service(monitor_service).await?;\n    \n    // Create a new data record\n    let create_result = node.request(\n        &quot;dataService/create&quot;,\n        vmap! {\n            &quot;name&quot; =&gt; &quot;test_record&quot;,\n            &quot;value&quot; =&gt; &quot;initial value&quot;\n        },\n    ).await?;\n    \n    println!(&quot;Create result: {:?}&quot;, create_result);\n    \n    // Get the record ID from the response\n    let record_id = create_result\n        .data\n        .and_then(|data| data.get(&quot;id&quot;))\n        .and_then(|id| id.as_str().map(|s| s.to_string()))\n        .expect(&quot;Failed to get record ID&quot;);\n    \n    // Update the record\n    let update_result = node.request(\n        &quot;dataService/update&quot;,\n        vmap! {\n            &quot;id&quot; =&gt; record_id.clone(),\n            &quot;value&quot; =&gt; &quot;updated value&quot;\n        },\n    ).await?;\n    \n    println!(&quot;Update result: {:?}&quot;, update_result);\n    \n    // Retrieve the record\n    let get_result = node.request(\n        &quot;dataService/get&quot;,\n        vmap! {\n            &quot;id&quot; =&gt; record_id.clone()\n        },\n    ).await?;\n    \n    println!(&quot;Get result: {:?}&quot;, get_result);\n    \n    // Wait a bit for events to be processed\n    tokio::time::sleep(std::time::Duration::from_millis(100)).await;\n    \n    // Get statistics from the monitor service\n    let stats_result = node.request(\n        &quot;dataMonitor/get_stats&quot;,\n        vmap! {},\n    ).await?;\n    \n    println!(&quot;Stats result: {:?}&quot;, stats_result);\n    \n    // Delete the record\n    let delete_result = node.request(\n        &quot;dataService/delete&quot;,\n        vmap! {\n            &quot;id&quot; =&gt; record_id\n        },\n    ).await?;\n    \n    println!(&quot;Delete result: {:?}&quot;, delete_result);\n    \n    // Wait a bit for events to be processed\n    tokio::time::sleep(std::time::Duration::from_millis(100)).await;\n    \n    // Get final statistics\n    let final_stats_result = node.request(\n        &quot;dataMonitor/get_stats&quot;,\n        vmap! {},\n    ).await?;\n    \n    println!(&quot;Final stats result: {:?}&quot;, final_stats_result);\n    \n    Ok(())\n}\n</code></pre>\n<p>This example demonstrates:</p>\n<ol>\n<li>Creating two services: <code>DataService</code> for managing data records and <code>DataMonitorService</code> for tracking statistics</li>\n<li>The <code>DataService</code> publishes events when records are created, updated, or deleted</li>\n<li>The <code>DataMonitorService</code> subscribes to these events and updates statistics</li>\n<li>Both services follow the service lifecycle guidelines (init, start, stop)</li>\n<li>Both services implement the request-response pattern for their operations</li>\n<li>They establish subscriptions during initialization as per the architecture guidelines</li>\n</ol>\n<h2>Examples</h2>\n<p>This section will be expanded with practical examples.</p>\n",
    "path": "/getting-started/example"
  },
  "home": {
    "html": "<h1>Kagi Documentation</h1>\n<p>Welcome to the official documentation for the Kagi distributed system framework.</p>\n<h2>Overview</h2>\n<p>Kagi is a powerful Rust-based framework for building resilient, peer-to-peer distributed applications. It provides a declarative API inspired by actor-based frameworks like Actix, making it easy to define services, handle actions, and manage communication between system components.</p>\n<h2>Getting Started</h2>\n<ul>\n<li><a href=\"getting-started/overview\">Overview</a> - Introduction to Kagi&#39;s concepts</li>\n<li><a href=\"getting-started/installation\">Installation</a> - How to install Kagi</li>\n<li><a href=\"getting-started/quickstart\">Quick Start</a> - Build your first Kagi application</li>\n</ul>\n<h2>Core Concepts</h2>\n<ul>\n<li><a href=\"core/architecture\">Architecture</a> - High-level overview of Kagi&#39;s architecture</li>\n<li><a href=\"core/p2p\">P2P Communication</a> - How peer-to-peer communication works in Kagi</li>\n<li><a href=\"core/discovery\">Discovery</a> - Node discovery mechanisms</li>\n<li><a href=\"core/system-diagrams\">System Diagrams</a> - Visual representations of Kagi&#39;s architecture</li>\n</ul>\n<h2>Services</h2>\n<ul>\n<li><a href=\"services/api\">API Reference</a> - Comprehensive API documentation</li>\n<li><a href=\"services/gateway\">Gateway</a> - Gateway service specification</li>\n<li><a href=\"getting-started/example\">Example Service</a> - Complete example implementation</li>\n</ul>\n<h2>Features</h2>\n<ul>\n<li><a href=\"features/caching\">Caching</a> - Caching strategies and implementation</li>\n<li><a href=\"features/keys-management\">Keys Management</a> - Cryptographic key management</li>\n<li><a href=\"features/logging\">Logging</a> - Logging configuration and usage</li>\n<li><a href=\"features/metrics\">Metrics</a> - Performance metrics and monitoring</li>\n</ul>\n<h2>Development</h2>\n<ul>\n<li><a href=\"development/macros\">Macros System</a> - How to use Kagi&#39;s declarative macros</li>\n<li><a href=\"development/mobile\">Mobile Support</a> - Building mobile applications with Kagi</li>\n</ul>\n",
    "path": "/"
  },
  "features/caching": {
    "html": "<h1>Caching Feature Specification</h1>\n<p>The caching feature enables the storage and retrieval of frequently accessed data to enhance application performance by reducing redundant computations or database queries. It provides a configurable, extensible caching system that integrates seamlessly with services, supporting multiple storage backends and offering robust mechanisms for cache management.</p>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#introduction\">Introduction</a></li>\n<li><a href=\"#cache-storage\">Cache Storage</a></li>\n<li><a href=\"#configuration\">Configuration</a></li>\n<li><a href=\"#cache-operations\">Cache Operations</a></li>\n<li><a href=\"#cache-key-generation\">Cache Key Generation</a></li>\n<li><a href=\"#cache-invalidation\">Cache Invalidation</a></li>\n<li><a href=\"#integration-with-services\">Integration with Services</a><ul>\n<li><a href=\"#declarative-caching\">Declarative Caching</a></li>\n<li><a href=\"#transparent-operation\">Transparent Operation</a></li>\n<li><a href=\"#automatic-cache-management-actions\">Automatic Cache Management Actions</a></li>\n</ul>\n</li>\n<li><a href=\"#error-handling\">Error Handling</a></li>\n<li><a href=\"#performance-considerations\">Performance Considerations</a></li>\n<li><a href=\"#security\">Security</a></li>\n<li><a href=\"#monitoring-and-logging\">Monitoring and Logging</a></li>\n<li><a href=\"#implementation-notes\">Implementation Notes</a></li>\n<li><a href=\"#examples\">Examples</a><ul>\n<li><a href=\"#configuration-example\">Configuration Example</a></li>\n<li><a href=\"#service-definition-example\">Service Definition Example</a></li>\n<li><a href=\"#cache-invalidation-example\">Cache Invalidation Example</a></li>\n</ul>\n</li>\n</ol>\n<h2>Introduction</h2>\n<p>The caching feature enables the storage and retrieval of frequently accessed data to enhance application performance by reducing redundant computations or database queries. It provides a configurable, extensible caching system that integrates seamlessly with services, supporting multiple storage backends and offering robust mechanisms for cache management.</p>\n<h2>Cache Storage</h2>\n<p><strong>Description</strong>: The system supports multiple cache storage backends to suit different scalability and performance needs.</p>\n<p><strong>Supported Backends</strong>:</p>\n<ul>\n<li><strong>In-memory Cache</strong>: A lightweight, fast cache stored in the application&#39;s memory (e.g., using a hash map)</li>\n<li><strong>DHT Cache</strong>: A distributed cache using the P2P network&#39;s DHT system</li>\n<li><strong>Custom Backends</strong>: Users can implement and integrate custom cache stores, including third-party solutions like Redis if needed</li>\n</ul>\n<p><strong>Configuration</strong>: The backend is selectable via configuration files (e.g., JSON/YAML) or environment variables (e.g., <code>CACHE_BACKEND=dht</code>).</p>\n<h3>DHT Cache Backend</h3>\n<p>When using the DHT as a cache backend, the system:</p>\n<ul>\n<li>Stores cache entries in the current network&#39;s DHT (network ID retrieved from context)</li>\n<li>Uses TTL-based expiration through DHT value expiration</li>\n<li>Provides automatic replication across peers</li>\n<li>Supports network-specific cache isolation</li>\n</ul>\n<p><strong>DHT Cache Configuration</strong>:</p>\n<pre><code class=\"language-yaml\">cache:\n  backend: dht\n  replication: 3     # Number of replicas\n  ttl: 3600          # Default TTL in seconds\n  prefix: &quot;cache:&quot;   # Key prefix in DHT\n</code></pre>\n<h2>Configuration</h2>\n<h3>Global Configuration:</h3>\n<ul>\n<li>Enable or disable caching system-wide</li>\n<li>Set a default TTL (Time To Live) for cache entries (e.g., 30 seconds)</li>\n</ul>\n<h3>Service-Level Configuration:</h3>\n<ul>\n<li>Override global settings for specific services</li>\n<li>Example: Enable caching only for a subset of services</li>\n</ul>\n<h3>Action-Level Configuration:</h3>\n<ul>\n<li>Enable/disable caching per action</li>\n<li>Specify custom TTL or caching conditions per action</li>\n<li>Example: <code>#[action(cache(enabled = true, ttl = 60))]</code></li>\n</ul>\n<h2>Cache Operations</h2>\n<p>The following diagram illustrates the cache operations flow:</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Request Received] --&gt; B{Cache Enabled?}\n    B --&gt;|No| C[Execute Action]\n    B --&gt;|Yes| D[Generate Cache Key]\n    D --&gt; E{Key in Cache?}\n    E --&gt;|Yes| F{Entry Expired?}\n    E --&gt;|No| G[Execute Action]\n    F --&gt;|Yes| G\n    F --&gt;|No| H[Return Cached Value]\n    G --&gt; I[Store Result in Cache]\n    I --&gt; J[Return Result]\n    H --&gt; J\n    \n    K[Cache Invalidation] --&gt; L{Invalidation Type}\n    L --&gt;|Time-based| M[Auto-expire after TTL]\n    L --&gt;|Action-based| N[Explicit Cache Clear]\n    L --&gt;|Event-based| O[Event Triggers Invalidation]\n</code></pre>\n<h3>System-Level API:</h3>\n<ul>\n<li><code>set(key, value, ttl)</code>: Stores a value in the cache with a specified key and optional TTL (in seconds)</li>\n<li><code>get(key)</code>: Retrieves the value associated with the key, returning null if not found or expired</li>\n<li><code>delete(key)</code>: Removes a specific cache entry</li>\n<li><code>clear()</code>: Deletes all entries in the cache</li>\n</ul>\n<p><strong>Note</strong>: These methods are available internally to the caching system but are not intended for direct use by service implementations. Services should use the auto-generated cache management actions.</p>\n<h2>Cache Key Generation</h2>\n<p><strong>Automatic Generation</strong>: Unique keys are generated based on the action name and its parameters (e.g., <code>getUser:123</code> for action <code>getUser</code> with parameter <code>id=123</code>)</p>\n<p><strong>Custom Keys</strong>: Users can define custom keys or provide a key generation function (e.g., <code>key: (params) =&gt; &quot;custom:&quot; + params.id</code>)</p>\n<h2>Cache Invalidation</h2>\n<p><strong>Time-based</strong>: Entries expire automatically after their TTL</p>\n<p><strong>Action-based Invalidation</strong>: Cache entries are invalidated using the auto-generated cache management actions:</p>\n<ul>\n<li><code>&lt;service&gt;/cache/clear</code>: Clear all cache entries for the service</li>\n<li><code>&lt;service&gt;/cache/delete</code>: Delete a specific cache entry by key</li>\n<li><code>&lt;service&gt;/cache/revoke</code>: Revoke cache entries by pattern matching</li>\n</ul>\n<p><strong>Event-based</strong>: Invalidate cache entries when specific events occur (e.g., a <code>user.updated</code> event clears related cache keys)</p>\n<ul>\n<li>Configurable via event mappings (e.g., <code>{ event: &quot;user.updated&quot;, keys: [&quot;getUser:*&quot;] }</code>)</li>\n</ul>\n<h2>Integration with Services</h2>\n<h3>Declarative Caching</h3>\n<p>Enable caching for actions using macros:</p>\n<ul>\n<li>Example: <code>#[cached(ttl = 60)]</code> or <code>#[action(cache(enabled = true, ttl = 60))]</code> in service definitions</li>\n</ul>\n<blockquote>\n<p><strong>Note</strong>: Kagi macros support both compile-time (distributed slices) and runtime registration approaches, making them fully compatible with testing environments without requiring unstable Rust features.</p>\n</blockquote>\n<h3>Transparent Operation</h3>\n<p>Caching operates transparently to service implementations:</p>\n<ol>\n<li>When a request is received, the caching system checks if a valid cache entry exists</li>\n<li>If a cache hit occurs, the cached result is returned immediately without invoking the action handler</li>\n<li>If a cache miss occurs, the action handler is invoked and its result is stored in the cache</li>\n</ol>\n<p>This means service implementations don&#39;t need to handle caching logic directly - the system manages it automatically.</p>\n<h3>Automatic Cache Management Actions</h3>\n<p>When caching is enabled for a service, the system automatically adds the following cache management actions:</p>\n<ul>\n<li><code>&lt;service&gt;/cache/clear</code>: Clears all cache entries for the service</li>\n<li><code>&lt;service&gt;/cache/delete</code>: Deletes a specific cache entry by key</li>\n<li><code>&lt;service&gt;/cache/revoke</code>: Revokes cache entries by pattern matching</li>\n</ul>\n<p>Example for a <code>user</code> service:</p>\n<pre><code>user/cache/clear                                  -&gt; Clears all user service cache entries\nuser/cache/delete {key: &quot;get_user:123&quot;}          -&gt; Deletes specific cache entry\nuser/cache/revoke {pattern: &quot;get_user:*&quot;}        -&gt; Invalidates all cache entries matching the pattern\n</code></pre>\n<p>These automatically generated endpoints provide a complete interface for cache management and can be used by services, admin interfaces, or for troubleshooting.</p>\n<h3>P2P Cache Integration</h3>\n<p>When using the DHT cache backend, the system integrates with the P2P transport layer:</p>\n<ol>\n<li><p><strong>DHT Storage</strong>:</p>\n<pre><code class=\"language-rust\">impl DHTCacheBackend {\n    async fn set(&amp;self, key: String, value: Vec&lt;u8&gt;, ttl: Duration) -&gt; Result&lt;()&gt; {\n        // Get network_id from context\n        let network_id = self.context.network_id();\n        \n        // Store in current network&#39;s DHT\n        self.p2p.dht_put(\n            network_id,\n            format!(&quot;{}:{}&quot;, self.prefix, key),\n            CacheEntry {\n                value,\n                expires_at: SystemTime::now() + ttl,\n            }.serialize()\n        ).await\n    }\n    \n    async fn get(&amp;self, key: String) -&gt; Result&lt;Option&lt;Vec&lt;u8&gt;&gt;&gt; {\n        // Get network_id from context\n        let network_id = self.context.network_id();\n        \n        // Retrieve from current network&#39;s DHT\n        if let Some(data) = self.p2p.dht_get(\n            network_id,\n            format!(&quot;{}:{}&quot;, self.prefix, key)\n        ).await? {\n            let entry: CacheEntry = deserialize(&amp;data)?;\n            if entry.expires_at &gt; SystemTime::now() {\n                return Ok(Some(entry.value));\n            }\n        }\n        Ok(None)\n    }\n}\n</code></pre>\n</li>\n<li><p><strong>Network Events</strong>:</p>\n<ul>\n<li>Subscribe to network events for cache invalidation</li>\n<li>Handle peer join/leave events for replication</li>\n<li>Coordinate cache updates across peers</li>\n</ul>\n</li>\n<li><p><strong>Replication Strategy</strong>:</p>\n<pre><code class=\"language-rust\">impl DHTCacheBackend {\n    async fn ensure_replication(&amp;self, key: String) -&gt; Result&lt;()&gt; {\n        // Get network_id from context\n        let network_id = self.context.network_id();\n        \n        let peers = self.p2p.get_network_peers(network_id).await?;\n        if peers.len() &lt; self.config.replication {\n            // Trigger replication to new peers\n            self.replicate_cache_entry(key).await?;\n        }\n        Ok(())\n    }\n    \n    async fn replicate_cache_entry(&amp;self, key: String) -&gt; Result&lt;()&gt; {\n        if let Some(entry) = self.get(key.clone()).await? {\n            // Get network_id from context\n            let network_id = self.context.network_id();\n            \n            // Replicate to additional peers\n            self.p2p.dht_put_replicated(\n                network_id,\n                format!(&quot;{}:{}&quot;, self.prefix, key),\n                entry,\n                self.config.replication\n            ).await?;\n        }\n        Ok(())\n    }\n}\n</code></pre>\n</li>\n<li><p><strong>Cache Consistency</strong>:</p>\n<ul>\n<li>Use DHT&#39;s eventual consistency model</li>\n<li>Handle conflicts through timestamp-based resolution</li>\n<li>Propagate invalidations across the network</li>\n</ul>\n</li>\n</ol>\n<h2>Error Handling</h2>\n<p><strong>Fallback Mechanism</strong>: If the cache backend is unavailable or fails, the system bypasses the cache and fetches data directly</p>\n<p><strong>Error Logging</strong>: Cache-related errors (e.g., connection failures) are logged for debugging, without disrupting service operation</p>\n<h2>Performance Considerations</h2>\n<p><strong>Low Overhead</strong>: Cache operations are optimized for speed, using asynchronous methods where applicable</p>\n<p><strong>In-memory Priority</strong>: Recommend in-memory caching for low-latency scenarios, with custom backends for scalability</p>\n<p><strong>Concurrency</strong>: Ensure thread-safe access for in-memory caches in multi-threaded environments</p>\n<h2>Security</h2>\n<p><strong>Data Sensitivity</strong>: Avoid caching sensitive data unless explicitly secured</p>\n<p><strong>External Backends</strong>: Use encrypted connections when caching data externally with custom backends</p>\n<p><strong>Access Control</strong>: Restrict cache access to authorized services or processes</p>\n<h2>Monitoring and Logging</h2>\n<p><strong>Metrics</strong>: Provide optional metrics for cache performance (e.g., hit rate, miss rate, operation latency)</p>\n<p><strong>Logging</strong>: Log cache events (e.g., hits, misses, errors) for debugging and optimization</p>\n<ul>\n<li>Example: <code>Cache hit: getUser:123</code>, <code>Cache miss: getUser:456</code></li>\n</ul>\n<h2>Implementation Notes</h2>\n<p><strong>Extensibility</strong>: The system allows plugging in custom cache backends via a defined interface (e.g., <code>{ get, set, delete, clear }</code>)</p>\n<p><strong>Minimal Impact</strong>: Caching logic is decoupled from business logic, ensuring clean service code</p>\n<p><strong>Scalability</strong>: Support for distributed caches ensures compatibility with multi-node deployments</p>\n<h2>Examples</h2>\n<h3>Configuration Example</h3>\n<pre><code class=\"language-json\">{\n  &quot;cache&quot;: {\n    &quot;enabled&quot;: true,\n    &quot;backend&quot;: &quot;dht&quot;,\n    &quot;ttl&quot;: 30,\n    &quot;replication&quot;: 3,\n    &quot;prefix&quot;: &quot;cache:&quot;\n  },\n  &quot;services&quot;: {\n    &quot;user&quot;: {\n      &quot;actions&quot;: {\n        &quot;get_user&quot;: {\n          &quot;cache&quot;: {\n            &quot;enabled&quot;: true,\n            &quot;ttl&quot;: 60,\n            &quot;keys&quot;: [&quot;id&quot;]\n          }\n        }\n      }\n    }\n  }\n}\n</code></pre>\n<h3>Service Definition Example</h3>\n<pre><code class=\"language-rust\">use kagi_node::prelude::*;\n\n// Define service with caching using macros\n#[kagi::service]\nstruct UserService {\n    #[inject]\n    db_connection: DatabaseConnection,\n}\n\nimpl UserService {\n    // Cached action with custom TTL using the action macro with cache attributes\n    #[action(cache(enabled = true, ttl = 60))]\n    async fn get_user(&amp;self, context: &amp;RequestContext, id: u64) -&gt; Result&lt;User&gt; {\n        // This will only be called on cache miss\n        // The caching system has already checked for a cached result before calling this method\n        let user = self.db_connection.query_one(&quot;SELECT * FROM users WHERE id = ?&quot;, &amp;[id]).await?;\n        Ok(user)\n    }\n    \n    // Alternative syntax with dedicated cached macro\n    #[action]\n    #[cached(ttl = 60)]\n    async fn get_user_profile(&amp;self, context: &amp;RequestContext, id: u64) -&gt; Result&lt;UserProfile&gt; {\n        let profile = self.db_connection.query_one(&quot;SELECT * FROM profiles WHERE user_id = ?&quot;, &amp;[id]).await?;\n        Ok(profile)\n    }\n    \n    // Action that invalidates cache\n    #[action]\n    async fn update_user(&amp;self, context: &amp;RequestContext, id: u64, data: UserData) -&gt; Result&lt;User&gt; {\n        let user = self.db_connection.update(&quot;users&quot;, id, &amp;data).await?;\n        \n        // Invalidate the cache for this user using the cache management action\n        let params = vmap! {\n            &quot;key&quot; =&gt; format!(&quot;get_user:{}&quot;, id)\n        };\n        context.request(&quot;user/cache/delete&quot;, params).await?;\n        \n        // Publish event that will trigger cache invalidation rules\n        context.publish(&quot;user.updated&quot;, json!({ &quot;id&quot;: id })).await?;\n        \n        Ok(user)\n    }\n}\n</code></pre>\n<h3>Cache Invalidation Example</h3>\n<p>Here&#39;s how cache invalidation works in practice:</p>\n<pre><code class=\"language-rust\">// Example of handling an update that requires cache invalidation\n#[action]\nasync fn update_profile(&amp;self, context: &amp;RequestContext, user_id: u64, profile_data: ProfileData) -&gt; Result&lt;Profile&gt; {\n    // Update the profile in the database\n    let updated_profile = self.db.update_profile(user_id, &amp;profile_data).await?;\n    \n    // Invalidate specific cache entry using the cache management action\n    let params = vmap! {\n        &quot;key&quot; =&gt; format!(&quot;get_profile:{}&quot;, user_id)\n    };\n    context.request(&quot;profile/cache/delete&quot;, params).await?;\n    \n    // For invalidating multiple related entries:\n    let params = vmap! {\n        &quot;pattern&quot; =&gt; format!(&quot;profile:user:{}:*&quot;, user_id)\n    };\n    context.request(&quot;profile/cache/revoke&quot;, params).await?;\n    \n    Ok(updated_profile)\n}\n</code></pre>\n<p>This caching system design ensures:</p>\n<ol>\n<li>Separation of concerns - services don&#39;t need to manage cache directly</li>\n<li>Performance - cached results are returned without invoking handlers</li>\n<li>Consistency - cache invalidation is handled through standard service actions</li>\n<li>Manageability - all cache operations are available as standard service actions</li>\n<li>Flexibility - configurable at global, service, and action levels</li>\n</ol>\n<h3>DHT Cache Example</h3>\n<pre><code class=\"language-yaml\"># DHT cache configuration\ncache:\n  backend: dht\n  replication: 3\n  ttl: 3600\n  prefix: &quot;cache:&quot;\n  consistency:\n    strategy: &quot;eventual&quot;\n    conflict_resolution: &quot;last_write_wins&quot;\n</code></pre>\n<pre><code class=\"language-rust\">// Service using DHT cache\n#[service]\nstruct ProfileService {\n    #[inject]\n    db: Database,\n}\n\nimpl ProfileService {\n    // Using DHT cache with the cached macro\n    #[action]\n    #[cached(backend = &quot;dht&quot;, ttl = 60)]\n    async fn get_user_profile(&amp;self, context: &amp;RequestContext, user_id: String) -&gt; Result&lt;Profile&gt; {\n        // Function implementation\n        // Network ID automatically retrieved from context\n        // Caching handled automatically by the system\n        let profile = self.db.get_profile(user_id).await?;\n        Ok(profile)\n    }\n\n    // Manual cache management\n    #[action]\n    async fn update_profile(&amp;self, context: &amp;RequestContext, user_id: String, profile: Profile) -&gt; Result&lt;()&gt; {\n        // Update profile\n        self.db.update_profile(user_id.clone(), profile).await?;\n        \n        // Invalidate cache within the current network\n        context.request(\n            &quot;profile/cache/delete&quot;,\n            vmap! {\n                &quot;key&quot; =&gt; format!(&quot;get_user_profile:{}&quot;, user_id)\n            }\n        ).await?;\n        \n        Ok(())\n    }\n}\n</code></pre>\n",
    "path": "/features/caching"
  },
  "features/metrics": {
    "html": "<h1>Kagi Node Metrics System</h1>\n<p>The Metrics module provides a robust framework for collecting, managing, and exporting metrics in distributed systems. It is designed to be scalable, efficient, and interoperable with modern observability tools, supporting both standard and custom metrics with aggregation across nodes.</p>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#introduction\">Introduction</a></li>\n<li><a href=\"#metric-types\">Metric Types</a></li>\n<li><a href=\"#metric-registry\">Metric Registry</a></li>\n<li><a href=\"#standard-metrics\">Standard Metrics</a></li>\n<li><a href=\"#custom-metrics\">Custom Metrics</a></li>\n<li><a href=\"#event-based-metrics\">Event-based Metrics</a></li>\n<li><a href=\"#metric-collection\">Metric Collection</a></li>\n<li><a href=\"#metric-export\">Metric Export</a></li>\n<li><a href=\"#configuration\">Configuration</a></li>\n<li><a href=\"#declarative-metrics\">Declarative Metrics</a></li>\n<li><a href=\"#observability-integration\">Observability Integration</a></li>\n<li><a href=\"#performance-considerations\">Performance Considerations</a></li>\n<li><a href=\"#security\">Security</a></li>\n</ol>\n<h2>Introduction</h2>\n<p>The Metrics module provides a robust framework for collecting, managing, and exporting metrics in distributed systems. It is designed to be scalable, efficient, and interoperable with modern observability tools, supporting both standard and custom metrics with aggregation across nodes.</p>\n<h2>Metric Types</h2>\n<ul>\n<li><p><strong>Counter</strong>: Monotonically increasing (e.g., total requests)</p>\n<ul>\n<li>Operations: increment, add</li>\n</ul>\n</li>\n<li><p><strong>Gauge</strong>: Fluctuating value (e.g., memory usage)</p>\n<ul>\n<li>Operations: set, increment, decrement</li>\n</ul>\n</li>\n<li><p><strong>Histogram</strong>: Distribution of values (e.g., latency)</p>\n<ul>\n<li>Operation: observe</li>\n</ul>\n</li>\n<li><p><strong>Summary</strong>: Quantiles over a window (e.g., 95th percentile)</p>\n<ul>\n<li>Operation: observe</li>\n</ul>\n</li>\n<li><p><strong>Rate</strong>: Rate of change (e.g., requests/sec)</p>\n<ul>\n<li>Derived from counters</li>\n</ul>\n</li>\n<li><p><strong>Timer</strong>: Duration measurement (e.g., processing time)</p>\n<ul>\n<li>Operations: start, stop</li>\n</ul>\n</li>\n</ul>\n<h2>Metric Registry</h2>\n<ul>\n<li><p><strong>Distributed Registry</strong>: Manages metrics across nodes/services</p>\n</li>\n<li><p><strong>Unique Identification</strong>: Name, labels, and node/service IDs</p>\n</li>\n<li><p><strong>Methods</strong>:</p>\n<ul>\n<li>Register new metrics</li>\n<li>Retrieve metrics for updates or readings</li>\n</ul>\n</li>\n</ul>\n<h2>Standard Metrics</h2>\n<ul>\n<li><p><strong>System Metrics</strong>:</p>\n<ul>\n<li>CPU usage (per core)</li>\n<li>Memory usage (heap, non-heap)</li>\n<li>Network I/O (bytes sent/received)</li>\n<li>Disk usage (read/write operations)</li>\n</ul>\n</li>\n<li><p><strong>P2P Metrics</strong>:</p>\n<ul>\n<li>Connection metrics</li>\n<li>Network metrics</li>\n<li>Gateway metrics</li>\n</ul>\n</li>\n</ul>\n<h3>P2P Metrics</h3>\n<p><strong>Connection Metrics</strong>:</p>\n<pre><code class=\"language-rust\">/// P2P connection metrics\npub struct P2PMetrics {\n    // Connection counts\n    active_connections: Gauge,\n    total_connections: Counter,\n    failed_connections: Counter,\n    \n    // Network metrics\n    active_networks: Gauge,\n    peers_per_network: Histogram,\n    \n    // Message metrics\n    messages_sent: Counter,\n    messages_received: Counter,\n    message_size: Histogram,\n    \n    // DHT metrics\n    dht_operations: Counter,\n    dht_latency: Histogram,\n    dht_storage_size: Gauge,\n    \n    // Token metrics\n    token_validations: Counter,\n    token_validation_failures: Counter,\n}\n\nimpl P2PMetrics {\n    pub fn record_connection(&amp;self, success: bool) {\n        self.total_connections.inc();\n        if success {\n            self.active_connections.inc();\n        } else {\n            self.failed_connections.inc();\n        }\n    }\n    \n    pub fn record_message(&amp;self, size: usize, is_outbound: bool) {\n        self.message_size.observe(size as f64);\n        if is_outbound {\n            self.messages_sent.inc();\n        } else {\n            self.messages_received.inc();\n        }\n    }\n    \n    pub fn record_dht_operation(&amp;self, op_type: &amp;str, duration: Duration) {\n        self.dht_operations.inc_by(1, &amp;[(&quot;type&quot;, op_type)]);\n        self.dht_latency.observe(duration.as_secs_f64());\n    }\n}\n</code></pre>\n<p><strong>Network Metrics</strong>:</p>\n<pre><code class=\"language-rust\">/// Network-specific metrics\npub struct NetworkMetrics {\n    // Peer metrics\n    active_peers: Gauge,\n    peer_message_rates: Histogram,\n    peer_latencies: Histogram,\n    \n    // Bandwidth metrics\n    bytes_sent: Counter,\n    bytes_received: Counter,\n    bandwidth_usage: Histogram,\n    \n    // Discovery metrics\n    discovery_attempts: Counter,\n    discovery_successes: Counter,\n    discovery_time: Histogram,\n}\n\nimpl NetworkMetrics {\n    pub fn record_peer_message(&amp;self, peer_id: &amp;PeerId, size: usize, duration: Duration) {\n        self.peer_message_rates.observe(1.0);\n        self.peer_latencies.observe(duration.as_secs_f64());\n        self.bytes_sent.inc_by(size as u64);\n    }\n    \n    pub fn record_discovery(&amp;self, success: bool, duration: Duration) {\n        self.discovery_attempts.inc();\n        if success {\n            self.discovery_successes.inc();\n            self.discovery_time.observe(duration.as_secs_f64());\n        }\n    }\n}\n</code></pre>\n<h3>Gateway Metrics</h3>\n<ul>\n<li><strong>Distributed Metrics</strong>:<ul>\n<li>Total active connections</li>\n<li>Aggregated request and error rates</li>\n</ul>\n</li>\n</ul>\n<h2>Custom Metrics</h2>\n<ul>\n<li><strong>Label Support</strong>: Enhanced with cardinality limits</li>\n<li><strong>Metadata</strong>: Descriptions and units</li>\n</ul>\n<h2>Event-based Metrics</h2>\n<ul>\n<li><strong>Distributed Event Tracking</strong>: Aggregate events across services</li>\n<li><strong>Event Latency</strong>: Time from emission to processing</li>\n</ul>\n<h2>Metric Collection</h2>\n<ul>\n<li><p><strong>Efficient Collection</strong>:</p>\n<ul>\n<li>Lock-free structures</li>\n<li>Batch updates</li>\n</ul>\n</li>\n<li><p><strong>Sampling</strong>:</p>\n<ul>\n<li>Configurable rates</li>\n<li>Adaptive sampling</li>\n</ul>\n</li>\n<li><p><strong>Aggregation</strong>:</p>\n<ul>\n<li>Sum, average, percentiles across nodes</li>\n</ul>\n</li>\n</ul>\n<h2>Metric Export</h2>\n<ul>\n<li><p><strong>Formats</strong>:</p>\n<ul>\n<li>OpenMetrics</li>\n<li>JSON, Protobuf</li>\n</ul>\n</li>\n<li><p><strong>Protocols</strong>:</p>\n<ul>\n<li>HTTP/HTTPS (pull)</li>\n<li>gRPC (push)</li>\n<li>UDP (StatsD)</li>\n</ul>\n</li>\n<li><p><strong>Distributed Export</strong>:</p>\n<ul>\n<li>Independent node export</li>\n<li>Central aggregator option</li>\n</ul>\n</li>\n</ul>\n<h2>Configuration</h2>\n<ul>\n<li><p><strong>Global</strong>:</p>\n<ul>\n<li>Enable/disable metrics</li>\n<li>Default sampling rates</li>\n</ul>\n</li>\n<li><p><strong>Per-Metric</strong>:</p>\n<ul>\n<li>Enable/disable specific metrics</li>\n<li>Labels and aggregation rules</li>\n</ul>\n</li>\n<li><p><strong>Export</strong>:</p>\n<ul>\n<li>Exporter type</li>\n<li>Intervals, batch sizes, security settings</li>\n</ul>\n</li>\n</ul>\n<h2>Declarative Metrics</h2>\n<p>The metrics system supports a declarative approach using macros to reduce boilerplate code. This makes it easy to add metrics to services, actions, and events without manually creating and managing metric instances.</p>\n<blockquote>\n<p><strong>Implementation Note</strong>: Kagi macros work with both compile-time (using distributed slices) and runtime registration approaches. This means metrics can be easily applied in both production and testing environments without requiring unstable Rust features.</p>\n</blockquote>\n<h3>Service-Level Metrics</h3>\n<p>Apply metrics to an entire service using the <code>#[metrics]</code> macro:</p>\n<pre><code class=\"language-rust\">use kagi_node::prelude::*;\n\n// Define service with automatic metrics collection\n#[kagi::service]\n#[metrics]\nstruct UserService {\n    #[inject]\n    db_connection: DatabaseConnection,\n}\n</code></pre>\n<p>This macro automatically creates and registers the following metrics for the service:</p>\n<ul>\n<li>Request counter (<code>service_requests_total</code>)</li>\n<li>Active requests gauge (<code>service_active_requests</code>)</li>\n<li>Error counter (<code>service_errors_total</code>)</li>\n<li>Response time histogram (<code>service_response_time_seconds</code>)</li>\n</ul>\n<p>All metrics are labeled with the service name for easy filtering and aggregation.</p>\n<h3>Action-Level Metrics</h3>\n<p>Apply metrics to specific actions using the <code>#[metered]</code> attribute or combined with the <code>#[action]</code> macro:</p>\n<pre><code class=\"language-rust\">impl UserService {\n    // Add metrics to this action using the dedicated metered macro\n    #[action]\n    #[metered]\n    async fn get_user(&amp;self, context: &amp;RequestContext, id: u64) -&gt; Result&lt;User&gt; {\n        // Implementation...\n        let user = self.db_connection.query_one(&quot;SELECT * FROM users WHERE id = ?&quot;, &amp;[id]).await?;\n        Ok(user)\n    }\n    \n    // Alternative syntax with action attributes\n    #[action(metrics = true)]\n    async fn update_user(&amp;self, context: &amp;RequestContext, id: u64, data: UserData) -&gt; Result&lt;User&gt; {\n        // Implementation...\n        Ok(user)\n    }\n    \n    // With custom metric configuration\n    #[action]\n    #[metered(\n        histogram_buckets = [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1.0],\n        labels = [&quot;priority&quot;, &quot;user_type&quot;]\n    )]\n    async fn process_complex_operation(&amp;self, context: &amp;RequestContext, data: ComplexData) -&gt; Result&lt;OperationResult&gt; {\n        // Implementation...\n        Ok(result)\n    }\n}\n</code></pre>\n<p>The <code>#[metered]</code> macro automatically wraps the action with metric collection:</p>\n<ol>\n<li>Increments a request counter specific to the action</li>\n<li>Records the duration of the action</li>\n<li>Tracks successes and failures</li>\n<li>Adds context-aware labels if specified</li>\n</ol>\n<h3>Event-Based Metrics</h3>\n<p>Automatically track metrics for events:</p>\n<pre><code class=\"language-rust\">#[event_handler]\n#[metered(event = &quot;user.updated&quot;)]\nasync fn handle_user_updated(&amp;self, context: &amp;EventContext, event: UserUpdatedEvent) -&gt; Result&lt;()&gt; {\n    // Event handling...\n    Ok(())\n}\n</code></pre>\n<p>This creates:</p>\n<ol>\n<li>Event counter (<code>event_received_total{event=&quot;user.updated&quot;}</code>)</li>\n<li>Event processing time histogram (<code>event_processing_time_seconds{event=&quot;user.updated&quot;}</code>)</li>\n<li>Event failure counter (<code>event_failures_total{event=&quot;user.updated&quot;}</code>)</li>\n</ol>\n<h3>Custom Metric Definitions</h3>\n<p>Define custom metrics with the <code>#[metric]</code> macro:</p>\n<pre><code class=\"language-rust\">#[metric(\n    type = &quot;counter&quot;,\n    name = &quot;user_registration_total&quot;,\n    description = &quot;Total number of user registrations&quot;,\n    labels = [&quot;source&quot;, &quot;account_type&quot;]\n)]\nstruct UserRegistrationMetric;\n\nimpl UserService {\n    #[action]\n    async fn register_user(&amp;self, context: &amp;RequestContext, user_data: UserRegistrationData) -&gt; Result&lt;User&gt; {\n        // Implementation...\n        \n        // Increment the custom metric with labels\n        metrics::increment!(&quot;user_registration_total&quot;, labels: {\n            &quot;source&quot; =&gt; user_data.source,\n            &quot;account_type&quot; =&gt; user_data.account_type\n        });\n        \n        Ok(user)\n    }\n}\n</code></pre>\n<h3>Macro-Based Helper Functions</h3>\n<p>The macros also provide convenient helper functions for common metric operations:</p>\n<pre><code class=\"language-rust\">// Increment a counter\nmetrics::increment!(&quot;custom_counter&quot;);\n\n// Increment with a specific value\nmetrics::increment!(&quot;custom_counter&quot;, value: 5);\n\n// Increment with labels\nmetrics::increment!(&quot;custom_counter&quot;, labels: {&quot;label1&quot; =&gt; &quot;value1&quot;});\n\n// Observe a value on a histogram\nmetrics::observe!(&quot;response_time&quot;, value: duration);\n\n// Set a gauge\nmetrics::set!(&quot;active_connections&quot;, value: count);\n\n// Start a timer and automatically record when dropped\nlet _timer = metrics::timer!(&quot;operation_duration&quot;);\n</code></pre>\n<h3>Automatic Metrics Collection</h3>\n<p>All metrics are automatically registered with the metric registry and included in exports. This removes the need to manually create, register, and update metric instances.</p>\n<h3>Comprehensive Service Example</h3>\n<p>Here&#39;s a complete example demonstrating how to use metric macros in a real-world service:</p>\n<pre><code class=\"language-rust\">use kagi_node::prelude::*;\n\n// Define a service with automatic metrics\n#[kagi::service]\n#[metrics(prefix = &quot;api_gateway_&quot;)]  // Optional prefix for all metrics\nstruct ApiGatewayService {\n    #[inject]\n    db: Database,\n    \n    #[inject]\n    cache_manager: CacheManager,\n    \n    // Custom metrics can still be defined manually when needed\n    #[metric_field]\n    cache_hit_ratio: Gauge,\n    \n    #[metric_field]\n    request_size: Histogram,\n}\n\nimpl ApiGatewayService {\n    // Constructor to set up any custom metrics not handled by macros\n    fn new() -&gt; Self {\n        // The #[metrics] macro will automatically set up common metrics,\n        // but we can still manually define specialized ones\n        let cache_hit_ratio = Gauge::new(\n            &quot;api_gateway_cache_hit_ratio&quot;,\n            &quot;Ratio of cache hits to total requests&quot;\n        ).register();\n        \n        let request_size = Histogram::new(\n            &quot;api_gateway_request_size_bytes&quot;,\n            &quot;Size of API requests in bytes&quot;\n        )\n        .with_buckets(vec![64.0, 256.0, 1024.0, 4096.0, 16384.0, 65536.0])\n        .register();\n        \n        Self {\n            db: Database::default(),\n            cache_manager: CacheManager::default(),\n            cache_hit_ratio,\n            request_size,\n        }\n    }\n\n    // Standard action with default metrics\n    #[action]\n    #[metered]\n    async fn get_user(&amp;self, context: &amp;RequestContext, id: String) -&gt; Result&lt;User&gt; {\n        // Implementation...\n        let user = self.db.find_user(&amp;id).await?;\n        Ok(user)\n    }\n    \n    // Action with both caching and metrics\n    #[action(cache(enabled = true, ttl = 60))]\n    #[metered(\n        buckets = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5],  // Custom time buckets\n        labels = [&quot;user_tier&quot;]                           // Custom labels\n    )]\n    async fn get_user_profile(&amp;self, context: &amp;RequestContext, id: String) -&gt; Result&lt;UserProfile&gt; {\n        // Implementation...\n        // The caching layer handles cache hits automatically\n        // The metrics layer tracks execution time and counts\n        \n        // Add the user_tier label value from context\n        metrics::add_label!(&quot;user_tier&quot;, context.user_tier().unwrap_or(&quot;free&quot;));\n        \n        let profile = self.db.find_user_profile(&amp;id).await?;\n        Ok(profile)\n    }\n    \n    // Action with custom metric tracking\n    #[action]\n    async fn process_order(&amp;self, context: &amp;RequestContext, order: Order) -&gt; Result&lt;OrderConfirmation&gt; {\n        // Start a timer for this specific operation\n        let timer = metrics::timer!(&quot;order_processing_time&quot;, labels: {\n            &quot;order_type&quot; =&gt; order.type_name(),\n            &quot;priority&quot; =&gt; order.priority().to_string()\n        });\n        \n        // Record the order amount\n        metrics::observe!(&quot;order_amount&quot;, value: order.total_amount(), labels: {\n            &quot;currency&quot; =&gt; order.currency()\n        });\n        \n        // Process the order\n        let result = process_order_internal(&amp;order).await;\n        \n        // Track success/failure\n        if result.is_ok() {\n            metrics::increment!(&quot;orders_processed&quot;);\n        } else {\n            metrics::increment!(&quot;orders_failed&quot;);\n        }\n        \n        // Timer automatically stops when dropped\n        drop(timer);\n        \n        result\n    }\n    \n    // Event handler with metrics\n    #[event_handler(&quot;payment.completed&quot;)]\n    #[metered(event = &quot;payment.completed&quot;)]\n    async fn handle_payment_completed(&amp;self, context: &amp;EventContext, event: PaymentCompletedEvent) -&gt; Result&lt;()&gt; {\n        // Implementation...\n        \n        // Track payment amount\n        metrics::observe!(&quot;payment_amount&quot;, value: event.amount, labels: {\n            &quot;payment_method&quot; =&gt; event.payment_method,\n            &quot;currency&quot; =&gt; event.currency\n        });\n        \n        // Event processing...\n        Ok(())\n    }\n    \n    // Background job with metrics\n    #[job(schedule = &quot;*/5 * * * *&quot;)]  // Run every 5 minutes\n    #[metered(name = &quot;cleanup_job&quot;)]  // Custom metric name\n    async fn cleanup_expired_sessions(&amp;self, context: &amp;JobContext) -&gt; Result&lt;CleanupReport&gt; {\n        let start_time = Instant::now();\n        \n        // Implementation...\n        let expired_count = cleanup_sessions().await?;\n        \n        // Record custom metrics about the cleanup\n        metrics::set!(&quot;expired_sessions_count&quot;, value: expired_count as f64);\n        \n        // Duration is automatically recorded by the metered macro\n        Ok(CleanupReport { removed_count: expired_count })\n    }\n}\n\n// Event publisher with automatic metrics\n#[publisher]\n#[metrics(events = true)]  // Track metrics for all published events\nstruct EventPublisher {\n    #[inject]\n    event_bus: EventBus,\n}\n\nimpl EventPublisher {\n    #[action]\n    async fn publish_user_event(&amp;self, context: &amp;RequestContext, event: UserEvent) -&gt; Result&lt;()&gt; {\n        // The metrics macro automatically tracks:\n        // - Number of events published\n        // - Publication latency\n        // - Success/failure rates\n        self.event_bus.publish(&quot;user&quot;, event).await\n    }\n}\n</code></pre>\n<p>This example demonstrates how to:</p>\n<ol>\n<li>Apply metrics to an entire service</li>\n<li>Add automatic metrics to individual actions</li>\n<li>Combine metrics with other features like caching</li>\n<li>Use custom metric configuration</li>\n<li>Add metrics to event handlers and background jobs</li>\n<li>Use the helper functions for manual metric tracking when needed</li>\n</ol>\n<h3>P2P and DHT Metric Integration</h3>\n<p>The metrics system seamlessly integrates with P2P networking and DHT operations through macros, enabling automatic collection of performance and operational data without manual tracking code.</p>\n<h4>Automatic P2P Metrics</h4>\n<p>Apply metrics to P2P transport operations:</p>\n<pre><code class=\"language-rust\">use kagi_node::p2p::prelude::*;\n\n// P2P service with automatic metrics\n#[p2p_service]\n#[metrics(prefix = &quot;p2p_&quot;)]\nstruct P2PService {\n    #[inject]\n    transport: P2PTransport,\n    \n    #[inject]\n    dht: DHTService,\n}\n\nimpl P2PService {\n    // DHT operation with automatic metrics\n    #[dht_operation]\n    #[metered(\n        prefix = &quot;dht_&quot;,\n        buckets = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5]\n    )]\n    async fn store_value(&amp;self, context: &amp;RequestContext, key: String, value: Vec&lt;u8&gt;) -&gt; Result&lt;()&gt; {\n        // Network ID is automatically retrieved from context\n        let network_id = context.network_id();\n        \n        // Store the value in DHT\n        self.dht.put(network_id, key, value).await\n    }\n    \n    // Peer discovery with metrics\n    #[action]\n    #[metered(name = &quot;peer_discovery&quot;)]\n    async fn discover_peers(&amp;self, context: &amp;RequestContext, network_id: String) -&gt; Result&lt;Vec&lt;PeerInfo&gt;&gt; {\n        let start = Instant::now();\n        \n        // Discover peers\n        let peers = self.transport.discover_peers(network_id).await?;\n        \n        // Record peer count\n        metrics::set!(&quot;discovered_peers_count&quot;, value: peers.len() as f64, labels: {\n            &quot;network&quot; =&gt; network_id\n        });\n        \n        Ok(peers)\n    }\n    \n    // Message broadcasting with metrics\n    #[action]\n    #[metered(name = &quot;broadcast&quot;)]\n    async fn broadcast_message(&amp;self, context: &amp;RequestContext, network_id: String, message: Message) -&gt; Result&lt;BroadcastStats&gt; {\n        // Implementation...\n        \n        // Record message size\n        metrics::observe!(&quot;message_size_bytes&quot;, value: message.size() as f64);\n        \n        // Broadcast is automatically metered\n        let stats = self.transport.broadcast(network_id, message).await?;\n        \n        // Record delivery stats\n        metrics::set!(&quot;message_delivery_ratio&quot;, value: stats.successful_deliveries as f64 / stats.total_targets as f64);\n        \n        Ok(stats)\n    }\n}\n</code></pre>\n<h4>DHT Service with Metrics</h4>\n<p>Define a DHT service with comprehensive metrics:</p>\n<pre><code class=\"language-rust\">use kagi_node::dht::prelude::*;\n\n#[dht_service]\n#[metrics]\nstruct DHTService {\n    #[inject]\n    storage: DHTStorage,\n    \n    #[metric_field]\n    storage_size: Gauge,\n    \n    #[metric_field]\n    replication_factor: Gauge,\n}\n\nimpl DHTService {\n    // Get operation with metrics\n    #[action]\n    #[metered(name = &quot;dht_get&quot;)]\n    async fn get_value(&amp;self, context: &amp;RequestContext, key: String) -&gt; Result&lt;Option&lt;Vec&lt;u8&gt;&gt;&gt; {\n        // Network ID from context\n        let network_id = context.network_id();\n        \n        // Record DHT operation\n        let _operation = metrics::timer!(&quot;dht_operation&quot;, labels: {\n            &quot;operation&quot; =&gt; &quot;get&quot;,\n            &quot;network&quot; =&gt; network_id\n        });\n        \n        // Implementation...\n        let result = self.storage.get(network_id, key.clone()).await?;\n        \n        // Record hit/miss\n        if result.is_some() {\n            metrics::increment!(&quot;dht_hits&quot;, labels: {&quot;network&quot; =&gt; network_id});\n        } else {\n            metrics::increment!(&quot;dht_misses&quot;, labels: {&quot;network&quot; =&gt; network_id});\n        }\n        \n        Ok(result)\n    }\n    \n    // Put operation with metrics\n    #[action]\n    #[metered(name = &quot;dht_put&quot;)]\n    async fn put_value(&amp;self, context: &amp;RequestContext, key: String, value: Vec&lt;u8&gt;, ttl: Option&lt;Duration&gt;) -&gt; Result&lt;()&gt; {\n        let network_id = context.network_id();\n        \n        // Record value size\n        metrics::observe!(&quot;dht_value_size_bytes&quot;, value: value.len() as f64, labels: {\n            &quot;network&quot; =&gt; network_id\n        });\n        \n        // Implementation...\n        self.storage.put(network_id, key, value, ttl).await?;\n        \n        // Update storage size metric\n        self.update_storage_metrics(network_id).await;\n        \n        Ok(())\n    }\n    \n    // Internal method to update storage metrics\n    async fn update_storage_metrics(&amp;self, network_id: &amp;str) {\n        if let Ok(stats) = self.storage.get_statistics(network_id).await {\n            self.storage_size.set(stats.size_bytes as f64, &amp;[(&quot;network&quot;, network_id)]);\n            self.replication_factor.set(stats.replication_factor as f64, &amp;[(&quot;network&quot;, network_id)]);\n        }\n    }\n}\n</code></pre>\n<h4>Network Metrics Dashboard</h4>\n<p>The declarative metrics approach makes it easy to create comprehensive dashboards for P2P and DHT operations, including:</p>\n<ul>\n<li>Network health (connections, latency, message delivery)</li>\n<li>DHT performance (gets, puts, hit ratio)</li>\n<li>Storage utilization (size, distribution)</li>\n<li>Peer statistics (count, churn rate)</li>\n</ul>\n<p>The collected metrics can be exported to monitoring systems like Prometheus and visualized in Grafana or other dashboarding tools without requiring custom integration code.</p>\n<h2>Observability Integration</h2>\n<ul>\n<li><strong>OpenTelemetry</strong>: Export compatibility</li>\n<li><strong>Tracing</strong>: Link with distributed traces</li>\n</ul>\n<h2>Performance Considerations</h2>\n<ul>\n<li><p><strong>Low Overhead</strong>:</p>\n<ul>\n<li>Efficient data structures</li>\n<li>Minimal synchronization</li>\n</ul>\n</li>\n<li><p><strong>Cardinality Management</strong>:</p>\n<ul>\n<li>Limit label combinations</li>\n<li>Monitor high-cardinality metrics</li>\n</ul>\n</li>\n</ul>\n<h2>Security</h2>\n<ul>\n<li><p><strong>Secure Export</strong>:</p>\n<ul>\n<li>TLS/SSL</li>\n<li>Authentication (API keys, tokens)</li>\n</ul>\n</li>\n<li><p><strong>Data Privacy</strong>:</p>\n<ul>\n<li>Exclude sensitive data</li>\n</ul>\n</li>\n</ul>\n<h2>Implementation Example</h2>\n<pre><code class=\"language-rust\">use kagi_node::metrics::prelude::*;\n\n// Create a simple counter\nlet requests_counter = Counter::new(&quot;http_requests_total&quot;, &quot;Total HTTP requests&quot;)\n    .with_label(&quot;service&quot;, &quot;api_gateway&quot;)\n    .register();\n\n// Increment the counter\nrequests_counter.increment();\n\n// Create a histogram for response time\nlet response_time = Histogram::new(\n    &quot;http_response_time_seconds&quot;, \n    &quot;HTTP response time in seconds&quot;\n)\n    .with_buckets(vec![0.01, 0.05, 0.1, 0.5, 1.0, 5.0])\n    .register();\n\n// Observe a value\nresponse_time.observe(0.42);\n\n// Create a gauge for concurrent connections\nlet connections = Gauge::new(\n    &quot;active_connections&quot;,\n    &quot;Number of active connections&quot;\n)\n    .register();\n\n// Set the gauge value\nconnections.set(42.0);\n\n// Create a timer for measuring operation duration\nlet operation_timer = Timer::new(\n    &quot;operation_duration_seconds&quot;,\n    &quot;Time to complete operation&quot;\n)\n    .register();\n\n// Use the timer\nlet timer_handle = operation_timer.start();\n// ... perform operation ...\ntimer_handle.stop(); // Automatically records the duration\n\n// Export metrics\nMetricsExporter::new()\n    .format(ExportFormat::OpenMetrics)\n    .protocol(ExportProtocol::Http)\n    .interval(Duration::from_secs(15))\n    .start();\n</code></pre>\n<h2>Service Integration Example</h2>\n<pre><code class=\"language-rust\">use kagi_node::prelude::*;\nuse kagi_node::metrics::prelude::*;\n\nstruct MyService {\n    name: String,\n    path: String,\n    // Service fields...\n    request_counter: Counter,\n    active_requests: Gauge,\n    response_time: Histogram,\n}\n\nimpl MyService {\n    fn new(name: &amp;str) -&gt; Self {\n        // Create metrics\n        let request_counter = Counter::new(&quot;service_requests_total&quot;, &quot;Total service requests&quot;)\n            .with_label(&quot;service&quot;, name)\n            .register();\n            \n        let active_requests = Gauge::new(&quot;service_active_requests&quot;, &quot;Active service requests&quot;)\n            .with_label(&quot;service&quot;, name)\n            .register();\n            \n        let response_time = Histogram::new(&quot;service_response_time_seconds&quot;, &quot;Service response time&quot;)\n            .with_label(&quot;service&quot;, name)\n            .with_buckets(vec![0.01, 0.05, 0.1, 0.5, 1.0])\n            .register();\n            \n        Self {\n            name: name.to_string(),\n            path: name.to_string(),\n            // Initialize other fields...\n            request_counter,\n            active_requests,\n            response_time,\n        }\n    }\n    \n    async fn handle_request(&amp;self, request: &amp;ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n        // Increment request counter\n        self.request_counter.increment();\n        \n        // Increment active requests\n        self.active_requests.increment();\n        \n        // Create timer for response time\n        let timer = self.response_time.start_timer();\n        \n        // Process the request\n        let result = self.process_request_internal(request).await;\n        \n        // Stop timer\n        timer.stop();\n        \n        // Decrement active requests\n        self.active_requests.decrement();\n        \n        result\n    }\n    \n    async fn process_request_internal(&amp;self, request: &amp;ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n        // Actual request processing logic...\n        // ...\n        \n        Ok(ServiceResponse {\n            status: ResponseStatus::Success,\n            message: &quot;Request processed&quot;.to_string(),\n            data: None,\n        })\n    }\n}\n\n#[async_trait]\nimpl AbstractService for MyService {\n    // AbstractService implementation...\n    \n    async fn process_request(&amp;self, request: ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n        self.handle_request(&amp;request).await\n    }\n}\n</code></pre>\n<h2>Integration</h2>\n<h3>P2P Integration</h3>\n<p>The metrics system integrates with the P2P transport layer to collect:</p>\n<ul>\n<li>Connection statistics</li>\n<li>Message flow metrics</li>\n<li>DHT operation metrics</li>\n<li>Network-specific metrics</li>\n</ul>\n<p><strong>Example Integration</strong>:</p>\n<pre><code class=\"language-rust\">impl P2PTransport {\n    async fn handle_message(&amp;self, message: Message) -&gt; Result&lt;(), Error&gt; {\n        let start = Instant::now();\n        let result = self.process_message(message).await;\n        let duration = start.elapsed();\n        \n        // Record metrics\n        self.metrics.record_p2p_message(\n            &amp;message.network_id,\n            &amp;message.peer_id,\n            message.size(),\n            duration\n        );\n        \n        result\n    }\n}\n</code></pre>\n<h2>Examples</h2>\n<p>This section will be expanded with practical examples.</p>\n",
    "path": "/features/metrics"
  },
  "features/keys-management": {
    "html": "<h1>Keys Management Specification</h1>\n<p>This specification defines the key management system for the P2P network, providing secure identities, network participation, and access control. It uses hierarchical deterministic (HD) key derivation for network keys and cryptographic tokens for authentication.</p>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#key-types\">Key Types</a><ul>\n<li><a href=\"#master-key\">Master Key</a></li>\n<li><a href=\"#network-key\">Network Key</a></li>\n<li><a href=\"#peer-key\">Peer Key</a></li>\n</ul>\n</li>\n<li><a href=\"#hd-key-derivation\">HD Key Derivation</a><ul>\n<li><a href=\"#process\">Process</a></li>\n<li><a href=\"#path-format\">Path Format</a></li>\n<li><a href=\"#implementation\">Implementation</a></li>\n</ul>\n</li>\n<li><a href=\"#access-tokens\">Access Tokens</a><ul>\n<li><a href=\"#structure\">Structure</a></li>\n<li><a href=\"#issuance\">Issuance</a></li>\n<li><a href=\"#verification\">Verification</a></li>\n<li><a href=\"#lifecycle\">Lifecycle</a></li>\n</ul>\n</li>\n<li><a href=\"#security-considerations\">Security Considerations</a></li>\n<li><a href=\"#implementation-examples\">Implementation Examples</a></li>\n</ol>\n<h2>Overview</h2>\n<p>The key management system provides:</p>\n<ul>\n<li>Secure identity management for peers and networks</li>\n<li>Hierarchical key derivation for network administration</li>\n<li>Cryptographic access control through tokens</li>\n<li>Integration with P2P transport layer security</li>\n</ul>\n<h2>Key Types</h2>\n<h3>Master Key</h3>\n<ul>\n<li><strong>Type</strong>: Ed25519 key pair</li>\n<li><strong>Purpose</strong>: Root key for network administration</li>\n<li><strong>Usage</strong>: Derives network-specific keys</li>\n<li><strong>Storage</strong>: Must be securely stored offline</li>\n<li><strong>Backup</strong>: Required, using secure backup procedures</li>\n</ul>\n<h3>Network Key</h3>\n<ul>\n<li><strong>Type</strong>: Ed25519 key pair derived from master key</li>\n<li><strong>Purpose</strong>: Identifies and secures individual networks</li>\n<li><strong>Components</strong>:<ul>\n<li><strong>Public Key</strong>: Serves as the NetworkId</li>\n<li><strong>Private Key</strong>: Signs access tokens</li>\n</ul>\n</li>\n<li><strong>Derivation</strong>: Uses HD derivation path</li>\n<li><strong>Management</strong>: One per logical network</li>\n</ul>\n<h3>Peer Key</h3>\n<ul>\n<li><strong>Type</strong>: Ed25519 key pair</li>\n<li><strong>Purpose</strong>: Identifies individual peers</li>\n<li><strong>Components</strong>:<ul>\n<li><strong>Public Key</strong>: Used for authentication</li>\n<li><strong>PeerId</strong>: SHA-256 hash of public key</li>\n</ul>\n</li>\n<li><strong>Generation</strong>: Unique per peer instance</li>\n<li><strong>Storage</strong>: Local to peer, not shared</li>\n</ul>\n<h2>HD Key Derivation</h2>\n<h3>Process</h3>\n<ol>\n<li>Administrator starts with master key</li>\n<li>Derives network keys using standardized paths</li>\n<li>Each derived key represents a separate network</li>\n<li>Public keys become NetworkIds</li>\n</ol>\n<h3>Path Format</h3>\n<pre><code>m/44&#39;/0&#39;/n&#39;\n</code></pre>\n<p>Where:</p>\n<ul>\n<li><code>m</code>: Master key</li>\n<li><code>44&#39;</code>: Purpose (hardened, BIP-44)</li>\n<li><code>0&#39;</code>: Coin type (hardened, generic)</li>\n<li><code>n&#39;</code>: Network index (hardened, 0, 1, 2, etc.)</li>\n</ul>\n<h3>Implementation</h3>\n<pre><code class=\"language-rust\">use ed25519_hd_key::DerivationPath;\n\n// Example key derivation\nfn derive_network_key(master_key: &amp;[u8], network_index: u32) -&gt; Result&lt;Ed25519KeyPair&gt; {\n    let path = format!(&quot;m/44&#39;/0&#39;/{}&#39;&quot;, network_index);\n    let derivation_path = DerivationPath::from_str(&amp;path)?;\n    \n    let derived_key = ed25519_hd_key::derive_key_from_path(\n        master_key,\n        &amp;derivation_path\n    )?;\n    \n    Ok(derived_key)\n}\n</code></pre>\n<h2>Access Tokens</h2>\n<h3>Structure</h3>\n<pre><code class=\"language-rust\">pub struct AccessToken {\n    /// SHA-256 hash of peer&#39;s public key\n    pub peer_id: PeerId,\n    \n    /// Derived network public key\n    pub network_id: NetworkId,\n    \n    /// Optional Unix timestamp for expiration\n    pub expiration: Option&lt;u64&gt;,\n    \n    /// Signature of the above fields with network&#39;s private key\n    pub signature: Vec&lt;u8&gt;,\n    \n    /// Optional capabilities or permissions\n    pub capabilities: Option&lt;Vec&lt;Capability&gt;&gt;,\n}\n\npub enum Capability {\n    Read,\n    Write,\n    Admin,\n    Custom(String),\n}\n</code></pre>\n<h3>Issuance</h3>\n<ol>\n<li>Administrator uses network private key</li>\n<li>Creates token with peer and network info</li>\n<li>Sets expiration and capabilities</li>\n<li>Signs token data</li>\n<li>Distributes to peer securely</li>\n</ol>\n<pre><code class=\"language-rust\">impl AccessToken {\n    pub fn new(\n        peer_id: PeerId,\n        network_id: NetworkId,\n        expiration: Option&lt;u64&gt;,\n        capabilities: Option&lt;Vec&lt;Capability&gt;&gt;,\n        network_key: &amp;Ed25519PrivateKey\n    ) -&gt; Result&lt;Self&gt; {\n        let mut token = Self {\n            peer_id,\n            network_id,\n            expiration,\n            capabilities,\n            signature: Vec::new(),\n        };\n        \n        // Sign token data\n        token.signature = network_key.sign(&amp;token.data_to_sign())?;\n        \n        Ok(token)\n    }\n}\n</code></pre>\n<h3>Verification</h3>\n<ol>\n<li>Peer receives token</li>\n<li>Verifies signature using NetworkId</li>\n<li>Checks expiration time</li>\n<li>Validates capabilities</li>\n<li>Stores for connection handshakes</li>\n</ol>\n<pre><code class=\"language-rust\">impl AccessToken {\n    pub fn verify(&amp;self, network_id: &amp;NetworkId) -&gt; Result&lt;bool&gt; {\n        // Check expiration\n        if let Some(exp) = self.expiration {\n            if exp &lt; current_unix_timestamp() {\n                return Ok(false);\n            }\n        }\n        \n        // Verify signature\n        network_id.verify(\n            &amp;self.data_to_sign(),\n            &amp;self.signature\n        )\n    }\n}\n</code></pre>\n<h3>Lifecycle</h3>\n<ol>\n<li><p><strong>Creation</strong>:</p>\n<ul>\n<li>Generated by network administrator</li>\n<li>Signed with network private key</li>\n<li>Distributed to peer securely</li>\n</ul>\n</li>\n<li><p><strong>Usage</strong>:</p>\n<ul>\n<li>Presented during connection handshake</li>\n<li>Verified by receiving peers</li>\n<li>Cached for session duration</li>\n</ul>\n</li>\n<li><p><strong>Renewal</strong>:</p>\n<ul>\n<li>Before expiration if temporary</li>\n<li>When capabilities change</li>\n<li>On network key rotation</li>\n</ul>\n</li>\n<li><p><strong>Revocation</strong>:</p>\n<ul>\n<li>Through expiration</li>\n<li>Via revocation list in DHT</li>\n<li>By network administrator</li>\n</ul>\n</li>\n</ol>\n<h2>Security Considerations</h2>\n<ol>\n<li><p><strong>Key Storage</strong>:</p>\n<ul>\n<li>Master key must be stored securely offline</li>\n<li>Network private keys require secure storage</li>\n<li>Peer keys stored with appropriate OS security</li>\n</ul>\n</li>\n<li><p><strong>Token Distribution</strong>:</p>\n<ul>\n<li>Use secure channels for token distribution</li>\n<li>Validate token before accepting</li>\n<li>Protect against replay attacks</li>\n</ul>\n</li>\n<li><p><strong>Revocation</strong>:</p>\n<ul>\n<li>Short-lived tokens preferred</li>\n<li>Maintain revocation lists</li>\n<li>Quick revocation mechanism</li>\n</ul>\n</li>\n<li><p><strong>Network Segmentation</strong>:</p>\n<ul>\n<li>Separate networks with different keys</li>\n<li>Limit token capabilities</li>\n<li>Isolate network access</li>\n</ul>\n</li>\n</ol>\n<h2>Implementation Examples</h2>\n<h3>Network Key Generation</h3>\n<pre><code class=\"language-rust\">use ed25519_hd_key::{DerivationPath, KEY_SIZE};\nuse rand::RngCore;\n\nfn generate_master_key() -&gt; Result&lt;[u8; KEY_SIZE]&gt; {\n    let mut key = [0u8; KEY_SIZE];\n    rand::thread_rng().fill_bytes(&amp;mut key);\n    Ok(key)\n}\n\nfn create_network(master_key: &amp;[u8], network_index: u32) -&gt; Result&lt;NetworkKey&gt; {\n    let derived_key = derive_network_key(master_key, network_index)?;\n    NetworkKey::from_ed25519_keypair(derived_key)\n}\n</code></pre>\n<h3>Token Management</h3>\n<pre><code class=\"language-rust\">impl NetworkAdmin {\n    pub async fn issue_token(\n        &amp;self,\n        peer_id: PeerId,\n        capabilities: Vec&lt;Capability&gt;,\n        duration: Duration\n    ) -&gt; Result&lt;AccessToken&gt; {\n        let expiration = Some(\n            SystemTime::now()\n                .checked_add(duration)\n                .unwrap()\n                .duration_since(UNIX_EPOCH)\n                .unwrap()\n                .as_secs()\n        );\n        \n        AccessToken::new(\n            peer_id,\n            self.network_id.clone(),\n            expiration,\n            Some(capabilities),\n            &amp;self.network_key\n        )\n    }\n}\n</code></pre>\n<p>This key management system provides a robust foundation for secure P2P network operations while maintaining flexibility for different network configurations and security requirements.</p>\n<p>Implementation Consideration for our architecture:</p>\n<ol>\n<li><p>some security flow will be implemented using the pub/sub api - anything that a service would need to integrat with the security system</p>\n</li>\n<li><p>some other security flows will need their own mechanism ( a socket, a http server etc) to talk to other components for reasons like: to make it more secure or that the pub/sub api is not available at that stage of the process.</p>\n</li>\n</ol>\n<p>so if the pub/sub api is available at that popint of the process and if there is not security concer, the data flow should gfo thought the pub/sub api meaning,\ninstead of<br>component A -&gt; http request -&gt; component B\nshouod be\ncomponent A -&gt; reqeust or publish event -&gt; componetn B using the kagi framework.</p>\n<p>when things needs to go external and nned to use http or websockets consider using the gateway service that allows to expose actions/events as REST API or the same pub/sub API via websockets ..  consider usign teh gateay before implemeting a custom web server.</p>\n<h2>Examples</h2>\n<p>This section will be expanded with practical examples.</p>\n",
    "path": "/features/keys-management"
  },
  "features/logging": {
    "html": "<h1>Logging System</h1>\n<h2>Overview</h2>\n<p>The Kagi Logging System provides a consistent, context-aware logging interface that works seamlessly in both asynchronous and synchronous code. Through clever use of macros, it eliminates the need to handle <code>.await</code> calls manually while ensuring that contextual information is uniformly included.</p>\n<h2>Key Features</h2>\n<ul>\n<li><strong>Unified API for async/sync contexts</strong>: Same syntax regardless of execution context</li>\n<li><strong>Contextual metadata</strong>: Automatic inclusion of request, node, and network IDs</li>\n<li><strong>Structured logging</strong>: Field-based logging for better filtering and analysis</li>\n<li><strong>ID truncation</strong>: Improved readability while maintaining searchability </li>\n<li><strong>Customizable fields</strong>: Easy addition of custom metadata to log entries</li>\n<li><strong>Log level control</strong>: Fine-grained control over which messages are logged</li>\n</ul>\n<h2>Basic Usage</h2>\n<h3>Simple Logging</h3>\n<p>The logging macros can be used with or without a context:</p>\n<pre><code class=\"language-rust\">// Basic logging with just a message\ninfo!(&quot;Server started on port 8080&quot;);\n\n// Logging with additional fields\ninfo!(&quot;Request processed&quot;, &quot;duration_ms&quot; =&gt; 42, &quot;status&quot; =&gt; &quot;success&quot;);\n\n// Logging with a context object that provides additional metadata\ninfo!(&quot;Handling request&quot;, request_context);\n</code></pre>\n<h3>Context-Aware Logging</h3>\n<p>When a context is provided, relevant metadata is automatically extracted:</p>\n<pre><code class=\"language-rust\">// With a RequestContext, this automatically includes request_id, node_id, etc.\ninfo!(&quot;Processing request&quot;, context);\n\n// Example output:\n// [INFO] [req:a7f3b] [net:d8e2c] [node:c4f1e] Processing request\n</code></pre>\n<h3>Adding Custom Fields</h3>\n<p>Additional fields can be added as key-value pairs:</p>\n<pre><code class=\"language-rust\">info!(&quot;Request processed&quot;, context, \n    &quot;duration_ms&quot; =&gt; 42, \n    &quot;status&quot; =&gt; &quot;success&quot;, \n    &quot;method&quot; =&gt; &quot;GET&quot;\n);\n\n// Example output:\n// [INFO] [req:a7f3b] [net:d8e2c] [node:c4f1e] [duration_ms:42] [status:success] [method:GET] Request processed\n</code></pre>\n<h2>Log Levels</h2>\n<p>The system provides multiple log level macros:</p>\n<pre><code class=\"language-rust\">// Detailed information for debugging\ndebug!(&quot;Connection details&quot;, context, &quot;bytes&quot; =&gt; payload.len());\n\n// Normal operational messages\ninfo!(&quot;Service started successfully&quot;, context);\n\n// Warning conditions\nwarn!(&quot;Retrying failed operation&quot;, context, &quot;attempt&quot; =&gt; retry_count);\n\n// Error conditions\nerror!(&quot;Database connection failed&quot;, context, &quot;reason&quot; =&gt; e.to_string());\n</code></pre>\n<h2>Async vs. Sync Contexts</h2>\n<p>The same logging macros work in both async and sync contexts:</p>\n<h3>In Async Functions</h3>\n<pre><code class=\"language-rust\">async fn process_request(request: Request, context: &amp;RequestContext) -&gt; Result&lt;Response&gt; {\n    info!(&quot;Processing request&quot;, context);\n    \n    // Do async work...\n    \n    info!(&quot;Request completed&quot;, context, &quot;duration_ms&quot; =&gt; duration);\n    Ok(response)\n}\n</code></pre>\n<h3>In Sync Functions</h3>\n<pre><code class=\"language-rust\">fn validate_input(input: &amp;str, context: &amp;RequestContext) -&gt; bool {\n    debug!(&quot;Validating input&quot;, context, &quot;length&quot; =&gt; input.len());\n    \n    // Validate synchronously...\n    \n    let valid = input.len() &gt; 0;\n    debug!(&quot;Validation result&quot;, context, &quot;valid&quot; =&gt; valid);\n    valid\n}\n</code></pre>\n<h2>ID Management</h2>\n<p>IDs are automatically truncated for readability while maintaining full searchability:</p>\n<pre><code class=\"language-rust\">// Log display shows truncated IDs (5 chars)\n// [INFO] [req:a7f3b] [net:d8e2c] [node:c4f1e] Processing request\n\n// But full IDs are included in the log entry for filtering\n// Full IDs: request_id_full:a7f3b291c4e5d6 network_id_full:d8e2c3a4b5c6d7 node_id_full:c4f1e2d3b4a5c6\n</code></pre>\n<h2>Logging Flow</h2>\n<pre><code class=\"language-mermaid\">@include &quot;../assets/images/logging-flow.txt&quot;\n</code></pre>\n<p>The diagram above illustrates how the logging system works:</p>\n<ol>\n<li>The logging macro is called with a message and optional context</li>\n<li>The macro determines if it&#39;s in an async or sync context</li>\n<li>In async contexts, the log operation is spawned as a task</li>\n<li>In sync contexts, a synchronous logging method is used</li>\n<li>Contextual metadata is automatically extracted and formatted</li>\n<li>The formatted log entry is written to the configured output</li>\n</ol>\n<h2>Implementation Details</h2>\n<h3>LogContext Trait</h3>\n<p>The system uses a trait to extract metadata from contexts:</p>\n<pre><code class=\"language-rust\">pub trait LogContext {\n    fn request_id(&amp;self) -&gt; Option&lt;&amp;str&gt; { None }\n    fn network_id(&amp;self) -&gt; Option&lt;&amp;str&gt; { None }\n    fn peer_id(&amp;self) -&gt; Option&lt;&amp;str&gt; { None }\n    fn node_id(&amp;self) -&gt; Option&lt;&amp;str&gt; { None }\n}\n\nimpl LogContext for RequestContext {\n    // Implementations\n}\n</code></pre>\n<h3>Macro Implementation</h3>\n<p>The macros detect whether they&#39;re in an async context and handle accordingly:</p>\n<pre><code class=\"language-rust\">#[macro_export]\nmacro_rules! info {\n    ($message:expr, $context:expr) =&gt; {\n        {\n            let formatted_context = format_context($context);\n            \n            #[cfg(feature = &quot;async&quot;)]\n            {\n                if let Some(runtime) = tokio::runtime::Handle::try_current().ok() {\n                    let _ = runtime.spawn(async {\n                        Logger::global().info($message, formatted_context).await\n                    });\n                } else {\n                    // Fall back to sync logging if not in an async context\n                    Logger::global().info_sync($message, formatted_context);\n                }\n            }\n            \n            #[cfg(not(feature = &quot;async&quot;))]\n            {\n                Logger::global().info_sync($message, formatted_context);\n            }\n        }\n    };\n    \n    // Other variants...\n}\n</code></pre>\n<h2>Best Practices</h2>\n<ol>\n<li><strong>Use appropriate log levels</strong>: Reserve <code>debug!</code> for detailed information and <code>info!</code> for significant events</li>\n<li><strong>Always include context</strong>: Pass relevant context objects to enable proper request tracing</li>\n<li><strong>Add relevant fields</strong>: Include operation-specific data as key-value fields</li>\n<li><strong>Be consistent</strong>: Use similar field names across related operations</li>\n<li><strong>Keep messages concise</strong>: Place details in fields rather than in the message text</li>\n<li><strong>Use structured data</strong>: Avoid embedding JSON or complex data in message strings</li>\n</ol>\n<h2>Configuration</h2>\n<p>Logging can be configured at several levels:</p>\n<h3>Global Configuration</h3>\n<pre><code class=\"language-rust\">// Set global log level\nLogger::global().set_level(LogLevel::Info);\n\n// Configure outputs\nLogger::global().add_output(FileOutput::new(&quot;/var/log/kagi.log&quot;));\nLogger::global().add_output(ConsoleOutput::new());\n\n// Set filter patterns\nLogger::global().add_filter(&quot;req:a7f3b*&quot;, LogLevel::Debug);\n</code></pre>\n<h3>Environment Variables</h3>\n<p>The logging system respects environment variables for dynamic configuration:</p>\n<pre><code># Set default log level\nexport KAGI_LOG_LEVEL=info\n\n# Enable debug logs for specific components\nexport KAGI_LOG_FILTER=&quot;p2p=debug,node=debug&quot;\n\n# Configure output format\nexport KAGI_LOG_FORMAT=&quot;json&quot;\n</code></pre>\n<h2>Integration with Other Systems</h2>\n<p>The logging system integrates with:</p>\n<ul>\n<li><strong>Distributed tracing</strong>: Compatible with OpenTelemetry and Jaeger</li>\n<li><strong>Log aggregation</strong>: Supports structured formats for Elasticsearch/Kibana</li>\n<li><strong>Monitoring systems</strong>: Can emit metrics along with logs</li>\n<li><strong>Cloud environments</strong>: Works with Kubernetes, Docker, and cloud logging services</li>\n</ul>\n<h2>Related Documentation</h2>\n<ul>\n<li><a href=\"context.md\">Context System</a> - How context enables secure and traceable communication</li>\n<li><a href=\"request_handling.md\">Request Handling</a> - Best practices for using logging in request handlers</li>\n<li><a href=\"lifecycle.md\">Service Lifecycle</a> - Understanding service logging during different lifecycle phases</li>\n<li><a href=\"vmap.md\">ValueMap (VMap)</a> - Core abstraction for working with structured data</li>\n</ul>\n",
    "path": "/features/logging"
  },
  "core/context": {
    "html": "<h1>Context System</h1>\n<h2>Overview</h2>\n<p>The Context System is a core component of the Kagi architecture that enables secure and traceable communication between services. This document outlines the design decisions and implementation details of the context system.</p>\n<h2>Context Types</h2>\n<p>Kagi uses two distinct context types to clearly separate concerns:</p>\n<h3>RequestContext</h3>\n<p><code>RequestContext</code> is used for handling service requests and provides:</p>\n<ul>\n<li>Request metadata (request ID, timestamp)</li>\n<li>Methods for nested requests (<code>request</code>, <code>publish</code>, <code>subscribe</code>)</li>\n<li>Request path tracking for debugging</li>\n<li>Parent request information for tracing request chains</li>\n</ul>\n<h3>LifecycleContext</h3>\n<p><code>LifecycleContext</code> is used for service lifecycle operations (init, start, stop) and provides:</p>\n<ul>\n<li>Configuration parameters needed for initialization</li>\n<li>A limited subset of functionality required for lifecycle operations</li>\n<li>Stripped-down interface without request-specific methods</li>\n</ul>\n<h2>Common Context Interface</h2>\n<p>Both context types implement a common interface for shared functionality:</p>\n<pre><code class=\"language-rust\">pub trait AbstractContext {\n    fn node_id(&amp;self) -&gt; &amp;str;\n    fn network_id(&amp;self) -&gt; &amp;str;\n    // Other common methods...\n}\n\nimpl AbstractContext for RequestContext {\n    // Implementation of common methods\n}\n\nimpl AbstractContext for LifecycleContext {\n    // Implementation of common methods\n}\n</code></pre>\n<h2>Request Metadata</h2>\n<p>For nested requests, metadata about the parent request is stored rather than direct object references:</p>\n<pre><code class=\"language-rust\">pub struct RequestMetadata {\n    id: String,        // Unique identifier for the request\n    path: String,      // Full request path\n    operation: String, // Operation being performed\n    timestamp: u64,    // When the request was initiated\n}\n\npub struct RequestContext {\n    // Other fields...\n    parent_request: Option&lt;RequestMetadata&gt;,\n}\n</code></pre>\n<h2>Usage Examples</h2>\n<h3>Creating a Root Request Context</h3>\n<p>A root request is the initial request without a parent:</p>\n<pre><code class=\"language-rust\">// Creating a root request context\nlet context = RequestContext::new(\n    &quot;node-123&quot;,   // Node ID\n    &quot;network-456&quot;, // Network ID\n    None           // No parent request\n);\n\n// Using the context for a request\nlet response = service.request(&quot;some/path&quot;, ValueType::String(&quot;data&quot;.to_string()), &amp;context).await?;\n</code></pre>\n<h3>Creating a Nested Request Context</h3>\n<p>For nested requests (service-to-service communication):</p>\n<pre><code class=\"language-rust\">// Original request context\nlet parent_context = /* ... */;\n\n// Creating a context for a nested request\nlet child_context = RequestContext::new(\n    parent_context.node_id(),\n    parent_context.network_id(),\n    Some(RequestMetadata::from(parent_context))\n);\n\n// The nested request inherits metadata from the parent\nassert_eq!(child_context.parent_request.unwrap().id, parent_context.id());\n</code></pre>\n<h3>Using a Lifecycle Context</h3>\n<p>For service lifecycle operations:</p>\n<pre><code class=\"language-rust\">// Creating a lifecycle context\nlet lifecycle_context = LifecycleContext::new(\n    &quot;node-123&quot;,    // Node ID \n    &quot;network-456&quot;  // Network ID\n);\n\n// Using in service initialization\nservice.init(&amp;lifecycle_context).await?;\n</code></pre>\n<h2>Request Tracing Flow</h2>\n<pre><code class=\"language-mermaid\">@include &quot;../assets/images/request-context-flow.txt&quot;\n</code></pre>\n<p>The diagram above illustrates how request contexts flow through the system:</p>\n<ol>\n<li>A root request arrives with no parent context</li>\n<li>Service A creates a child context when calling Service B</li>\n<li>Service B creates another child context when calling Service C</li>\n<li>Each context maintains a reference to its parent&#39;s metadata</li>\n<li>This enables full request tracing through the entire call chain</li>\n</ol>\n<h2>Key Benefits</h2>\n<ol>\n<li><strong>Clear separation of concerns</strong>: Different context types for different operations</li>\n<li><strong>Simplified API</strong>: Each context type only provides what&#39;s needed</li>\n<li><strong>Complete request tracing</strong>: Full parent-child relationship tracking</li>\n<li><strong>Type safety</strong>: Compiler enforces correct context usage</li>\n<li><strong>Improved testability</strong>: Services can be tested with appropriate context types</li>\n</ol>\n<h2>Best Practices</h2>\n<ol>\n<li><strong>Always pass the context</strong>: Never create a new context unless starting a new request chain</li>\n<li><strong>Use the right context type</strong>: Use RequestContext for requests and LifecycleContext for lifecycle operations</li>\n<li><strong>Don&#39;t modify context objects</strong>: Treat contexts as immutable after creation</li>\n<li><strong>Preserve request chains</strong>: When making nested requests, always pass parent metadata</li>\n<li><strong>Add relevant context fields</strong>: Use context-aware logging to aid in debugging</li>\n</ol>\n<h2>Implementation Details</h2>\n<p>The context system implementation ensures:</p>\n<ul>\n<li>Thread safety through the use of Arc/Mutex where needed</li>\n<li>Efficient context creation with minimal overhead</li>\n<li>Proper error propagation through context chains</li>\n<li>Serialization support for distributed tracing</li>\n<li>Integration with the logging system</li>\n</ul>\n<h2>Related Documentation</h2>\n<ul>\n<li><a href=\"lifecycle.md\">Service Lifecycle</a> - Understanding how context is used throughout the service lifecycle</li>\n<li><a href=\"request_handling.md\">Request Handling</a> - Best practices for using context in request handlers</li>\n<li><a href=\"logging.md\">Logging System</a> - How context integrates with the logging system</li>\n<li><a href=\"vmap.md\">ValueMap (VMap)</a> - Working with structured data using VMap</li>\n</ul>\n",
    "path": "/core/context"
  },
  "core/lifecycle": {
    "html": "<h1>Service Lifecycle</h1>\n<h2>Overview</h2>\n<p>This document outlines the lifecycle of services in Kagi, focusing on proper initialization, operation, and shutdown. Following these lifecycle best practices ensures reliable service behavior, efficient resource usage, and predictable interactions between services.</p>\n<h2>Service States</h2>\n<p>A Kagi service transitions through several states during its lifecycle:</p>\n<ol>\n<li><strong>Created</strong>: Initial state when a service instance is constructed</li>\n<li><strong>Initialized</strong>: Service has completed its initialization and is ready to start</li>\n<li><strong>Running</strong>: Service is actively processing requests</li>\n<li><strong>Stopped</strong>: Service has been gracefully stopped</li>\n<li><strong>Failed</strong>: Service encountered an error during its lifecycle</li>\n</ol>\n<pre><code class=\"language-mermaid\">stateDiagram-v2\n    [*] --&gt; Created\n    Created --&gt; Initialized : init()\n    Initialized --&gt; Running : start()\n    Running --&gt; Stopped : stop()\n    Created --&gt; Failed : init() error\n    Initialized --&gt; Failed : start() error\n    Running --&gt; Failed : runtime error\n    Stopped --&gt; [*]\n    Failed --&gt; [*]\n</code></pre>\n<h2>Lifecycle Methods</h2>\n<h3>Constructor</h3>\n<p>The constructor creates a new service instance with minimal setup:</p>\n<pre><code class=\"language-rust\">fn new(name: &amp;str) -&gt; Self {\n    Self {\n        name: name.to_string(),\n        path: name.to_string(),\n        state: Mutex::new(ServiceState::Created),\n        // Initialize other fields\n    }\n}\n</code></pre>\n<p><strong>Best Practices</strong>:</p>\n<ul>\n<li>Keep constructors lightweight</li>\n<li>Only initialize fields that don&#39;t depend on context</li>\n<li>Don&#39;t perform I/O operations or network calls</li>\n<li>Don&#39;t acquire locks or resources</li>\n</ul>\n<h3>init</h3>\n<p>The <code>init</code> method performs all necessary initialization before the service can start running:</p>\n<pre><code class=\"language-rust\">async fn init(&amp;mut self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n    info!(&quot;Initializing service&quot;, context);\n    \n    // Set up subscriptions during initialization\n    self.setup_subscriptions(context).await?;\n    \n    // Initialize resources\n    self.connect_to_database(context).await?;\n    \n    // Update service state\n    *self.state.lock().await = ServiceState::Initialized;\n    \n    Ok(())\n}\n</code></pre>\n<p><strong>Best Practices</strong>:</p>\n<ul>\n<li>Always set up subscriptions in the <code>init</code> method, not during request handling</li>\n<li>Initialize all resources needed by the service</li>\n<li>Update the service state to <code>Initialized</code> at the end of successful initialization</li>\n<li>Log initialization steps for debugging</li>\n<li>Handle errors appropriately</li>\n</ul>\n<h3>start</h3>\n<p>The <code>start</code> method transitions the service from <code>Initialized</code> to <code>Running</code>:</p>\n<pre><code class=\"language-rust\">async fn start(&amp;mut self) -&gt; Result&lt;()&gt; {\n    info!(&quot;Starting service&quot;, context = None);\n    \n    // Start any background tasks\n    self.start_background_workers().await?;\n    \n    // Update service state\n    *self.state.lock().await = ServiceState::Running;\n    \n    Ok(())\n}\n</code></pre>\n<p><strong>Best Practices</strong>:</p>\n<ul>\n<li>Only start background tasks or workers in this method</li>\n<li>Keep the method quick and focused</li>\n<li>Don&#39;t perform long-running operations</li>\n<li>Update the service state to <code>Running</code> at the end</li>\n</ul>\n<h3>stop</h3>\n<p>The <code>stop</code> method gracefully stops the service:</p>\n<pre><code class=\"language-rust\">async fn stop(&amp;mut self) -&gt; Result&lt;()&gt; {\n    info!(&quot;Stopping service&quot;, context = None);\n    \n    // Stop any background tasks\n    self.stop_background_workers().await?;\n    \n    // Release resources\n    self.close_database_connections().await?;\n    \n    // Update service state\n    *self.state.lock().await = ServiceState::Stopped;\n    \n    Ok(())\n}\n</code></pre>\n<p><strong>Best Practices</strong>:</p>\n<ul>\n<li>Clean up all resources acquired during initialization</li>\n<li>Stop all background tasks</li>\n<li>Close connections</li>\n<li>Wait for tasks to complete when appropriate</li>\n<li>Update the service state to <code>Stopped</code> at the end</li>\n</ul>\n<h2>Subscription Setup</h2>\n<h3>Best Practice: Setup During Initialization</h3>\n<p>Subscriptions should always be set up during the service&#39;s <code>init</code> method:</p>\n<pre><code class=\"language-rust\">async fn init(&amp;mut self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n    info!(&quot;Initializing MyService&quot;, context);\n    \n    // Set up subscriptions during initialization\n    self.setup_subscriptions(context).await?;\n    \n    // Update service state\n    *self.state.lock().await = ServiceState::Initialized;\n    \n    Ok(())\n}\n\nasync fn setup_subscriptions(&amp;self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n    // Set up all required subscriptions\n    context.subscribe(&quot;topic/one&quot;, |payload| { /* handler */ }).await?;\n    context.subscribe(&quot;topic/two&quot;, |payload| { /* handler */ }).await?;\n    \n    Ok(())\n}\n</code></pre>\n<p><strong>Benefits of this approach</strong>:</p>\n<ol>\n<li>Cleaner, more predictable service lifecycle</li>\n<li>Better performance (no lock overhead during request handling)</li>\n<li>Subscriptions are guaranteed to be set up before any requests are processed</li>\n<li>Avoids potential race conditions and duplicate subscriptions</li>\n<li>Makes the service&#39;s dependencies and requirements clear</li>\n</ol>\n<h3>Anti-Pattern: Subscription Setup During Request Handling</h3>\n<p>Never set up or validate subscriptions during request handling:</p>\n<pre><code class=\"language-rust\">// ANTI-PATTERN: Don&#39;t do this\nasync fn handle_request(&amp;self, request: ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n    // Bad practice: Setting up or checking subscriptions during request handling\n    self.ensure_subscriptions(&amp;request.request_context).await?;\n    \n    // Rest of request handling...\n}\n</code></pre>\n<p><strong>Why this is problematic</strong>:</p>\n<ol>\n<li>Adds unnecessary overhead to every request</li>\n<li>Creates potential thread contention on the lock</li>\n<li>Violates the principle that initialization should happen during service init</li>\n<li>Could lead to race conditions or duplicate subscriptions</li>\n<li>Makes the service behavior less predictable</li>\n</ol>\n<h2>Event Handlers</h2>\n<p>When setting up event handlers in the <code>setup_subscriptions</code> method, follow these best practices:</p>\n<ol>\n<li><p><strong>Clone the service for closures</strong>:</p>\n<pre><code class=\"language-rust\">let self_clone = Arc::new(self.clone());\n</code></pre>\n</li>\n<li><p><strong>Use specific clones for each handler</strong>:</p>\n<pre><code class=\"language-rust\">let self_valid = self_clone.clone();\n</code></pre>\n</li>\n<li><p><strong>Process events asynchronously</strong>:</p>\n<pre><code class=\"language-rust\">tokio::spawn(async move {\n    self_valid.handle_valid_event(json_value).await;\n});\n</code></pre>\n</li>\n<li><p><strong>Handle different payload formats</strong>:</p>\n<pre><code class=\"language-rust\">if let ValueType::Json(json_value) = payload {\n    // Handle JSON\n} else if let ValueType::Map(map_value) = payload {\n    // Handle Map\n} else {\n    // Handle other formats\n}\n</code></pre>\n</li>\n<li><p><strong>Log event handling</strong>:</p>\n<pre><code class=\"language-rust\">debug!(&quot;Received event on topic&quot;, \n    &quot;topic&quot; =&gt; topic,\n    &quot;payload_type&quot; =&gt; format!(&quot;{:?}&quot;, payload)\n);\n</code></pre>\n</li>\n</ol>\n<h2>Lifecycle Context</h2>\n<p>For initialization that depends on the service&#39;s lifecycle, use the <code>LifecycleContext</code>:</p>\n<pre><code class=\"language-rust\">fn with_lifecycle_context&lt;F, R&gt;(&amp;self, f: F) -&gt; R\nwhere\n    F: FnOnce(&amp;LifecycleContext) -&gt; R,\n{\n    let context = LifecycleContext::new(self.name(), self.path());\n    f(&amp;context)\n}\n</code></pre>\n<p>This provides a context for operations that occur during the service lifecycle but outside of request handling.</p>\n<h2>Common Anti-Patterns</h2>\n<h3>1. Late Initialization</h3>\n<p><strong>Anti-Pattern</strong>: Deferring initialization tasks until a request arrives:</p>\n<pre><code class=\"language-rust\">// ANTI-PATTERN: Late initialization in request handling\nasync fn handle_request(&amp;self, request: ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n    if self.database.lock().await.is_none() {\n        self.initialize_database().await?;\n    }\n    // ...\n}\n</code></pre>\n<p><strong>Best Practice</strong>: Initialize everything in the <code>init</code> method:</p>\n<pre><code class=\"language-rust\">async fn init(&amp;mut self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n    self.initialize_database().await?;\n    // ...\n}\n</code></pre>\n<h3>2. Subscription Validation During Request Handling</h3>\n<p><strong>Anti-Pattern</strong>: Checking if subscriptions are set up during request handling:</p>\n<pre><code class=\"language-rust\">// ANTI-PATTERN: Don&#39;t do this\nasync fn ensure_subscriptions(&amp;self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n    let setup = self.subscriptions_setup.lock().await;\n    if !*setup {\n        drop(setup); // Release the lock before calling setup_subscriptions\n        self.setup_subscriptions(context).await?;\n    }\n    Ok(())\n}\n</code></pre>\n<p><strong>Best Practice</strong>: Set up all subscriptions during initialization and avoid any checks during request handling.</p>\n<h3>3. State Mutation During Request Handling</h3>\n<p><strong>Anti-Pattern</strong>: Changing the service state during request handling:</p>\n<pre><code class=\"language-rust\">// ANTI-PATTERN: Don&#39;t change service state during request handling\nasync fn handle_request(&amp;self, request: ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n    *self.state.lock().await = ServiceState::Running; // Bad practice\n    // ...\n}\n</code></pre>\n<p><strong>Best Practice</strong>: Only change service state in lifecycle methods (<code>init</code>, <code>start</code>, <code>stop</code>).</p>\n<h2>Related Documentation</h2>\n<ul>\n<li><a href=\"context.md\">Context System</a> - How to use the context system effectively</li>\n<li><a href=\"request_handling.md\">Request Handling</a> - Best practices for handling service requests</li>\n<li><a href=\"logging.md\">Logging System</a> - Context-aware logging practices</li>\n</ul>\n",
    "path": "/core/lifecycle"
  },
  "core/request_handling": {
    "html": "<h1>Request Handling Best Practices</h1>\n<h2>Overview</h2>\n<p>This document outlines best practices for handling service requests in Kagi. Following these guidelines ensures consistent, maintainable, and performant service implementations.</p>\n<h2>Service Request Handling</h2>\n<h3>The <code>handle_request</code> Method</h3>\n<p>The <code>handle_request</code> method is the main entry point for all service requests. This method replaced the deprecated <code>process_request</code> method and follows a clear pattern:</p>\n<pre><code class=\"language-rust\">async fn handle_request(&amp;self, request: ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n    // 1. Log the incoming request\n    debug!(&quot;Handling request&quot;, &amp;request.request_context, \n        &quot;operation&quot; =&gt; &amp;request.operation,\n        &quot;path&quot; =&gt; &amp;request.path\n    );\n    \n    // 2. Match on the operation and delegate to specialized methods\n    match request.operation.as_str() {\n        &quot;operation1&quot; =&gt; self.handle_operation1(request).await,\n        &quot;operation2&quot; =&gt; self.handle_operation2(request).await,\n        _ =&gt; {\n            warn!(&quot;Unknown operation&quot;, &amp;request.request_context, \n                &quot;operation&quot; =&gt; &amp;request.operation\n            );\n            Ok(ServiceResponse {\n                status: ResponseStatus::Error,\n                message: format!(&quot;Unknown operation: {}&quot;, request.operation),\n                data: None,\n            })\n        }\n    }\n}\n</code></pre>\n<p><strong>Key principles</strong>:</p>\n<ol>\n<li>The <code>handle_request</code> method should be <strong>simple</strong> and focused on <strong>routing</strong> requests</li>\n<li>It should <strong>delegate</strong> to specialized methods for each operation</li>\n<li>It should <strong>not</strong> contain complex business logic</li>\n<li>It should provide appropriate <strong>logging</strong> for request tracking</li>\n</ol>\n<h3>Operation-Specific Methods</h3>\n<p>Each operation should have a dedicated handler method:</p>\n<pre><code class=\"language-rust\">// Example operation handler\nasync fn handle_operation1(&amp;self, request: ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n    // Extract parameters\n    let params = self.extract_parameters(request.params)?;\n    \n    // Process the request\n    let result = self.process_data(params).await?;\n    \n    // Return response\n    Ok(ServiceResponse {\n        status: ResponseStatus::Success,\n        message: &quot;Operation completed successfully&quot;.to_string(),\n        data: Some(result),\n    })\n}\n</code></pre>\n<h2>Service Lifecycle Concerns</h2>\n<h3>Anti-Pattern: Subscription Setup During Request Handling</h3>\n<p>A common anti-pattern is setting up subscriptions during request handling instead of during initialization:</p>\n<pre><code class=\"language-rust\">// ANTI-PATTERN: Don&#39;t do this\nasync fn handle_request(&amp;self, request: ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n    // Bad practice: Setting up or checking subscriptions during request handling\n    self.ensure_subscriptions(&amp;request.request_context).await?;\n    \n    // Rest of request handling...\n}\n\n// ANTI-PATTERN: Don&#39;t do this either\nasync fn ensure_subscriptions(&amp;self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n    let setup = self.subscriptions_setup.lock().await;\n    if !*setup {\n        drop(setup); // Release the lock before calling setup_subscriptions\n        self.setup_subscriptions(context).await?;\n    }\n    Ok(())\n}\n</code></pre>\n<p><strong>Why this is problematic:</strong></p>\n<ol>\n<li>Adds unnecessary overhead to every request (acquiring/checking a lock)</li>\n<li>Creates potential thread contention on the lock</li>\n<li>Violates the principle that initialization should happen during service init</li>\n<li>Could lead to race conditions or duplicate subscriptions</li>\n<li>Makes the service behavior less predictable</li>\n</ol>\n<h3>Best Practice: Setup During Initialization</h3>\n<p>Instead, always set up subscriptions during the service&#39;s <code>init</code> method:</p>\n<pre><code class=\"language-rust\">// GOOD PRACTICE: Do this\nasync fn init(&amp;mut self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n    info!(&quot;Initializing MyService&quot;, context);\n    \n    // Set up subscriptions during initialization\n    self.setup_subscriptions(context).await?;\n    \n    // Update service state\n    *self.state.lock().await = ServiceState::Initialized;\n    \n    Ok(())\n}\n\n// No &quot;ensure&quot; method needed - init is called exactly once\nasync fn setup_subscriptions(&amp;self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n    // Set up all required subscriptions\n    context.subscribe(&quot;topic/one&quot;, |payload| { /* handler */ }).await?;\n    context.subscribe(&quot;topic/two&quot;, |payload| { /* handler */ }).await?;\n    \n    Ok(())\n}\n</code></pre>\n<p><strong>Benefits of this approach:</strong></p>\n<ol>\n<li>Cleaner, more predictable service lifecycle</li>\n<li>Better performance (no lock overhead during request handling)</li>\n<li>Subscriptions are guaranteed to be set up before any requests are processed</li>\n<li>Avoids potential race conditions and duplicate subscriptions</li>\n<li>Makes the service&#39;s dependencies and requirements clear</li>\n</ol>\n<h2>Data Format Best Practices</h2>\n<h3>JSON vs VMap Usage</h3>\n<p>Follow these guidelines when working with JSON and VMap:</p>\n<ol>\n<li><strong>Minimize Conversions</strong>: Avoid unnecessary conversions between data formats</li>\n<li><strong>Preserve Original Format</strong>: If data arrives as JSON, keep it as JSON; if it&#39;s a Map/VMap, keep it as VMap</li>\n<li><strong>Choose Appropriate Tools</strong>: Use the right tools for the data format you have</li>\n</ol>\n<h3>Examples:</h3>\n<h4>Good Practice - Handling JSON Input:</h4>\n<pre><code class=\"language-rust\">// When input is already JSON, work with it directly\nif let Some(ValueType::Json(json_data)) = &amp;request.params {\n    // Access JSON fields directly\n    let name = json_data.get(&quot;name&quot;)\n        .and_then(|v| v.as_str())\n        .unwrap_or(&quot;default&quot;);\n        \n    // Process with the JSON data\n    // ...\n}\n</code></pre>\n<h4>Good Practice - Handling Map/VMap Input:</h4>\n<pre><code class=\"language-rust\">// When input is a Map, use VMap for type-safe extraction\nif let Some(ValueType::Map(map_data)) = &amp;request.params {\n    let vmap = VMap::from_hashmap(map_data.clone());\n    \n    // Extract typed values\n    let name: String = vmap!(vmap, &quot;name&quot;, String)?;\n    let count: i32 = vmap!(vmap, &quot;count&quot;, Int)?;\n    \n    // Process with the extracted values\n    // ...\n}\n</code></pre>\n<h4>Bad Practice - Unnecessary Conversion:</h4>\n<pre><code class=\"language-rust\">// DON&#39;T DO THIS: Converting JSON to VMap unnecessarily\nif let Some(ValueType::Json(json_data)) = &amp;request.params {\n    // Unnecessary conversion from JSON to VMap\n    let vmap = VMap::from_json(json_data.clone());\n    \n    // Now extracting with VMap macros\n    let name: String = vmap!(vmap, &quot;name&quot;, String)?;\n    \n    // ...\n}\n</code></pre>\n<h2>Context-Aware Logging</h2>\n<p>Always use the context-aware logging system with appropriate log levels:</p>\n<pre><code class=\"language-rust\">// Debug level for detailed information\ndebug!(&quot;Processing request details&quot;, &amp;request.request_context, \n    &quot;key1&quot; =&gt; &amp;value1,\n    &quot;key2&quot; =&gt; &amp;value2\n);\n\n// Info level for normal operational messages\ninfo!(&quot;Operation completed&quot;, &amp;request.request_context, \n    &quot;duration_ms&quot; =&gt; duration\n);\n\n// Warning level for concerning but non-critical issues\nwarn!(&quot;Resource usage high&quot;, &amp;request.request_context, \n    &quot;memory_usage&quot; =&gt; memory_mb\n);\n\n// Error level for failures\nerror!(&quot;Operation failed&quot;, &amp;request.request_context, \n    &quot;reason&quot; =&gt; &amp;error_message\n);\n</code></pre>\n<h2>Backward Compatibility</h2>\n<p>For backward compatibility, implement <code>process_request</code> to delegate to <code>handle_request</code>:</p>\n<pre><code class=\"language-rust\">#[allow(deprecated)]\nasync fn process_request(&amp;self, request: ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n    // Delegate to handle_request for backward compatibility\n    self.handle_request(request).await\n}\n</code></pre>\n<h2>Implementation Checklist</h2>\n<ul>\n<li><input disabled=\"\" type=\"checkbox\"> <code>handle_request</code> method is simple and delegates to specialized methods</li>\n<li><input disabled=\"\" type=\"checkbox\"> Each operation has a dedicated handler method</li>\n<li><input disabled=\"\" type=\"checkbox\"> Data format conversions are minimized</li>\n<li><input disabled=\"\" type=\"checkbox\"> Context-aware logging is used throughout</li>\n<li><input disabled=\"\" type=\"checkbox\"> Backward compatibility with <code>process_request</code> is maintained</li>\n<li><input disabled=\"\" type=\"checkbox\"> Error handling is consistent and informative</li>\n<li><input disabled=\"\" type=\"checkbox\"> Service metadata accurately lists all supported operations</li>\n<li><input disabled=\"\" type=\"checkbox\"> Subscriptions are set up during service initialization, not during request handling</li>\n<li><input disabled=\"\" type=\"checkbox\"> No <code>ensure_subscriptions</code> checks are performed during request handling</li>\n</ul>\n<h2>Related Documentation</h2>\n<ul>\n<li><a href=\"context.md\">Context System</a> - How to use the context system effectively</li>\n<li><a href=\"vmap.md\">ValueMap (VMap)</a> - Working with structured data using VMap</li>\n<li><a href=\"logging.md\">Logging System</a> - Context-aware logging practices</li>\n<li><a href=\"lifecycle.md\">Service Lifecycle</a> - Understanding the service lifecycle and initialization best practices</li>\n</ul>\n",
    "path": "/core/request_handling"
  },
  "core/system-diagrams": {
    "html": "<h1>Kagi Node System Diagrams</h1>\n<p>This document provides a comprehensive collection of system diagrams illustrating the various flows and interactions within the Kagi node system.</p>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#sequence-diagrams\">Sequence Diagrams</a><ul>\n<li><a href=\"#local-service-request\">Local Service Request</a></li>\n<li><a href=\"#remote-service-request\">Remote Service Request</a></li>\n<li><a href=\"#p2p-discovery-and-connection\">P2P Discovery and Connection</a></li>\n<li><a href=\"#event-publication\">Event Publication</a></li>\n<li><a href=\"#service-subscription-setup\">Service Subscription Setup</a></li>\n<li><a href=\"#dht-operations\">DHT Operations</a></li>\n<li><a href=\"#service-lifecycle\">Service Lifecycle</a></li>\n<li><a href=\"#network-authentication\">Network Authentication</a></li>\n</ul>\n</li>\n<li><a href=\"#flow-diagrams\">Flow Diagrams</a><ul>\n<li><a href=\"#request-processing\">Request Processing</a></li>\n<li><a href=\"#service-initialization\">Service Initialization</a></li>\n<li><a href=\"#p2p-message-routing\">P2P Message Routing</a></li>\n<li><a href=\"#cache-operations\">Cache Operations</a></li>\n<li><a href=\"#event-distribution\">Event Distribution</a></li>\n<li><a href=\"#discovery-process\">Discovery Process</a></li>\n<li><a href=\"#security-flow\">Security Flow</a></li>\n<li><a href=\"#service-communication\">Service Communication</a></li>\n</ul>\n</li>\n</ol>\n<h2>Sequence Diagrams</h2>\n<h3>Local Service Request</h3>\n<p>Shows the flow of a request to a local service.</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant C as Client\n    participant G as Gateway\n    participant SR as ServiceRegistry\n    participant S as Service\n\n    C-&gt;&gt;G: HTTP Request\n    G-&gt;&gt;SR: Lookup Service\n    SR--&gt;&gt;G: Return Service Reference\n    G-&gt;&gt;S: Forward Request\n    Note over S: Process Request\n    S--&gt;&gt;G: Return Response\n    G--&gt;&gt;C: HTTP Response\n</code></pre>\n<h3>Remote Service Request</h3>\n<p>Illustrates how requests are handled when the target service is on a remote peer.</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant C as Client\n    participant G as Gateway\n    participant SR as ServiceRegistry\n    participant P2P as P2PTransport\n    participant RP as RemotePeer\n    participant RS as RemoteService\n\n    C-&gt;&gt;G: HTTP Request\n    G-&gt;&gt;SR: Lookup Service\n    SR-&gt;&gt;P2P: Find Remote Service\n    P2P-&gt;&gt;RP: Service Discovery Request\n    RP--&gt;&gt;P2P: Service Info Response\n    P2P-&gt;&gt;RS: Forward Request\n    Note over RS: Process Request\n    RS--&gt;&gt;P2P: Return Response\n    P2P--&gt;&gt;G: Forward Response\n    G--&gt;&gt;C: HTTP Response\n</code></pre>\n<h3>P2P Discovery and Connection</h3>\n<p>Shows how peers discover and establish connections with each other.</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant P1 as Peer1\n    participant M as Multicast\n    participant P2 as Peer2\n    participant DHT as DHTNetwork\n\n    P1-&gt;&gt;M: Send Discovery Message\n    Note right of M: Contains PeerId, NetworkId, Token\n    P2-&gt;&gt;M: Receive Discovery Message\n    Note over P2: Validate Token\n    P2-&gt;&gt;P1: QUIC Connection Request\n    Note over P1: Validate Token\n    P1--&gt;&gt;P2: Connection Accept\n    P1-&gt;&gt;P2: Exchange Service Directory\n    P2-&gt;&gt;P1: Exchange Service Directory\n    P1-&gt;&gt;DHT: Announce Services\n    P2-&gt;&gt;DHT: Announce Services\n</code></pre>\n<h3>Event Publication</h3>\n<p>Demonstrates how events are published and distributed across the network.</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant S as Service\n    participant SR as ServiceRegistry\n    participant LS as LocalSubscribers\n    participant P2P as P2PTransport\n    participant RP1 as RemotePeer1\n    participant RP2 as RemotePeer2\n    participant LS1 as LocalServices1\n    participant LS2 as LocalServices2\n\n    S-&gt;&gt;SR: Publish Event\n    SR-&gt;&gt;LS: Notify Local Subscribers\n    SR-&gt;&gt;P2P: Forward to Network\n    P2P-&gt;&gt;RP1: Forward Event\n    P2P-&gt;&gt;RP2: Forward Event\n    RP1-&gt;&gt;LS1: Notify Local Subscribers\n    RP2-&gt;&gt;LS2: Notify Local Subscribers\n</code></pre>\n<h3>Service Subscription Setup</h3>\n<p>Shows how services set up their subscriptions during initialization.</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant S as Service\n    participant SR as ServiceRegistry\n    participant P2P as P2PTransport\n    participant RP as RemotePeers\n\n    Note over S: Service Initialization\n    S-&gt;&gt;SR: Register Service\n    S-&gt;&gt;SR: Subscribe to Topics\n    SR-&gt;&gt;P2P: Propagate Subscriptions\n    P2P-&gt;&gt;RP: Broadcast Subscription Info\n    Note over RP: Store Remote Subscriptions\n    RP--&gt;&gt;P2P: Acknowledge\n    P2P--&gt;&gt;SR: Update Remote Subscription Table\n    Note over SR: Ready for Event Distribution\n</code></pre>\n<h3>DHT Operations</h3>\n<p>Illustrates how DHT operations are processed.</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant S as Service\n    participant P2P as P2PTransport\n    participant DHT as DHTNetwork\n    participant RP as RemotePeers\n\n    S-&gt;&gt;P2P: DHT Put Request\n    P2P-&gt;&gt;DHT: Find Closest Peers\n    DHT--&gt;&gt;P2P: Return Peer List\n    P2P-&gt;&gt;RP: Store Value Request\n    Note over RP: Validate &amp; Store\n    RP--&gt;&gt;P2P: Acknowledge Storage\n    P2P--&gt;&gt;S: Operation Complete\n\n    S-&gt;&gt;P2P: DHT Get Request\n    P2P-&gt;&gt;DHT: Find Value\n    DHT-&gt;&gt;RP: Query Value\n    RP--&gt;&gt;DHT: Return Value\n    DHT--&gt;&gt;P2P: Return Result\n    P2P--&gt;&gt;S: Return Value\n</code></pre>\n<h3>Service Lifecycle</h3>\n<p>Shows the different states a service can be in.</p>\n<pre><code class=\"language-mermaid\">stateDiagram-v2\n    [*] --&gt; Created\n    Created --&gt; Initialized: init()\n    Initialized --&gt; Running: start()\n    Running --&gt; Paused: pause()\n    Paused --&gt; Running: resume()\n    Running --&gt; Stopped: stop()\n    Paused --&gt; Stopped: stop()\n    Stopped --&gt; [*]\n\n    note right of Created: Service object constructed\n    note right of Initialized: Subscriptions setup\n    note right of Running: Processing requests\n    note right of Paused: Temporary suspension\n    note right of Stopped: Cleanup complete\n</code></pre>\n<h3>Network Authentication</h3>\n<p>Shows the authentication process between peers.</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant P1 as Peer1\n    participant P2 as Peer2\n    participant DHT as DHTNetwork\n\n    P1-&gt;&gt;P2: Connection Request\n    Note over P1,P2: Include AccessToken\n    P2-&gt;&gt;DHT: Verify NetworkId\n    DHT--&gt;&gt;P2: Network Info\n    Note over P2: Validate Token\n    alt Token Valid\n        P2--&gt;&gt;P1: Connection Accepted\n        P1-&gt;&gt;P2: Begin Service Discovery\n    else Token Invalid\n        P2--&gt;&gt;P1: Connection Rejected\n    end\n</code></pre>\n<h2>Flow Diagrams</h2>\n<h3>Request Processing</h3>\n<p>Shows how requests are processed through the system.</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Client Request] --&gt; B{Local Service?}\n    B --&gt;|Yes| C[Get Service Reference]\n    B --&gt;|No| D[P2P Lookup]\n    \n    C --&gt; E[Validate Request]\n    D --&gt; E\n    \n    E --&gt; F{Valid?}\n    F --&gt;|No| G[Return Error]\n    F --&gt;|Yes| H[Process Request]\n    \n    H --&gt; I{Cacheable?}\n    I --&gt;|Yes| J[Store in Cache]\n    I --&gt;|No| K[Return Response]\n    J --&gt; K\n    \n    K --&gt; L[Record Metrics]\n    L --&gt; M[Send Response]\n</code></pre>\n<h3>Service Initialization</h3>\n<p>Illustrates the initialization process of a service.</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Service Creation] --&gt; B[Load Configuration]\n    B --&gt; C[Initialize State]\n    \n    C --&gt; D[Setup Metrics]\n    D --&gt; E[Setup Cache]\n    \n    E --&gt; F{P2P Enabled?}\n    F --&gt;|Yes| G[Setup P2P]\n    F --&gt;|No| H[Local Only Setup]\n    \n    G --&gt; I[Register Subscriptions]\n    H --&gt; I\n    \n    I --&gt; J[Register Actions]\n    J --&gt; K{All Setup Complete?}\n    \n    K --&gt;|Yes| L[Mark as Initialized]\n    K --&gt;|No| M[Cleanup]\n    M --&gt; N[Return Error]\n</code></pre>\n<h3>P2P Message Routing</h3>\n<p>Shows how messages are routed in the P2P network.</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Incoming Message] --&gt; B{Message Type?}\n    \n    B --&gt;|Request| C[Validate Token]\n    B --&gt;|Event| D[Check Subscriptions]\n    B --&gt;|DHT| E[Process DHT Op]\n    \n    C --&gt; F{Token Valid?}\n    F --&gt;|Yes| G[Route to Service]\n    F --&gt;|No| H[Reject Message]\n    \n    D --&gt; I{Has Subscribers?}\n    I --&gt;|Yes| J[Notify Subscribers]\n    I --&gt;|No| K[Check Forward Rules]\n    \n    E --&gt; L{Operation Type?}\n    L --&gt;|Get| M[Find Value]\n    L --&gt;|Put| N[Store Value]\n    L --&gt;|Find Node| O[Return Closest]\n</code></pre>\n<h3>Cache Operations</h3>\n<p>Illustrates the flow of cache operations.</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Cache Operation] --&gt; B{Operation Type?}\n    \n    B --&gt;|Get| C[Check Local Cache]\n    B --&gt;|Set| D[Validate Data]\n    B --&gt;|Delete| E[Remove Entry]\n    \n    C --&gt; F{Cache Hit?}\n    F --&gt;|Yes| G[Return Cached]\n    F --&gt;|No| H{Using DHT?}\n    \n    H --&gt;|Yes| I[Query DHT]\n    H --&gt;|No| J[Return Miss]\n    \n    D --&gt; K{Backend Type?}\n    K --&gt;|Memory| L[Store Local]\n    K --&gt;|Redis| M[Store Redis]\n    K --&gt;|DHT| N[Store DHT]\n    \n    N --&gt; O[Setup Replication]\n</code></pre>\n<h3>Event Distribution</h3>\n<p>Shows how events are distributed through the system.</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Event Published] --&gt; B[Check Topic]\n    \n    B --&gt; C{Scope?}\n    C --&gt;|Local| D[Local Distribution]\n    C --&gt;|Network| E[Network Distribution]\n    C --&gt;|Global| F[Global Distribution]\n    \n    D --&gt; G[Find Local Subscribers]\n    E --&gt; H[Find Network Subscribers]\n    F --&gt; I[Find All Subscribers]\n    \n    G --&gt; J[Local Delivery]\n    H --&gt; K[P2P Delivery]\n    I --&gt; L[Full Distribution]\n    \n    J --&gt; M[Record Metrics]\n    K --&gt; M\n    L --&gt; M\n</code></pre>\n<h3>Discovery Process</h3>\n<p>Illustrates the peer discovery process.</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Start Discovery] --&gt; B[Load Networks]\n    \n    B --&gt; C{Discovery Method?}\n    C --&gt;|Multicast| D[Send Announcement]\n    C --&gt;|DHT| E[Query DHT]\n    C --&gt;|Bootstrap| F[Contact Seeds]\n    \n    D --&gt; G[Process Responses]\n    E --&gt; G\n    F --&gt; G\n    \n    G --&gt; H{Valid Peer?}\n    H --&gt;|Yes| I[Store Peer Info]\n    H --&gt;|No| J[Discard]\n    \n    I --&gt; K[Update Routing]\n    K --&gt; L[Start Connection]\n</code></pre>\n<h3>Security Flow</h3>\n<p>Shows the security validation process.</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Security Check] --&gt; B{Check Type?}\n    \n    B --&gt;|Token| C[Validate Token]\n    B --&gt;|Network| D[Verify Network]\n    B --&gt;|Permission| E[Check Access]\n    \n    C --&gt; F{Token Valid?}\n    F --&gt;|Yes| G[Check Expiry]\n    F --&gt;|No| H[Reject]\n    \n    D --&gt; I{Network Member?}\n    I --&gt;|Yes| J[Verify Rights]\n    I --&gt;|No| H\n    \n    E --&gt; K{Has Permission?}\n    K --&gt;|Yes| L[Allow]\n    K --&gt;|No| H\n</code></pre>\n<h3>Service Communication</h3>\n<p>Illustrates different types of service communication.</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Communication Request] --&gt; B{Type?}\n    \n    B --&gt;|Direct| C[Service-to-Service]\n    B --&gt;|Event| D[Pub/Sub]\n    B --&gt;|Broadcast| E[Network-Wide]\n    \n    C --&gt; F[Get Target Service]\n    D --&gt; G[Topic Resolution]\n    E --&gt; H[Network Distribution]\n    \n    F --&gt; I{Service Location?}\n    I --&gt;|Local| J[Local Call]\n    I --&gt;|Remote| K[P2P Call]\n    \n    G --&gt; L[Find Subscribers]\n    H --&gt; M[Find Network Peers]\n    \n    J --&gt; N[Process &amp; Return]\n    K --&gt; O[Remote Process]\n    L --&gt; P[Deliver Event]\n    M --&gt; Q[Broadcast Message]\n</code></pre>\n<h2>Examples</h2>\n<p>This section will be expanded with practical examples.</p>\n",
    "path": "/core/system-diagrams"
  },
  "core/discovery": {
    "html": "<h1>Discovery Mechanism Specification</h1>\n<p>This specification defines the discovery mechanism for the P2P network, allowing peers to locate each other on the same local network using UDP multicast. It includes secure validation of discovery messages to ensure only authorized peers are considered for connection.</p>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#introduction\">Introduction</a></li>\n<li><a href=\"#discovery-method\">Discovery Method</a></li>\n<li><a href=\"#multicast-group\">Multicast Group</a></li>\n<li><a href=\"#discovery-message\">Discovery Message</a></li>\n<li><a href=\"#accesstoken-in-discovery\">AccessToken in Discovery</a></li>\n<li><a href=\"#sending-discovery-messages\">Sending Discovery Messages</a></li>\n<li><a href=\"#receiving-discovery-messages\">Receiving Discovery Messages</a></li>\n<li><a href=\"#security\">Security</a></li>\n<li><a href=\"#references-between-specifications\">References Between Specifications</a></li>\n</ol>\n<h2>Introduction</h2>\n<p>This specification defines the discovery mechanism for the P2P network, allowing peers to locate each other on the same local network using UDP multicast. It includes secure validation of discovery messages to ensure only authorized peers are considered for connection.</p>\n<p>The following diagram illustrates the P2P discovery and connection process:</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant P1 as Peer1\n    participant M as Multicast Network\n    participant D as DHT Network\n    participant P2 as Peer2\n\n    P1-&gt;&gt;M: Send Discovery Message\n    M--&gt;&gt;P2: Receive Discovery Message\n    P2-&gt;&gt;P1: Establish Direct Connection\n    Note over P1,P2: Connection Established\n    \n    P1-&gt;&gt;D: Register Peer Info\n    P2-&gt;&gt;D: Lookup Remote Peer\n    D--&gt;&gt;P2: Return Peer Connection Info\n    P2-&gt;&gt;P1: Establish Connection via DHT\n</code></pre>\n<p>The following flow diagram illustrates the complete discovery process:</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Node Starts] --&gt; B[Initialize Discovery]\n    B --&gt; C[Join Multicast Group]\n    C --&gt; D[Send Discovery Message]\n    D --&gt; E[Listen for Discovery Messages]\n    \n    F[Discovery Message Received] --&gt; G[Validate Message]\n    G --&gt; H{Valid Message?}\n    H --&gt;|No| I[Discard Message]\n    H --&gt;|Yes| J[Extract Peer Info]\n    J --&gt; K[Verify Access Token]\n    K --&gt; L{Token Valid?}\n    L --&gt;|No| M[Reject Connection]\n    L --&gt;|Yes| N[Add to Peer List]\n    N --&gt; O[Establish Connection]\n    \n    P[DHT Discovery] --&gt; Q[Register in DHT]\n    Q --&gt; R[Lookup Remote Peers]\n    R --&gt; S[Connect to Remote Peers]\n</code></pre>\n<h2>Discovery Method</h2>\n<ul>\n<li><strong>UDP Multicast</strong>: Peers periodically announce their presence and listen for announcements within the local network.</li>\n</ul>\n<h2>Multicast Group</h2>\n<ul>\n<li><strong>Address</strong>: 239.255.255.250</li>\n<li><strong>Port</strong>: 4445</li>\n</ul>\n<h2>Discovery Message</h2>\n<ul>\n<li><p><strong>Format</strong>: JSON</p>\n</li>\n<li><p><strong>Structure</strong>:</p>\n<pre><code class=\"language-json\">{\n  &quot;peer_id&quot;: &quot;base64_peer_id&quot;,\n  &quot;networks&quot;: [\n    {\n      &quot;network_id&quot;: &quot;base64_network_id&quot;,\n      &quot;token&quot;: &quot;base64_access_token&quot;\n    }\n  ],\n  &quot;ip&quot;: &quot;peer_ip_address&quot;,\n  &quot;port&quot;: &quot;peer_tcp_port&quot;,\n  &quot;timestamp&quot;: &quot;unix_timestamp&quot;,\n  &quot;version&quot;: &quot;protocol_version&quot;\n}\n</code></pre>\n</li>\n<li><p><strong>Fields</strong>:</p>\n<ul>\n<li><code>peer_id</code>: Base64-encoded SHA-256 hash of the peer&#39;s Ed25519 public key (see Keys Management Specification)</li>\n<li><code>networks</code>: A list of network entries, each with:<ul>\n<li><code>network_id</code>: Base64-encoded derived public key (see Keys Management Specification)</li>\n<li><code>token</code>: Base64-encoded AccessToken (see Keys Management Specification)</li>\n</ul>\n</li>\n<li><code>ip</code>, <code>port</code>: The peer&#39;s IP address and TCP port for QUIC connections (used by P2P Transport Layer Specification)</li>\n<li><code>timestamp</code>: Unix timestamp for message freshness</li>\n<li><code>version</code>: Protocol version (e.g., &quot;1.0&quot;)</li>\n</ul>\n</li>\n</ul>\n<h2>AccessToken in Discovery</h2>\n<ul>\n<li><p><strong>Structure</strong>: Matches the AccessToken defined in the Keys Management Specification.</p>\n</li>\n<li><p><strong>Validation</strong>:</p>\n<ul>\n<li>Receiving peers verify each token using the corresponding <code>network_id</code> (public key)</li>\n<li>Ensure the <code>peer_id</code> in the token matches the message&#39;s <code>peer_id</code> and the token hasn&#39;t expired</li>\n</ul>\n</li>\n</ul>\n<h2>Sending Discovery Messages</h2>\n<ul>\n<li><p><strong>Frequency</strong>: Sent every 10 seconds, with 2 seconds of random jitter to avoid collisions.</p>\n</li>\n<li><p><strong>Process</strong>: Serialize the message to JSON and transmit it via UDP to the multicast group.</p>\n</li>\n</ul>\n<h2>Receiving Discovery Messages</h2>\n<ul>\n<li><p><strong>Processing</strong>:</p>\n<ul>\n<li>Ignore messages from the peer itself (based on <code>peer_id</code>)</li>\n<li>Check for common <code>network_ids</code> with the local peer&#39;s networks</li>\n<li>Verify the AccessToken for each matching network using the <code>network_id</code></li>\n<li>If valid, add or update the peer in the local peer list with its <code>ip</code> and <code>port</code></li>\n</ul>\n</li>\n<li><p><strong>Timeout</strong>: Remove peers from the list if no message is received for 30 seconds.</p>\n</li>\n</ul>\n<h2>Security</h2>\n<ul>\n<li><strong>Validation</strong>: Ensures only peers with valid AccessTokens are considered for connection.</li>\n<li><strong>Timestamp</strong>: Prevents replay attacks by rejecting old messages.</li>\n</ul>\n<h2>References Between Specifications</h2>\n<h3>P2P Transport Layer</h3>\n<ul>\n<li>Uses PeerId, NetworkId, and AccessToken from the Keys Management Specification for identity and access control.</li>\n<li>Relies on the Discovery Mechanism Specification to obtain peer addresses for QUIC connections.</li>\n</ul>\n<h3>Keys Management</h3>\n<ul>\n<li>Provides cryptographic identities and tokens used by both the P2P Transport Layer Specification and Discovery Mechanism Specification.</li>\n</ul>\n<h3>Discovery Mechanism</h3>\n<ul>\n<li>Uses AccessToken from the Keys Management Specification to secure discovery messages.</li>\n<li>Supplies peer addresses (<code>ip</code> and <code>port</code>) to the P2P Transport Layer Specification for establishing QUIC connections.</li>\n</ul>\n<h2>Implementation Example</h2>\n<pre><code class=\"language-rust\">use kagi_node::discovery::prelude::*;\nuse kagi_node::keys::AccessToken;\nuse std::time::{Duration, SystemTime, UNIX_EPOCH};\n\n// Set up discovery service\nlet mut discovery = DiscoveryService::new()?;\ndiscovery\n    .set_multicast_addr(&quot;239.255.255.250:4445&quot;)\n    .set_announce_interval(Duration::from_secs(10))\n    .set_peer_timeout(Duration::from_secs(30));\n\n// Add a network to announce\nlet network_id = &quot;base64_encoded_network_id&quot;;\nlet token = AccessToken::new(\n    peer_id, \n    network_id, \n    SystemTime::now() + Duration::from_secs(3600)\n);\ndiscovery.add_network(network_id, token);\n\n// Start the discovery service (runs in background)\ndiscovery.start()?;\n\n// Get discovered peers\nlet peers = discovery.get_peers_for_network(network_id);\nfor peer in peers {\n    println!(&quot;Discovered peer: {}:{} with ID {}&quot;, \n        peer.ip, \n        peer.port, \n        peer.peer_id\n    );\n}\n\n// Stop discovery when done\ndiscovery.stop()?;\n</code></pre>\n<h2>Examples</h2>\n<p>This section will be expanded with practical examples.</p>\n",
    "path": "/core/discovery"
  },
  "core/p2p": {
    "html": "<h1>P2P Transport Layer Specification</h1>\n<p>This specification defines a peer-to-peer (P2P) transport layer implemented in Rust, designed as an event bus using QUIC as the transport protocol. It supports network-specific participation, decentralized storage via a Kademlia Distributed Hash Table (DHT), and secure access control through cryptographic tokens.</p>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#overview\">Overview</a></li>\n<li><a href=\"#core-components\">Core Components</a><ul>\n<li><a href=\"#transport-layer\">Transport Layer</a></li>\n<li><a href=\"#dht-system\">DHT System</a></li>\n<li><a href=\"#network-management\">Network Management</a></li>\n</ul>\n</li>\n<li><a href=\"#api-design\">API Design</a><ul>\n<li><a href=\"#message-operations\">Message Operations</a></li>\n<li><a href=\"#network-operations\">Network Operations</a></li>\n<li><a href=\"#dht-operations\">DHT Operations</a></li>\n</ul>\n</li>\n<li><a href=\"#security\">Security</a><ul>\n<li><a href=\"#access-control\">Access Control</a></li>\n<li><a href=\"#connection-security\">Connection Security</a></li>\n</ul>\n</li>\n<li><a href=\"#implementation-details\">Implementation Details</a><ul>\n<li><a href=\"#transport-implementation\">Transport Implementation</a></li>\n<li><a href=\"#dht-implementation\">DHT Implementation</a></li>\n</ul>\n</li>\n<li><a href=\"#integration\">Integration</a><ul>\n<li><a href=\"#service-integration\">Service Integration</a></li>\n<li><a href=\"#gateway-integration\">Gateway Integration</a></li>\n<li><a href=\"#discovery-integration\">Discovery Integration</a></li>\n</ul>\n</li>\n</ol>\n<h2>Overview</h2>\n<p>The P2P transport layer provides:</p>\n<ul>\n<li>QUIC-based reliable transport</li>\n<li>Network-scoped DHT for decentralized storage</li>\n<li>Secure peer authentication and authorization</li>\n<li>Integration with the Kagi node service architecture</li>\n<li>Event-based message routing and delivery</li>\n</ul>\n<h2>Core Components</h2>\n<h3>Transport Layer</h3>\n<p><strong>Requirements</strong>:</p>\n<ul>\n<li>Reliable message delivery using QUIC</li>\n<li>Support for Rust object serialization</li>\n<li>Peer-to-peer and broadcast messaging</li>\n<li>Connection multiplexing</li>\n<li>Flow control and backpressure</li>\n</ul>\n<p><strong>Features</strong>:</p>\n<ul>\n<li>Asynchronous message handling</li>\n<li>Automatic reconnection</li>\n<li>Connection pooling</li>\n<li>Quality of service options</li>\n<li>Error recovery</li>\n</ul>\n<p>The following diagram illustrates the P2P message routing flow:</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Message Created] --&gt; B[Serialize Message]\n    B --&gt; C{Local or Remote?}\n    C --&gt;|Local| D[Process Locally]\n    C --&gt;|Remote| E[Lookup Peer Route]\n    E --&gt; F{Direct Connection?}\n    F --&gt;|Yes| G[Send via Direct Connection]\n    F --&gt;|No| H[Find Route via DHT]\n    H --&gt; I[Forward to Next Hop]\n    I --&gt; J[Receive at Destination]\n    J --&gt; K[Deserialize Message]\n    K --&gt; L[Process Message]\n    L --&gt; M[Generate Response]\n    M --&gt; N[Return via Same Route]\n</code></pre>\n<h3>DHT System</h3>\n<p><strong>Features</strong>:</p>\n<ul>\n<li>Kademlia-based routing</li>\n<li>Network-scoped key-value storage</li>\n<li>Replication and redundancy</li>\n<li>Automatic peer discovery</li>\n<li>Value expiration and refresh</li>\n</ul>\n<h3>Network Management</h3>\n<p><strong>Features</strong>:</p>\n<ul>\n<li>Network-specific participation</li>\n<li>Access token validation</li>\n<li>Peer authentication</li>\n<li>Connection management</li>\n<li>Network metadata</li>\n</ul>\n<h2>API Design</h2>\n<h3>Message Operations</h3>\n<pre><code class=\"language-rust\">/// Send a message to a specific peer\nasync fn send_to_peer&lt;T: Serialize&gt;(\n    &amp;self,\n    peer_id: PeerId,\n    message: T\n) -&gt; Result&lt;(), Error&gt;;\n\n/// Broadcast a message to multiple peers\nasync fn broadcast&lt;T: Serialize&gt;(\n    &amp;self,\n    peer_ids: &amp;[PeerId],\n    message: T\n) -&gt; Result&lt;(), Error&gt;;\n\n/// Start listening for incoming messages\nfn start_listening(&amp;self) -&gt; mpsc::Receiver&lt;(PeerId, Vec&lt;u8&gt;)&gt;;\n</code></pre>\n<h3>Network Operations</h3>\n<pre><code class=\"language-rust\">/// Configure network metadata\nasync fn set_network_metadata(\n    &amp;self,\n    network_id: NetworkId,\n    admin_pubkey: PublicKey,\n    name: String\n) -&gt; Result&lt;(), Error&gt;;\n\n/// Add network access token\nasync fn add_network_token(\n    &amp;self,\n    network_id: NetworkId,\n    token: AccessToken\n) -&gt; Result&lt;(), Error&gt;;\n\n/// Connect to a peer in a specific network\nasync fn connect_to_peer(\n    &amp;self,\n    peer_id: PeerId,\n    network_id: NetworkId,\n    address: String\n) -&gt; Result&lt;Connection, Error&gt;;\n</code></pre>\n<h3>DHT Operations</h3>\n<p>The following diagram illustrates the DHT operations in the P2P network:</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant N1 as Node1\n    participant K1 as Kademlia (Node1)\n    participant K2 as Kademlia (Node2)\n    participant N2 as Node2\n    participant K3 as Kademlia (Node3)\n    participant N3 as Node3\n\n    N1-&gt;&gt;K1: Store Value (Key, Value)\n    K1-&gt;&gt;K2: Forward to Closer Node\n    K2-&gt;&gt;N2: Store Value\n    Note over N2: Value Stored\n\n    N3-&gt;&gt;K3: Get Value (Key)\n    K3-&gt;&gt;K2: Query Closer Node\n    K2-&gt;&gt;N2: Retrieve Value\n    N2--&gt;&gt;K2: Return Value\n    K2--&gt;&gt;K3: Forward Value\n    K3--&gt;&gt;N3: Return Value\n</code></pre>\n<pre><code class=\"language-rust\">/// Store a value in the DHT\nasync fn dht_put(\n    &amp;self,\n    network_id: NetworkId,\n    key: Vec&lt;u8&gt;,\n    value: Vec&lt;u8&gt;\n) -&gt; Result&lt;(), Error&gt;;\n\n/// Retrieve a value from the DHT\nasync fn dht_get(\n    &amp;self,\n    network_id: NetworkId,\n    key: Vec&lt;u8&gt;\n) -&gt; Result&lt;Option&lt;Vec&lt;u8&gt;&gt;, Error&gt;;\n\n/// Bootstrap the DHT using a known peer\nasync fn bootstrap(\n    &amp;self,\n    network_id: NetworkId,\n    bootstrap_peer: PeerId\n) -&gt; Result&lt;(), Error&gt;;\n</code></pre>\n<h2>Security</h2>\n<p>The following diagram illustrates the network authentication process:</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant C as Client Node\n    participant A as Auth Service\n    participant N as Network Admin\n    participant T as Target Node\n\n    C-&gt;&gt;N: Request Network Access\n    N-&gt;&gt;A: Generate Access Token\n    A--&gt;&gt;N: Signed Access Token\n    N--&gt;&gt;C: Provide Access Token\n    \n    C-&gt;&gt;T: Connect with Access Token\n    T-&gt;&gt;T: Validate Token\n    Note over T: Check Signature\n    Note over T: Verify Permissions\n    T--&gt;&gt;C: Connection Established/Rejected\n</code></pre>\n<p>The following flow diagram illustrates the security flow in the P2P network:</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Connection Request] --&gt; B[TLS Handshake]\n    B --&gt; C[Verify Certificate]\n    C --&gt; D{Certificate Valid?}\n    D --&gt;|No| E[Reject Connection]\n    D --&gt;|Yes| F[Extract Peer ID]\n    F --&gt; G[Verify Network Access]\n    G --&gt; H{Access Token?}\n    H --&gt;|No| I[Request Access Token]\n    H --&gt;|Yes| J[Validate Token]\n    J --&gt; K{Token Valid?}\n    K --&gt;|No| L[Reject Connection]\n    K --&gt;|Yes| M[Establish Secure Channel]\n    M --&gt; N[Apply Message Encryption]\n    N --&gt; O[Connection Established]\n    \n    P[Message Received] --&gt; Q[Decrypt Message]\n    Q --&gt; R[Verify Message Integrity]\n    R --&gt; S{Integrity Check?}\n    S --&gt;|Fail| T[Discard Message]\n    S --&gt;|Pass| U[Process Message]\n</code></pre>\n<h3>Access Control</h3>\n<p><strong>Token Validation</strong>:</p>\n<pre><code class=\"language-rust\">impl P2PTransport {\n    async fn validate_peer_token(\n        &amp;self,\n        peer_id: &amp;PeerId,\n        network_id: &amp;NetworkId,\n        token: &amp;AccessToken\n    ) -&gt; Result&lt;bool, Error&gt; {\n        // Verify token signature using network&#39;s public key\n        if !token.verify(network_id)? {\n            return Ok(false);\n        }\n        \n        // Check token belongs to the peer\n        if token.peer_id != *peer_id {\n            return Ok(false);\n        }\n        \n        // Check expiration\n        if token.is_expired() {\n            return Ok(false);\n        }\n        \n        Ok(true)\n    }\n}\n</code></pre>\n<h3>Connection Security</h3>\n<p><strong>QUIC Configuration</strong>:</p>\n<pre><code class=\"language-rust\">impl P2PTransport {\n    fn configure_quic(&amp;self) -&gt; QuicConfig {\n        QuicConfig::new()\n            .with_max_idle_timeout(Duration::from_secs(30))\n            .with_max_concurrent_bidi_streams(100u32)\n            .with_max_concurrent_uni_streams(100u32)\n            .with_application_protocols(vec![&quot;kagi-p2p-1&quot;.into()])\n    }\n}\n</code></pre>\n<h2>Implementation Details</h2>\n<h3>Transport Implementation</h3>\n<p><strong>Connection Management</strong>:</p>\n<pre><code class=\"language-rust\">pub struct P2PTransport {\n    endpoint: QuicEndpoint,\n    connections: Arc&lt;RwLock&lt;HashMap&lt;PeerId, Connection&gt;&gt;&gt;,\n    networks: Arc&lt;RwLock&lt;HashMap&lt;NetworkId, NetworkState&gt;&gt;&gt;,\n    message_tx: mpsc::Sender&lt;(PeerId, Vec&lt;u8&gt;)&gt;,\n    message_rx: mpsc::Receiver&lt;(PeerId, Vec&lt;u8&gt;)&gt;,\n}\n\nimpl P2PTransport {\n    async fn handle_connection(&amp;self, conn: Connection) {\n        while let Ok(stream) = conn.accept_bi().await {\n            let (mut send, mut recv) = stream;\n            \n            // Handle incoming messages\n            while let Some(message) = recv.next().await {\n                self.process_message(message).await?;\n            }\n        }\n    }\n}\n</code></pre>\n<h3>DHT Implementation</h3>\n<p><strong>Kademlia Integration</strong>:</p>\n<pre><code class=\"language-rust\">pub struct DHTNode {\n    routing_table: RoutingTable,\n    storage: Arc&lt;RwLock&lt;HashMap&lt;Vec&lt;u8&gt;, Vec&lt;u8&gt;&gt;&gt;&gt;,\n    network_id: NetworkId,\n}\n\nimpl DHTNode {\n    async fn handle_find_value(\n        &amp;self,\n        key: Vec&lt;u8&gt;\n    ) -&gt; Result&lt;Option&lt;Vec&lt;u8&gt;&gt;, Error&gt; {\n        // Check local storage first\n        if let Some(value) = self.storage.read().await.get(&amp;key) {\n            return Ok(Some(value.clone()));\n        }\n        \n        // Query closest peers\n        let closest = self.routing_table.closest_peers(&amp;key);\n        for peer in closest {\n            if let Some(value) = self.query_peer(peer, key.clone()).await? {\n                return Ok(Some(value));\n            }\n        }\n        \n        Ok(None)\n    }\n}\n</code></pre>\n<h2>Integration</h2>\n<h3>Service Integration</h3>\n<p>The P2P transport integrates with Kagi services through the service registry:</p>\n<pre><code class=\"language-rust\">impl P2PTransport {\n    async fn forward_to_service(\n        &amp;self,\n        service: &amp;str,\n        request: ServiceRequest\n    ) -&gt; Result&lt;ServiceResponse, Error&gt; {\n        let service = self.registry.get_service(service)?;\n        service.process_request(request).await\n    }\n}\n</code></pre>\n<h3>Gateway Integration</h3>\n<p>Integration with the Gateway module for external access:</p>\n<pre><code class=\"language-rust\">impl Gateway {\n    async fn handle_p2p_request(\n        &amp;self,\n        req: HttpRequest\n    ) -&gt; Result&lt;HttpResponse, Error&gt; {\n        let peer_id = self.extract_peer_id(&amp;req)?;\n        let network_id = self.extract_network_id(&amp;req)?;\n        \n        // Validate access token\n        let token = self.extract_token(&amp;req)?;\n        if !self.p2p.validate_peer_token(peer_id, network_id, &amp;token).await? {\n            return Err(Error::Unauthorized);\n        }\n        \n        // Forward request to P2P network\n        let response = self.p2p\n            .send_to_peer(peer_id, req.into_inner())\n            .await?;\n            \n        Ok(response.into())\n    }\n}\n</code></pre>\n<h3>Discovery Integration</h3>\n<p>Integration with the Discovery mechanism:</p>\n<pre><code class=\"language-rust\">impl P2PTransport {\n    async fn handle_discovery_event(\n        &amp;self,\n        event: DiscoveryEvent\n    ) -&gt; Result&lt;(), Error&gt; {\n        match event {\n            DiscoveryEvent::PeerFound { peer_id, addr, networks } =&gt; {\n                for network_id in networks {\n                    if self.is_network_member(&amp;network_id) {\n                        self.connect_to_peer(peer_id, network_id, addr.clone()).await?;\n                    }\n                }\n            }\n            DiscoveryEvent::PeerLost { peer_id } =&gt; {\n                self.remove_peer(peer_id).await?;\n            }\n        }\n        Ok(())\n    }\n}\n</code></pre>\n<p>This specification aligns with:</p>\n<ul>\n<li>Keys Management Specification for PeerId and NetworkId definitions</li>\n<li>Discovery Mechanism Specification for peer discovery</li>\n<li>Gateway Specification for external access</li>\n<li>Service Architecture for message routing and processing</li>\n</ul>\n<h2>Examples</h2>\n<p>This section will be expanded with practical examples.</p>\n",
    "path": "/core/p2p"
  },
  "core/vmap": {
    "html": "<h1>ValueMap (VMap)</h1>\n<h2>Overview</h2>\n<p>ValueMap (VMap) is a core abstraction in Kagi that provides an ergonomic interface for working with structured data. It simplifies parameter extraction and reduces boilerplate code through an intuitive API and accompanying macros.</p>\n<h2>Key Features</h2>\n<ul>\n<li><strong>Type-safe parameter extraction</strong>: Get parameters with proper type conversion</li>\n<li><strong>Comprehensive error handling</strong>: Detailed errors for missing or invalid parameters</li>\n<li><strong>Macro-based simplification</strong>: Dramatically reduce parameter handling code</li>\n<li><strong>Integration with ValueType</strong>: Seamless work with Kagi&#39;s value type system</li>\n</ul>\n<h2>Basic Usage</h2>\n<h3>Creating a VMap</h3>\n<pre><code class=\"language-rust\">// Create an empty VMap\nlet vmap = VMap::new();\n\n// Create from key-value pairs using the macro\nlet params = vmap! {\n    &quot;name&quot; =&gt; &quot;kagi&quot;,\n    &quot;version&quot; =&gt; &quot;1.0&quot;,\n    &quot;count&quot; =&gt; 42,\n    &quot;enabled&quot; =&gt; true\n};\n\n// Create from an existing HashMap\nlet map: HashMap&lt;String, ValueType&gt; = /* ... */;\nlet vmap = VMap::from_hashmap(map);\n</code></pre>\n<h3>Extracting Values</h3>\n<pre><code class=\"language-rust\">// Get a String value with the macro\nlet name: String = vmap!(params, &quot;name&quot;, String)?;\n\n// Get an integer with the macro\nlet count: i32 = vmap!(params, &quot;count&quot;, Int)?;\n\n// Get a boolean with the macro\nlet enabled: bool = vmap!(params, &quot;enabled&quot;, Bool)?;\n\n// Get an optional value (doesn&#39;t error if missing)\nlet description: Option&lt;String&gt; = vmap_opt!(params, &quot;description&quot;, String);\n</code></pre>\n<h2>Before and After Comparison</h2>\n<h3>Before VMap</h3>\n<p>Extracting parameters used to require significant boilerplate:</p>\n<pre><code class=\"language-rust\">fn process_request(params: HashMap&lt;String, ValueType&gt;) -&gt; Result&lt;(), Error&gt; {\n    // Extract name\n    let name = match params.get(&quot;name&quot;) {\n        Some(value) =&gt; match value {\n            ValueType::String(s) =&gt; s.clone(),\n            _ =&gt; return Err(Error::InvalidParameter(&quot;name must be a string&quot;.to_string())),\n        },\n        None =&gt; return Err(Error::MissingParameter(&quot;name&quot;.to_string())),\n    };\n\n    // Extract count\n    let count = match params.get(&quot;count&quot;) {\n        Some(value) =&gt; match value {\n            ValueType::Int(i) =&gt; *i,\n            _ =&gt; return Err(Error::InvalidParameter(&quot;count must be an integer&quot;.to_string())),\n        },\n        None =&gt; return Err(Error::MissingParameter(&quot;count&quot;.to_string())),\n    };\n\n    // Extract enabled\n    let enabled = match params.get(&quot;enabled&quot;) {\n        Some(value) =&gt; match value {\n            ValueType::Bool(b) =&gt; *b,\n            _ =&gt; return Err(Error::InvalidParameter(&quot;enabled must be a boolean&quot;.to_string())),\n        },\n        None =&gt; false, // Default value\n    };\n\n    // Process with extracted parameters\n    println!(&quot;Processing: {}, count={}, enabled={}&quot;, name, count, enabled);\n    Ok(())\n}\n</code></pre>\n<h3>After VMap</h3>\n<p>With VMap, parameter extraction becomes concise and readable:</p>\n<pre><code class=\"language-rust\">fn process_request(params: VMap) -&gt; Result&lt;(), Error&gt; {\n    // Extract parameters with type conversion\n    let name: String = vmap!(params, &quot;name&quot;, String)?;\n    let count: i32 = vmap!(params, &quot;count&quot;, Int)?;\n    let enabled: bool = vmap_opt!(params, &quot;enabled&quot;, Bool).unwrap_or(false);\n\n    // Process with extracted parameters\n    println!(&quot;Processing: {}, count={}, enabled={}&quot;, name, count, enabled);\n    Ok(())\n}\n</code></pre>\n<h2>Advanced Usage</h2>\n<h3>Working with Complex Types</h3>\n<p>VMap supports various parameter types, including complex structures:</p>\n<pre><code class=\"language-rust\">// Extract a JSON object\nlet config: serde_json::Value = vmap!(params, &quot;config&quot;, Json)?;\n\n// Extract an array of strings\nlet tags: Vec&lt;String&gt; = vmap!(params, &quot;tags&quot;, StringArray)?;\n\n// Extract a nested VMap\nlet options: VMap = vmap!(params, &quot;options&quot;, Map)?;\n</code></pre>\n<h3>Default Values</h3>\n<p>The <code>vmap_opt!</code> macro allows specifying default values:</p>\n<pre><code class=\"language-rust\">// If &quot;timeout&quot; is missing, use 30 seconds\nlet timeout: u64 = vmap_opt!(params, &quot;timeout&quot;, Int).unwrap_or(30);\n\n// If &quot;mode&quot; is missing, use &quot;standard&quot;\nlet mode: String = vmap_opt!(params, &quot;mode&quot;, String).unwrap_or_else(|| &quot;standard&quot;.to_string());\n</code></pre>\n<h3>Handling Nested Parameters</h3>\n<p>Extract nested parameters with path notation:</p>\n<pre><code class=\"language-rust\">// Extract nested value: { &quot;user&quot;: { &quot;profile&quot;: { &quot;name&quot;: &quot;Alice&quot; } } }\nlet name: String = vmap!(params, &quot;user.profile.name&quot;, String)?;\n\n// Or extract a sub-map and then access it\nlet user: VMap = vmap!(params, &quot;user&quot;, Map)?;\nlet profile: VMap = vmap!(user, &quot;profile&quot;, Map)?;\nlet name: String = vmap!(profile, &quot;name&quot;, String)?;\n</code></pre>\n<h2>Error Handling</h2>\n<p>VMap provides detailed error messages that make debugging easier:</p>\n<pre><code class=\"language-rust\">match vmap!(params, &quot;count&quot;, Int) {\n    Ok(count) =&gt; {\n        // Use count\n    },\n    Err(e) =&gt; match e {\n        Error::MissingParameter(param) =&gt; {\n            println!(&quot;Missing required parameter: {}&quot;, param);\n        },\n        Error::InvalidParameter(msg) =&gt; {\n            println!(&quot;Invalid parameter format: {}&quot;, msg);\n        },\n        _ =&gt; {\n            println!(&quot;Other error: {:?}&quot;, e);\n        }\n    }\n}\n</code></pre>\n<h2>VMap Data Flow</h2>\n<pre><code class=\"language-mermaid\">@include &quot;../assets/images/vmap-flow.txt&quot;\n</code></pre>\n<p>The diagram above illustrates how data flows through the VMap system:</p>\n<ol>\n<li>Parameter data enters the system as a HashMap&lt;String, ValueType&gt;</li>\n<li>The VMap wrapper provides a structured interface to this data</li>\n<li>Extraction macros handle type conversion and error checking</li>\n<li>Typed data is passed to the application logic</li>\n</ol>\n<h2>Best Practices</h2>\n<ol>\n<li><strong>Use macros for clarity</strong>: Prefer <code>vmap!</code> over manual extraction</li>\n<li><strong>Handle optional parameters</strong>: Use <code>vmap_opt!</code> for optional values</li>\n<li><strong>Validate early</strong>: Extract and validate parameters at the entry point</li>\n<li><strong>Use descriptive error messages</strong>: Add context to error messages</li>\n<li><strong>Type consistency</strong>: Use consistent parameter naming and types across services</li>\n</ol>\n<h2>Implementation Details</h2>\n<p>The VMap implementation consists of:</p>\n<ul>\n<li>The <code>VMap</code> struct wrapping a <code>HashMap&lt;String, ValueType&gt;</code></li>\n<li>Type-specific extraction methods for different data types</li>\n<li>The <code>vmap!</code> and <code>vmap_opt!</code> macros for simplified access</li>\n<li>Integration with Kagi&#39;s error handling system</li>\n</ul>\n<h2>Related Documentation</h2>\n<ul>\n<li><a href=\"context.md\">Context System</a> - How context enables secure and traceable communication</li>\n<li><a href=\"request_handling.md\">Request Handling</a> - Best practices for using VMap in request handlers</li>\n<li><a href=\"lifecycle.md\">Service Lifecycle</a> - Understanding the service lifecycle and initialization</li>\n<li><a href=\"logging.md\">Logging System</a> - Context-aware, structured logging</li>\n</ul>\n",
    "path": "/core/vmap"
  },
  "core/architecture": {
    "html": "<h1>Kagi Node System Architecture</h1>\n<p>This document describes the high-level architecture of the Kagi node system, including core components, data flow patterns, design principles, and implementation guidelines.</p>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#introduction\">Introduction</a></li>\n<li><a href=\"#core-components\">Core Components</a><ul>\n<li><a href=\"#node\">Node</a></li>\n<li><a href=\"#service-registry\">Service Registry</a></li>\n<li><a href=\"#abstract-service\">Abstract Service</a></li>\n<li><a href=\"#request-context\">Request Context</a></li>\n<li><a href=\"#logging-system\">Logging System</a></li>\n<li><a href=\"#database-system\">Database System</a></li>\n<li><a href=\"#ipc-system\">IPC System</a></li>\n</ul>\n</li>\n<li><a href=\"#data-flow-patterns\">Data Flow Patterns</a><ul>\n<li><a href=\"#requestresponse-pattern\">Request/Response Pattern</a></li>\n<li><a href=\"#publishsubscribe-pattern\">Publish/Subscribe Pattern</a></li>\n</ul>\n</li>\n<li><a href=\"#design-principles\">Design Principles</a><ul>\n<li><a href=\"#service-organization\">Service Organization</a></li>\n<li><a href=\"#communication-patterns\">Communication Patterns</a></li>\n<li><a href=\"#event-handler-lifecycle-management\">Event Handler Lifecycle</a></li>\n<li><a href=\"#implementation-guidelines\">Implementation Guidelines</a></li>\n<li><a href=\"#service-implementation-patterns\">Service Implementation Patterns</a></li>\n</ul>\n</li>\n<li><a href=\"#service-lifecycle-management\">Service Lifecycle Management</a><ul>\n<li><a href=\"#service-initialization\">Service Initialization</a></li>\n<li><a href=\"#subscription-management\">Subscription Management</a></li>\n</ul>\n</li>\n<li><a href=\"#p2p-architecture\">P2P Architecture</a><ul>\n<li><a href=\"#service-discovery\">Service Discovery</a></li>\n<li><a href=\"#peer-to-peer-communication\">Peer-to-Peer Communication</a></li>\n<li><a href=\"#network-configuration\">Network Configuration</a></li>\n</ul>\n</li>\n<li><a href=\"#security-considerations\">Security Considerations</a><ul>\n<li><a href=\"#authentication\">Authentication</a></li>\n<li><a href=\"#authorization\">Authorization</a></li>\n<li><a href=\"#secure-communication\">Secure Communication</a></li>\n</ul>\n</li>\n</ol>\n<h2>Introduction</h2>\n<p>The Kagi node system follows a modular, service-oriented architecture designed for flexibility, extensibility, and robust operation in distributed environments. This document provides an overview of the key components and principles governing the system design.</p>\n<h2>Core Components</h2>\n<h3>Node</h3>\n<p>The central component that manages services and provides core functionality:</p>\n<ul>\n<li>Defined in <code>node.rs</code></li>\n<li>Contains configuration, service management, and network operations</li>\n<li>Acts as the main entry point for the application</li>\n<li>Provides interfaces for service communication and event handling</li>\n</ul>\n<h3>Service Registry</h3>\n<p>Manages service registration, discovery, and communication:</p>\n<ul>\n<li>Defined in <code>services/registry.rs</code></li>\n<li>Maintains a map of registered services</li>\n<li>Routes requests to appropriate services</li>\n<li>Handles publish/subscribe for events</li>\n<li>Manages remote service discovery and communication</li>\n</ul>\n<h3>Abstract Service</h3>\n<p>Base trait implemented by all services:</p>\n<ul>\n<li>Defined in <code>services/abstract_service.rs</code></li>\n<li>Provides unified lifecycle management (init, start, stop)</li>\n<li>Standardizes request processing</li>\n<li>Defines service state transitions</li>\n</ul>\n<h3>Request Context</h3>\n<p>Context for service requests:</p>\n<ul>\n<li>Handles path routing and parameter passing</li>\n<li>Provides a uniform interface for service communication</li>\n<li>Enables service-to-service communication</li>\n<li>Manages event subscription and publishing</li>\n</ul>\n<h3>Logging System</h3>\n<p>Component-based logging for debugging and monitoring:</p>\n<ul>\n<li>Defined in <code>util/logging.rs</code></li>\n<li>Categorizes logs by system component</li>\n<li>Supports multiple log levels</li>\n<li>Provides structured logging capabilities</li>\n</ul>\n<h3>Database System</h3>\n<p>SQLite-based storage layer:</p>\n<ul>\n<li>Defined in <code>db.rs</code> and <code>services/sqlite.rs</code></li>\n<li>Provides persistence for system data</li>\n<li>Supports CRUD operations and queries</li>\n<li>Manages database connections and transactions</li>\n</ul>\n<h3>IPC System</h3>\n<p>Client-server communication:</p>\n<ul>\n<li>Facilitates communication with external processes</li>\n<li>Implements secure inter-process communication</li>\n<li>Provides APIs for external service integration</li>\n</ul>\n<h2>Data Flow Patterns</h2>\n<p>The Kagi node system follows two primary data flow patterns:</p>\n<h3>Request/Response Pattern</h3>\n<ol>\n<li><p><strong>Client Request</strong></p>\n<ul>\n<li>Requests begin in the <code>RequestContext</code> with a path and parameters</li>\n<li>The <code>NodeRequestHandlerImpl</code> parses the path into service name and operation</li>\n<li>Requests are routed to appropriate services through the registry</li>\n<li>Services process requests and return responses</li>\n<li>Responses flow back through the handler to the client</li>\n</ul>\n</li>\n<li><p><strong>Request Routing Flow</strong></p>\n<pre><code>Client  Node  ServiceRegistry  TargetService  process_request()  Response\n</code></pre>\n</li>\n</ol>\n<h3>Publish/Subscribe Pattern</h3>\n<ol>\n<li><p><strong>Event Publication</strong></p>\n<ul>\n<li>Publishers emit events to specific topics</li>\n<li>The service registry manages topic subscriptions</li>\n<li>Subscribers receive events when published to their topics</li>\n<li>Events include metadata like timestamps</li>\n<li>Subscribers process events based on topic and content</li>\n</ul>\n</li>\n<li><p><strong>Event Flow</strong></p>\n<pre><code>Publisher  Node  ServiceRegistry  Topic Subscribers  Event Handlers\n</code></pre>\n</li>\n</ol>\n<h2>Design Principles</h2>\n<h3>Service Organization</h3>\n<ul>\n<li>Each functionality should be implemented as a dedicated service</li>\n<li>Services should be self-contained and follow the single responsibility principle</li>\n<li>Avoid conditional routing within services - use dedicated services for different functionalities</li>\n<li>Information services should be separate from their data sources (e.g., <code>RegistryInfoService</code> separate from <code>ServiceRegistry</code>)</li>\n<li>Use delegation pattern when a service needs to expose data from another component</li>\n</ul>\n<h3>Communication Patterns</h3>\n<h4>Request/Response</h4>\n<ul>\n<li>All service requests must include a <code>RequestContext</code></li>\n<li>Path format should be &quot;serviceName/operation&quot; to enable proper routing</li>\n<li><code>NodeRequestHandler</code> should parse the path to extract service name and operation</li>\n<li>Services should process requests based on the operation field</li>\n</ul>\n<h4>Publish/Subscribe</h4>\n<ul>\n<li>Publish operations should mirror request pattern (same path parsing, context handling)</li>\n<li>No response is expected from publish operations</li>\n<li>Event handlers should receive the same context as request handlers</li>\n<li>Context allows event handlers to make additional service calls or trigger events</li>\n<li>Subscribe operations should use the complete path (e.g., &quot;user/created&quot;)</li>\n<li>Service name should be extracted from path using the same mechanism as requests</li>\n<li>Each topic should have a clear ownership model (which service owns which topics)</li>\n</ul>\n<h5>Subscription Processing</h5>\n<ul>\n<li>When subscribing from within a service, the service name is implied and can be omitted</li>\n<li>When subscribing directly from a Node without a service context, an anonymous service is created</li>\n<li>Anonymous subscribers are registered in the ServiceRegistry with a unique service name</li>\n<li>This ensures all subscribers are tied to a service, maintaining a consistent architecture</li>\n<li>Anonymous services are implemented as fully-functional AbstractService instances</li>\n</ul>\n<h5>Subscription Propagation</h5>\n<ul>\n<li>When a node subscribes to a topic, the subscription should be stored in the local registry</li>\n<li>All non-internal services (events and actions) (topics not starting with &quot;internal/&quot;) should be propagated to all connected peers</li>\n<li>Internal topics are meant for local node usage only and should not be shared across the network</li>\n<li>This ensures that peers are aware of what topics each node is interested in</li>\n<li>Propagating subscriptions allows nodes to route events across the network efficiently</li>\n<li>When a node receives a remote subscription, it should record it for future event routing</li>\n</ul>\n<h3>Event Handler Lifecycle Management</h3>\n<ul>\n<li>Event handlers remain active until explicitly unregistered using:<ul>\n<li><code>node.unsubscribe(topic, [handler_id])</code> at the Node level</li>\n<li><code>context.unsubscribe(topic, [handler_id])</code> from within a RequestContext</li>\n</ul>\n</li>\n<li>One-time event handlers that auto-unregister after being triggered once:<ul>\n<li><code>node.once(topic, callback)</code> at the Node level</li>\n<li><code>context.once(topic, callback)</code> from within a RequestContext</li>\n</ul>\n</li>\n<li>Advanced subscription options via <code>subscribe_with_options()</code>:<ul>\n<li>Supports TTL (time-to-live) for automatic cleanup after a specified duration</li>\n<li>Supports max_triggers to automatically unregister after being triggered N times</li>\n<li>Supports conditional unsubscribe based on callback return value</li>\n</ul>\n</li>\n<li>Anonymous services for subscriptions are subject to the following lifecycle:<ul>\n<li>Created when a subscription is registered without a service context</li>\n<li>Remain active as long as they have at least one active subscription</li>\n<li>Can be manually unregistered or expire based on subscription options</li>\n<li>Periodic cleanup removes services with no active subscriptions</li>\n</ul>\n</li>\n</ul>\n<h3>Implementation Guidelines</h3>\n<ul>\n<li>Maintain consistent path handling across all communication patterns</li>\n<li>Make service boundaries explicit and well-defined</li>\n<li>Services should expose clear interfaces through their operations</li>\n<li>Prefer composition over inheritance when extending functionality</li>\n</ul>\n<h3>Service Implementation Patterns</h3>\n<p><strong>Service Operation Delegation:</strong></p>\n<ul>\n<li>The <code>process_request</code> method should match on the operation name and delegate to local methods</li>\n<li>Local method names should match the operation names for clarity and traceability</li>\n<li>Example: <code>operation &quot;get_data&quot;</code> should call a local method named <code>get_data()</code></li>\n<li>This improves code organization, readability, and testability</li>\n<li>Complex operation implementations should be moved out of the <code>process_request</code> method</li>\n<li>Each operation should have a single, focused implementation method</li>\n</ul>\n<h2>Service Lifecycle Management</h2>\n<p>The following diagram illustrates the lifecycle of a service in the Kagi node system:</p>\n<pre><code class=\"language-mermaid\">sequenceDiagram\n    participant N as Node\n    participant SR as ServiceRegistry\n    participant S as Service\n    participant ES as EventSystem\n\n    N-&gt;&gt;S: Create Service\n    Note over S: State: Created\n    N-&gt;&gt;S: Initialize Service\n    S-&gt;&gt;ES: Register Subscriptions\n    Note over S: State: Initialized\n    N-&gt;&gt;S: Start Service\n    Note over S: State: Running\n    S-&gt;&gt;SR: Register Service\n    \n    Note over S: Service Processing...\n    \n    N-&gt;&gt;S: Stop Service\n    S-&gt;&gt;ES: Unregister Subscriptions\n    S-&gt;&gt;SR: Unregister Service\n    Note over S: State: Stopped\n</code></pre>\n<h3>Service Initialization</h3>\n<p>The following diagram illustrates the service initialization flow:</p>\n<pre><code class=\"language-mermaid\">flowchart TD\n    A[Create Service] --&gt; B[Call init Method]\n    B --&gt; C[Setup Resources]\n    C --&gt; D[Register Subscriptions]\n    D --&gt; E[Set State to Initialized]\n    E --&gt; F[Call start Method]\n    F --&gt; G[Register with Service Registry]\n    G --&gt; H[Set State to Running]\n    H --&gt; I[Begin Processing Requests]\n</code></pre>\n<p><strong>Subscription Setup:</strong></p>\n<ul>\n<li>Service subscriptions should be established during the initialization phase (<code>init</code> method)</li>\n<li>The <code>init</code> method MUST receive a RequestContext parameter to enable subscription registration</li>\n<li>Subscriptions should NEVER be set up in the <code>process_request</code> method</li>\n<li>Reasons for this pattern:<ul>\n<li>Ensures subscriptions are set up exactly once when the service starts</li>\n<li>Prevents redundant subscription setup on every request</li>\n<li>Maintains clear separation of concerns in the service lifecycle</li>\n<li>Improves performance by avoiding unnecessary subscription checks</li>\n</ul>\n</li>\n<li>If a service needs to verify subscriptions are active, use a private method that checks state rather than attempting to re-subscribe</li>\n<li>For dynamic subscriptions that depend on runtime parameters, create dedicated operations for subscription management</li>\n</ul>\n<p><strong>Service Initialization Flow:</strong></p>\n<ul>\n<li>Services should have a predictable initialization flow: create  init  start</li>\n<li>The <code>init</code> method is where all one-time setup like subscriptions should occur</li>\n<li>The <code>start</code> method should focus on activating the service&#39;s functionality</li>\n<li>Subscriptions registered during <code>init</code> should follow the service&#39;s lifecycle</li>\n<li>When a service is stopped, its subscriptions should be unregistered</li>\n</ul>\n<h2>P2P Architecture</h2>\n<h3>Service Discovery</h3>\n<p>The Kagi node system implements a comprehensive service discovery mechanism across the P2P network:</p>\n<ul>\n<li><strong>Service Advertisement</strong>: Services are automatically advertised to connected peers when registered</li>\n<li><strong>Remote Service Discovery</strong>: Services are discovered when connecting to peers in the P2P network</li>\n<li><strong>Service Lookup</strong>: The Node provides a <code>wait_for_service</code> method to wait for service availability</li>\n<li><strong>Service Availability</strong>: Services can be local or remote, with transparent access through the service registry</li>\n<li><strong>Timeout Support</strong>: Service discovery includes timeout mechanisms to prevent indefinite waiting</li>\n</ul>\n<pre><code class=\"language-rust\">// Wait for a service to become available with a 5-second timeout\nlet service_available = node.wait_for_service(&quot;remote_service&quot;, Some(5000)).await;\nif service_available {\n    // Service is ready to use\n} else {\n    // Handle service unavailable\n}\n</code></pre>\n<h3>Peer-to-Peer Communication</h3>\n<p>The P2P layer in Kagi nodes implements the following features:</p>\n<ul>\n<li><strong>Transport Protocol</strong>: QUIC-based transport for reliable, secure, and multiplexed communication</li>\n<li><strong>Peer Identification</strong>: Peers are identified by a PeerId derived from their public key</li>\n<li><strong>Network Participation</strong>: Peers can participate in multiple networks with network-specific keys</li>\n<li><strong>Access Control</strong>: Network access is controlled through cryptographic AccessTokens</li>\n<li><strong>Message Routing</strong>: Messages are routed to appropriate services across the P2P network</li>\n<li><strong>Discovery Mechanism</strong>: Peers discover each other using UDP multicast and DHT routing</li>\n<li><strong>NAT Traversal</strong>: STUN-like server and UDP hole punching for connectivity across NATs</li>\n</ul>\n<h3>Network Configuration</h3>\n<p>P2P functionality in Kagi nodes is configured through the Node configuration:</p>\n<pre><code class=\"language-rust\">// Example P2P configuration\nlet p2p_config = TransportConfig {\n    network_id: &quot;network_id&quot;.to_string(),\n    state_path: &quot;state_path&quot;.to_string(),\n    bootstrap_nodes: Some(vec![&quot;127.0.0.1:50601&quot;.to_string()]),\n    listen_addr: Some(&quot;127.0.0.1:50602&quot;.to_string()),\n};\n\n// Create and initialize node with P2P support\nlet mut node = Node::new(NodeConfig {\n    node_id: &quot;my_node&quot;.to_string(),\n    data_dir: &quot;./data&quot;.to_string(),\n    db_path: &quot;./data/db&quot;.to_string(),\n    p2p_config: Some(p2p_config),\n}).await?;\n</code></pre>\n<h2>Security Considerations</h2>\n<h3>Authentication</h3>\n<ul>\n<li>Services should authenticate requests when necessary</li>\n<li>P2P connections require mutual authentication through AccessTokens</li>\n<li>Authentication should be performed at the service boundary</li>\n</ul>\n<h3>Authorization</h3>\n<ul>\n<li>Services should implement appropriate authorization checks</li>\n<li>Access to sensitive operations should be restricted</li>\n<li>Access control should be enforced consistently across all services</li>\n</ul>\n<h3>Secure Communication</h3>\n<ul>\n<li>All P2P communication uses QUIC with TLS for encryption</li>\n<li>Service-to-service communication within a node is memory-safe</li>\n<li>External communication channels should be properly secured</li>\n</ul>\n<h2>Examples</h2>\n<p>This section will be expanded with practical examples.</p>\n",
    "path": "/core/architecture"
  },
  "core/readme": {
    "html": "<h1>Kagi Core Documentation</h1>\n<p>This directory contains documentation for the core components of the Kagi architecture. These documents explain the fundamental abstractions and systems that power the Kagi node.</p>\n<h2>Core Components</h2>\n<h3><a href=\"context.md\">Context System</a></h3>\n<p>The Context System enables secure and traceable communication between services. It provides:</p>\n<ul>\n<li>Request and lifecycle contexts for different operations</li>\n<li>Request metadata for tracing request chains</li>\n<li>Common interface for shared functionality</li>\n</ul>\n<h3><a href=\"vmap.md\">ValueMap (VMap)</a></h3>\n<p>VMap is a core abstraction for working with structured data that:</p>\n<ul>\n<li>Provides type-safe parameter extraction</li>\n<li>Reduces boilerplate code through intuitive macros</li>\n<li>Offers comprehensive error handling</li>\n<li>Integrates with Kagi&#39;s value type system</li>\n</ul>\n<h3><a href=\"logging.md\">Logging System</a></h3>\n<p>The Logging System provides a consistent, context-aware logging interface that:</p>\n<ul>\n<li>Works seamlessly in both asynchronous and synchronous code</li>\n<li>Automatically includes contextual metadata</li>\n<li>Supports structured logging for better filtering and analysis</li>\n<li>Manages ID truncation for improved readability</li>\n</ul>\n<h3><a href=\"request_handling.md\">Request Handling</a></h3>\n<p>The Request Handling document outlines best practices for service implementations:</p>\n<ul>\n<li>Guidelines for implementing the <code>handle_request</code> method</li>\n<li>Patterns for clean operation delegation</li>\n<li>Best practices for data format handling (JSON vs VMap)</li>\n<li>Recommendations for context-aware logging in request handlers</li>\n</ul>\n<h3><a href=\"lifecycle.md\">Service Lifecycle</a></h3>\n<p>The Service Lifecycle document details:</p>\n<ul>\n<li>Service state transitions (Created, Initialized, Running, Stopped)</li>\n<li>Best practices for implementing lifecycle methods</li>\n<li>Proper subscription setup during initialization</li>\n<li>Common anti-patterns to avoid in service implementation</li>\n</ul>\n<h2>Core Concepts Relationships</h2>\n<p>Understanding how these core components relate to each other is essential for effective Kagi development:</p>\n<ol>\n<li><p><strong>Service Lifecycle  Request Handling</strong>:</p>\n<ul>\n<li>Services follow a lifecycle (create  initialize  run  stop)</li>\n<li>Request handling occurs during the &quot;Running&quot; state</li>\n<li>Initialization (including subscription setup) must complete before handling requests</li>\n</ul>\n</li>\n<li><p><strong>Context System  Logging/Request Handling</strong>:</p>\n<ul>\n<li>Context provides the foundation for both logging and request handling</li>\n<li>RequestContext carries metadata across service boundaries</li>\n<li>LifecycleContext provides context during initialization and other lifecycle events</li>\n</ul>\n</li>\n<li><p><strong>VMap  Request Handling</strong>:</p>\n<ul>\n<li>VMap provides type-safe parameter extraction in request handlers</li>\n<li>It integrates with both JSON and Map formats used in service requests</li>\n</ul>\n</li>\n<li><p><strong>Logging  All Components</strong>:</p>\n<ul>\n<li>The logging system integrates with all other components</li>\n<li>Context-aware logging provides traceability across service boundaries</li>\n<li>Structured logging enables better operational insights</li>\n</ul>\n</li>\n</ol>\n<p>This diagram illustrates the relationships:</p>\n<pre><code>       \n Service                 Request         \n Lifecycle        Handling        \n       \n                                  \n                                  \n                 \n                                                  \n                    Context               \n                                                   \n                                          \n                 \n                        \n                                                          \n     Logging                                  VMap        \n                                                          \n                        \n                                                     \n                                                     \n                      \n                                        \n                                        \n                                   Service\n                                   Requests\n</code></pre>\n<h2>Common Anti-Patterns to Avoid</h2>\n<p>When developing services in Kagi, be aware of these common anti-patterns that can lead to inefficient or problematic code:</p>\n<h3>Subscription Setup During Request Handling</h3>\n<p><strong>Anti-Pattern</strong>: Setting up or checking subscriptions during request handling rather than during initialization.</p>\n<pre><code class=\"language-rust\">// DON&#39;T DO THIS: Checking subscriptions on every request\nasync fn handle_request(&amp;self, request: ServiceRequest) -&gt; Result&lt;ServiceResponse&gt; {\n    self.ensure_subscriptions(&amp;request.request_context).await?;\n    // ...\n}\n</code></pre>\n<p><strong>Best Practice</strong>: Set up all subscriptions during the <code>init</code> lifecycle method.</p>\n<pre><code class=\"language-rust\">// DO THIS: Set up subscriptions during initialization\nasync fn init(&amp;mut self, context: &amp;RequestContext) -&gt; Result&lt;()&gt; {\n    self.setup_subscriptions(context).await?;\n    // ...\n}\n</code></pre>\n<h3>Unnecessary Data Format Conversions</h3>\n<p><strong>Anti-Pattern</strong>: Converting data between formats (JSON to VMap or vice versa) when not necessary.</p>\n<p><strong>Best Practice</strong>: Process data in its original format when possible, especially when just passing it through or accessing a few fields.</p>\n<h3>Complex Logic in <code>handle_request</code></h3>\n<p><strong>Anti-Pattern</strong>: Implementing complex business logic directly in the <code>handle_request</code> method.</p>\n<p><strong>Best Practice</strong>: Keep <code>handle_request</code> focused on operation routing, delegating to specialized methods for each operation.</p>\n<p>For detailed explanations and examples of these anti-patterns, refer to the specific documentation pages.</p>\n<h2>Diagrams</h2>\n<p>The documentation includes Mermaid diagrams to visualize key concepts:</p>\n<ul>\n<li>Request Context Flow: How context propagates through service requests</li>\n<li>VMap Data Flow: How data flows through the VMap system</li>\n<li>Logging Flow: How the logging system processes log entries</li>\n<li>Service Lifecycle: State transitions during a service&#39;s lifecycle</li>\n</ul>\n<h2>Related Documentation</h2>\n<p>For more information on the overall architecture, see:</p>\n<ul>\n<li><a href=\"architecture.md\">Architecture Overview</a></li>\n<li><a href=\"p2p.md\">P2P Communication</a></li>\n<li><a href=\"discovery.md\">Service Discovery</a></li>\n<li><a href=\"system-diagrams.md\">System Diagrams</a></li>\n</ul>\n<h2>Contributing to Documentation</h2>\n<p>When updating or creating documentation in the Kagi core system, please follow these guidelines to maintain consistency:</p>\n<h3>Documentation Structure</h3>\n<p>Each core documentation file should include these standard sections:</p>\n<ol>\n<li><strong>Title</strong> - Clear title describing the component</li>\n<li><strong>Overview</strong> - Brief introduction to the component and its purpose</li>\n<li><strong>Key Features/Components</strong> - Bulleted list of main capabilities</li>\n<li><strong>Detailed Sections</strong> - In-depth explanation of specific aspects</li>\n<li><strong>Best Practices</strong> - Guidelines for effective use</li>\n<li><strong>Implementation Details</strong> - Technical information about the implementation</li>\n<li><strong>Related Documentation</strong> - Cross-references to related documentation</li>\n</ol>\n<h3>Cross-Referencing</h3>\n<ul>\n<li>Always include a &quot;Related Documentation&quot; section with links to related files</li>\n<li>Use relative links: <code>[Title](filename.md)</code></li>\n<li>Provide a brief description of why the related document is relevant</li>\n</ul>\n<h3>Visual Elements</h3>\n<ul>\n<li>Include diagrams where they add value (preferably using Mermaid)</li>\n<li>Keep ASCII diagrams simple and clear</li>\n<li>Ensure diagrams have explanatory text</li>\n</ul>\n<h3>Code Examples</h3>\n<ul>\n<li>Always include practical code examples</li>\n<li>Provide both basic and advanced usage examples</li>\n<li>Use consistent formatting with syntax highlighting</li>\n<li>Include comments in code examples</li>\n</ul>\n<p>By following these guidelines, we can maintain a high-quality, consistent documentation set that helps developers effectively use the Kagi framework. </p>\n",
    "path": "/core/readme"
  },
  "development/mobile": {
    "html": "<h1>iOS P2P Network Mobile App Specification</h1>\n<p>This specification defines an iOS mobile application built with Swift, designed to integrate with the Kagi Node P2P network architecture. The app leverages QUIC for transport, Kademlia DHT for decentralized storage, and implements the secure key management system defined in the Keys Management Specification.</p>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#introduction\">Introduction</a></li>\n<li><a href=\"#alignment-with-kagi-node-architecture\">Alignment with Kagi Node Architecture</a></li>\n<li><a href=\"#key-features\">Key Features</a></li>\n<li><a href=\"#requirements\">Requirements</a><ul>\n<li><a href=\"#functional-requirements\">Functional Requirements</a></li>\n<li><a href=\"#non-functional-requirements\">Non-Functional Requirements</a></li>\n</ul>\n</li>\n<li><a href=\"#architecture\">Architecture</a><ul>\n<li><a href=\"#components\">Components</a></li>\n<li><a href=\"#data-model\">Data Model</a></li>\n<li><a href=\"#integration-with-kagi-node\">Integration with Kagi Node</a></li>\n</ul>\n</li>\n<li><a href=\"#key-management-system\">Key Management System</a><ul>\n<li><a href=\"#key-types\">Key Types</a></li>\n<li><a href=\"#hd-key-derivation\">HD Key Derivation</a></li>\n<li><a href=\"#key-generation\">Key Generation</a></li>\n<li><a href=\"#key-storage\">Key Storage</a></li>\n<li><a href=\"#access-tokens\">Access Tokens</a></li>\n</ul>\n</li>\n<li><a href=\"#p2p-transport-layer\">P2P Transport Layer</a><ul>\n<li><a href=\"#quic-integration\">QUIC Integration</a></li>\n<li><a href=\"#message-handling\">Message Handling</a></li>\n<li><a href=\"#dht-operations\">DHT Operations</a></li>\n<li><a href=\"#nat-traversal\">NAT Traversal</a></li>\n</ul>\n</li>\n<li><a href=\"#discovery-mechanism\">Discovery Mechanism</a><ul>\n<li><a href=\"#udp-multicast\">UDP Multicast</a></li>\n<li><a href=\"#message-format\">Message Format</a></li>\n<li><a href=\"#peer-discovery\">Peer Discovery</a></li>\n</ul>\n</li>\n<li><a href=\"#user-interface\">User Interface</a><ul>\n<li><a href=\"#structure\">Structure</a></li>\n<li><a href=\"#screens\">Screens</a></li>\n<li><a href=\"#ux-workflows\">UX Workflows</a></li>\n</ul>\n</li>\n<li><a href=\"#qr-code-system\">QR Code System</a><ul>\n<li><a href=\"#use-cases\">Use Cases</a></li>\n<li><a href=\"#data-encoding\">Data Encoding</a></li>\n<li><a href=\"#token-exchange-workflow\">Token Exchange Workflow</a></li>\n<li><a href=\"#implementation\">Implementation</a></li>\n</ul>\n</li>\n<li><a href=\"#implementation-details\">Implementation Details</a><ul>\n<li><a href=\"#dependencies\">Dependencies</a></li>\n<li><a href=\"#permissions\">Permissions</a></li>\n<li><a href=\"#error-handling\">Error Handling</a></li>\n<li><a href=\"#security-measures\">Security Measures</a></li>\n</ul>\n</li>\n<li><a href=\"#complete-workflows\">Complete Workflows</a><ul>\n<li><a href=\"#network-creation-workflow\">Network Creation Workflow</a></li>\n<li><a href=\"#network-joining-workflow\">Network Joining Workflow</a></li>\n<li><a href=\"#peer-connection-workflow\">Peer Connection Workflow</a></li>\n<li><a href=\"#dht-interaction-workflow\">DHT Interaction Workflow</a></li>\n</ul>\n</li>\n</ol>\n<h2>Introduction</h2>\n<p>This mobile application provides a native iOS interface to the Kagi Node P2P network architecture. It implements the cryptographic identity system, transport layer, and distributed hash table functionality defined in the core Kagi specifications, while providing intuitive mobile-specific interfaces for network participation.</p>\n<h2>Alignment with Kagi Node Architecture</h2>\n<p>The iOS application fully aligns with the core Kagi Node architecture:</p>\n<ul>\n<li><strong>P2P Transport Layer</strong>: Implements the QUIC-based transport protocol as defined in the P2P Transport Layer Specification</li>\n<li><strong>Key Management</strong>: Follows the hierarchical deterministic (HD) key derivation system defined in the Keys Management Specification</li>\n<li><strong>DHT Implementation</strong>: Uses the Kademlia-based distributed hash table for decentralized storage and peer discovery</li>\n<li><strong>Discovery Mechanism</strong>: Implements the UDP multicast discovery protocol for local peer discovery</li>\n<li><strong>Network Access Control</strong>: Enforces the AccessToken system for network access control and authentication</li>\n</ul>\n<h2>Key Features</h2>\n<ul>\n<li><strong>Full P2P Compatibility</strong>: Seamless interaction with desktop and server Kagi Node instances</li>\n<li><strong>Key Management</strong>: Generate, derive, and securely store cryptographic keys according to the Keys Management Specification</li>\n<li><strong>QR Code Interface</strong>: Exchange network metadata, access tokens, and connection details through a QR code interface</li>\n<li><strong>Modern UI</strong>: SwiftUI-based interface providing intuitive access to P2P functionality</li>\n<li><strong>Offline Operation</strong>: Support for local network operation without internet connectivity</li>\n</ul>\n<h2>Requirements</h2>\n<h3>Functional Requirements</h3>\n<ul>\n<li><p><strong>Network Administration</strong>:</p>\n<ul>\n<li>Create new networks (generate NetworkId via HD derivation from master key)</li>\n<li>Issue access tokens to peers with configurable expiration</li>\n<li>Manage network metadata and access control</li>\n</ul>\n</li>\n<li><p><strong>Network Participation</strong>:</p>\n<ul>\n<li>Join existing networks using AccessTokens</li>\n<li>Discover peers through multicast UDP and DHT routing</li>\n<li>Connect to peers using QUIC transport with NAT traversal</li>\n</ul>\n</li>\n<li><p><strong>Peer Functionality</strong>:</p>\n<ul>\n<li>Send and receive messages to/from specific peers</li>\n<li>Store and retrieve data in the network-specific DHT</li>\n<li>Subscribe to topics and publish events</li>\n</ul>\n</li>\n<li><p><strong>QR Code Interface</strong>:</p>\n<ul>\n<li>Generate QR codes for sharing network metadata and tokens</li>\n<li>Scan QR codes to join networks and connect to peers</li>\n<li>Display peer&#39;s connection details as QR code for easy pairing</li>\n</ul>\n</li>\n</ul>\n<h3>Non-Functional Requirements</h3>\n<ul>\n<li><strong>Platform</strong>: iOS 17+</li>\n<li><strong>Performance</strong>: Low-latency message delivery and DHT operations</li>\n<li><strong>Security</strong>: Secure storage for keys, validated token exchange</li>\n<li><strong>Usability</strong>: Simplified UX for complex P2P operations</li>\n<li><strong>Connectivity</strong>: Operation across cellular networks with NAT traversal</li>\n</ul>\n<h2>Architecture</h2>\n<h3>Components</h3>\n<ul>\n<li><p><strong>Core Rust Libraries</strong> (compiled for iOS):</p>\n<ul>\n<li><code>kagi-transport</code>: Implements QUIC transport, DHT, and message routing</li>\n<li><code>kagi-keys</code>: Implements the HD key derivation and token management</li>\n<li><code>kagi-discovery</code>: Implements the UDP multicast discovery protocol</li>\n</ul>\n</li>\n<li><p><strong>Swift Wrapper Layer</strong>:</p>\n<ul>\n<li>FFI bindings to the Rust core</li>\n<li>Asynchronous APIs using Swift Concurrency (async/await)</li>\n<li>Type-safe interfaces for Rust functionality</li>\n</ul>\n</li>\n<li><p><strong>Application Layer</strong>:</p>\n<ul>\n<li><strong>UI Module</strong>: SwiftUI views and view models</li>\n<li><strong>Key Management Module</strong>: Interface to key generation and storage</li>\n<li><strong>Network Module</strong>: Handles connections and message routing</li>\n<li><strong>QR Code Module</strong>: Generates and processes QR codes</li>\n</ul>\n</li>\n</ul>\n<h3>Data Model</h3>\n<p>The application uses the same data model defined in the core specifications:</p>\n<ul>\n<li><strong>PeerId</strong>: 32-byte SHA-256 hash of the peer&#39;s Ed25519 public key</li>\n<li><strong>NetworkId</strong>: 32-byte Ed25519 public key derived from administrator&#39;s master key</li>\n<li><strong>AccessToken</strong>: Structure containing peer_id, network_id, expiration time, and a cryptographic signature</li>\n<li><strong>Connection</strong>: Represents a QUIC connection to a remote peer</li>\n<li><strong>NetworkMetadata</strong>: Contains information about a network (name, admin public key, etc.)</li>\n</ul>\n<h3>Integration with Kagi Node</h3>\n<p>The mobile app represents a fully-functional Kagi Node that implements the same interfaces and protocols as the desktop/server version:</p>\n<pre><code class=\"language-swift\">/// The primary interface to the Kagi Node functionality\nclass KagiNode {\n    /// Initialize the node with configuration\n    init(config: NodeConfig) async throws\n    \n    /// Get the node&#39;s peer ID\n    var peerId: PeerId { get }\n    \n    /// Send a message to a specific peer\n    func sendToPeer&lt;T: Encodable&gt;(_ message: T, peerId: PeerId) async throws\n    \n    /// Broadcast a message to multiple peers\n    func broadcast&lt;T: Encodable&gt;(_ message: T, peerIds: [PeerId]) async throws\n    \n    /// Listen for incoming messages\n    func startListening() -&gt; AsyncStream&lt;(PeerId, Data)&gt;\n    \n    /// Store a value in the DHT\n    func dhtPut(networkId: NetworkId, key: Data, value: Data) async throws\n    \n    /// Retrieve a value from the DHT\n    func dhtGet(networkId: NetworkId, key: Data) async throws -&gt; Data?\n    \n    /// Add an access token for a network\n    func addNetworkToken(networkId: NetworkId, token: AccessToken)\n    \n    /// Connect to a peer using their address\n    func connectToPeer(peerId: PeerId, networkId: NetworkId, address: String) async throws -&gt; Connection\n    \n    /// Subscribe to network events\n    func subscribe(networkId: NetworkId, topic: String, handler: @escaping (Data) -&gt; Void) -&gt; Subscription\n    \n    /// Publish an event to the network\n    func publish(networkId: NetworkId, topic: String, message: Data) async throws\n}\n</code></pre>\n<h2>Key Management System</h2>\n<h3>Key Types</h3>\n<p>The application implements the three key types defined in the Keys Management specification:</p>\n<ol>\n<li><strong>Master Key</strong>: Ed25519 key pair used by administrators to derive network keys</li>\n<li><strong>Network Key</strong>: Ed25519 key pair derived from the master key, where the public key serves as the NetworkId</li>\n<li><strong>Peer Key</strong>: Unique Ed25519 key pair generated for each device, where the PeerId is the SHA-256 hash of the public key</li>\n</ol>\n<h3>HD Key Derivation</h3>\n<p>The application implements hierarchical deterministic key derivation for network keys following the specification:</p>\n<pre><code class=\"language-swift\">/// Derives a network key from the master key\nfunc deriveNetworkKey(masterKey: Ed25519PrivateKey, networkIndex: UInt32) -&gt; Ed25519KeyPair {\n    // Use BIP-32 path m/44&#39;/0&#39;/networkIndex&#39;\n    let path = &quot;m/44&#39;/0&#39;/\\(networkIndex)&#39;&quot;\n    return rustFFI.deriveEd25519Key(masterKey: masterKey.rawRepresentation, path: path)\n}\n</code></pre>\n<h3>Key Generation</h3>\n<p>For key generation, the application uses:</p>\n<ul>\n<li>Swift CryptoKit for generating Ed25519 keys</li>\n<li>Rust FFI for HD derivation of network keys from master keys</li>\n</ul>\n<pre><code class=\"language-swift\">/// Generate a new master key\nfunc generateMasterKey() -&gt; Ed25519KeyPair {\n    let privateKey = Curve25519.Signing.PrivateKey()\n    return Ed25519KeyPair(privateKey: privateKey, publicKey: privateKey.publicKey)\n}\n\n/// Generate a new peer key\nfunc generatePeerKey() -&gt; Ed25519KeyPair {\n    let privateKey = Curve25519.Signing.PrivateKey()\n    return Ed25519KeyPair(privateKey: privateKey, publicKey: privateKey.publicKey)\n}\n</code></pre>\n<h3>Key Storage</h3>\n<p>Keys are securely stored in the iOS Keychain with appropriate protection levels:</p>\n<pre><code class=\"language-swift\">/// Store a private key in the Keychain\nfunc storePrivateKey(_ key: Ed25519PrivateKey, withIdentifier identifier: String) throws {\n    let query: [String: Any] = [\n        kSecClass as String: kSecClassGenericPassword,\n        kSecAttrAccount as String: identifier,\n        kSecValueData as String: key.rawRepresentation,\n        kSecAttrAccessible as String: kSecAttrAccessibleWhenUnlockedThisDeviceOnly\n    ]\n    \n    // Add to keychain\n    let status = SecItemAdd(query as CFDictionary, nil)\n    guard status == errSecSuccess else {\n        throw KeychainError.unableToStore\n    }\n}\n</code></pre>\n<h3>Access Tokens</h3>\n<p>The application implements the AccessToken structure as defined in the Keys Management specification:</p>\n<pre><code class=\"language-swift\">struct AccessToken: Codable {\n    let peerId: PeerId\n    let networkId: NetworkId\n    let expiration: Date?\n    let signature: Data\n    \n    /// Create a new access token and sign it with the network&#39;s private key\n    static func create(peerId: PeerId, \n                      networkId: NetworkId, \n                      networkPrivateKey: Ed25519PrivateKey, \n                      expiration: Date? = nil) -&gt; AccessToken {\n        // Create token data\n        let tokenData = peerId.rawRepresentation + \n                       networkId.rawRepresentation + \n                       (expiration?.timeIntervalSince1970.data ?? Data())\n        \n        // Sign token data\n        let signature = try! networkPrivateKey.signature(for: tokenData)\n        \n        return AccessToken(\n            peerId: peerId,\n            networkId: networkId,\n            expiration: expiration,\n            signature: signature\n        )\n    }\n    \n    /// Verify the token using the network&#39;s public key (NetworkId)\n    func verify() -&gt; Bool {\n        let tokenData = peerId.rawRepresentation + \n                       networkId.rawRepresentation + \n                       (expiration?.timeIntervalSince1970.data ?? Data())\n        \n        return try! networkId.isValidSignature(signature, for: tokenData)\n    }\n}\n</code></pre>\n<h2>P2P Transport Layer</h2>\n<h3>QUIC Integration</h3>\n<p>The application integrates with the Rust &#39;quinn&#39; library via FFI to implement QUIC transport:</p>\n<pre><code class=\"language-swift\">class QuinnTransport {\n    private var endpoint: OpaquePointer?\n    \n    /// Initialize the QUIC transport\n    init() throws {\n        endpoint = rustFFI.quinnCreateEndpoint()\n        guard endpoint != nil else {\n            throw TransportError.initializationFailed\n        }\n    }\n    \n    /// Connect to a remote peer\n    func connect(to address: String) throws -&gt; Connection {\n        let conn = rustFFI.quinnConnect(endpoint, address)\n        guard let conn = conn else {\n            throw TransportError.connectionFailed\n        }\n        return Connection(pointer: conn)\n    }\n    \n    /// Send data over a connection\n    func send(data: Data, over connection: Connection) throws {\n        let result = rustFFI.quinnSend(connection.pointer, data.baseAddress, data.count)\n        if result != 0 {\n            throw TransportError.sendFailed\n        }\n    }\n    \n    /// Start listening for incoming connections\n    func startListening() -&gt; AsyncStream&lt;Connection&gt; {\n        // Implementation omitted for brevity\n        // Returns AsyncStream of new connections\n    }\n}\n</code></pre>\n<h3>Message Handling</h3>\n<p>The application implements the message sending and receiving APIs defined in the P2P Transport specification:</p>\n<pre><code class=\"language-swift\">extension KagiNode {\n    /// Send a message to a specific peer\n    func sendToPeer&lt;T: Encodable&gt;(_ message: T, peerId: PeerId) async throws {\n        // Serialize the message using Bincode\n        let data = try Bincode.serialize(message)\n        \n        // Get connection to peer\n        let connection = try await getOrCreateConnection(to: peerId)\n        \n        // Send over QUIC\n        try transport.send(data: data, over: connection)\n    }\n    \n    /// Broadcast a message to multiple peers\n    func broadcast&lt;T: Encodable&gt;(_ message: T, peerIds: [PeerId]) async throws {\n        // Serialize the message once using Bincode\n        let data = try Bincode.serialize(message)\n        \n        // Send to each peer\n        try await withThrowingTaskGroup(of: Void.self) { group in\n            for peerId in peerIds {\n                group.addTask {\n                    let connection = try await self.getOrCreateConnection(to: peerId)\n                    try self.transport.send(data: data, over: connection)\n                }\n            }\n        }\n    }\n    \n    /// Start listening for incoming messages\n    func startListening() -&gt; AsyncStream&lt;(PeerId, Data)&gt; {\n        // Implementation returns AsyncStream of (PeerId, message data) tuples\n    }\n}\n</code></pre>\n<h3>DHT Operations</h3>\n<p>The application implements DHT operations with caching support:</p>\n<pre><code class=\"language-swift\">extension KagiNode {\n    /// Store a value in the DHT with optional caching\n    func dhtPut(networkId: NetworkId, key: Data, value: Data, cache: Bool = true) async throws {\n        // Store in DHT\n        try await rustFFI.dhtPut(networkId: networkId.rawRepresentation,\n                               key: key,\n                               value: value)\n        \n        // Update cache if enabled\n        if cache {\n            try await rustFFI.cacheSet(networkId: networkId.rawRepresentation,\n                                    key: key,\n                                    value: value)\n        }\n    }\n    \n    /// Retrieve a value from the DHT with caching\n    func dhtGet(networkId: NetworkId, key: Data) async throws -&gt; Data? {\n        // Check cache first\n        if let cached = try await rustFFI.cacheGet(networkId: networkId.rawRepresentation,\n                                                 key: key) {\n            return cached\n        }\n        \n        // Fallback to DHT\n        return try await rustFFI.dhtGet(networkId: networkId.rawRepresentation,\n                                     key: key)\n    }\n    \n    /// Bootstrap the DHT with a known peer\n    func dhtBootstrap(networkId: NetworkId, bootstrapPeer: PeerId) async throws {\n        try await rustFFI.dhtBootstrap(networkId: networkId.rawRepresentation,\n                                     bootstrapPeer: bootstrapPeer.rawRepresentation)\n    }\n}\n</code></pre>\n<h3>Metrics Collection</h3>\n<p>The application implements P2P metrics collection:</p>\n<pre><code class=\"language-swift\">class P2PMetrics {\n    // Connection metrics\n    private let activeConnections: Gauge\n    private let totalConnections: Counter\n    private let failedConnections: Counter\n    \n    // Network metrics\n    private let activeNetworks: Gauge\n    private let peersPerNetwork: Histogram\n    \n    // Message metrics\n    private let messagesSent: Counter\n    private let messagesReceived: Counter\n    private let messageSize: Histogram\n    \n    // DHT metrics\n    private let dhtOperations: Counter\n    private let dhtLatency: Histogram\n    private let dhtStorageSize: Gauge\n    \n    // Token metrics\n    private let tokenValidations: Counter\n    private let tokenValidationFailures: Counter\n    \n    func recordConnection(success: Bool) {\n        totalConnections.increment()\n        if success {\n            activeConnections.increment()\n        } else {\n            failedConnections.increment()\n        }\n    }\n    \n    func recordMessage(size: Int, isOutbound: Bool) {\n        messageSize.observe(Double(size))\n        if isOutbound {\n            messagesSent.increment()\n        } else {\n            messagesReceived.increment()\n        }\n    }\n    \n    func recordDHTOperation(type: String, duration: TimeInterval) {\n        dhtOperations.increment(labels: [&quot;type&quot;: type])\n        dhtLatency.observe(duration)\n    }\n}\n\nclass NetworkMetrics {\n    // Peer metrics\n    private let activePeers: Gauge\n    private let peerMessageRates: Histogram\n    private let peerLatencies: Histogram\n    \n    // Bandwidth metrics\n    private let bytesSent: Counter\n    private let bytesReceived: Counter\n    private let bandwidthUsage: Histogram\n    \n    // Discovery metrics\n    private let discoveryAttempts: Counter\n    private let discoverySuccesses: Counter\n    private let discoveryTime: Histogram\n    \n    func recordPeerMessage(peerId: PeerId, size: Int, duration: TimeInterval) {\n        peerMessageRates.observe(1.0)\n        peerLatencies.observe(duration)\n        bytesSent.increment(by: UInt64(size))\n    }\n    \n    func recordDiscovery(success: Bool, duration: TimeInterval) {\n        discoveryAttempts.increment()\n        if success {\n            discoverySuccesses.increment()\n            discoveryTime.observe(duration)\n        }\n    }\n}\n</code></pre>\n<h3>Cache Management</h3>\n<p>The application implements cache management through service actions:</p>\n<pre><code class=\"language-swift\">extension KagiNode {\n    /// Clear cache for a service\n    func clearCache(service: String) async throws {\n        try await request(&quot;\\(service)/cache/clear&quot;, [:])\n    }\n    \n    /// Delete specific cache entry\n    func deleteCache(service: String, key: String) async throws {\n        try await request(&quot;\\(service)/cache/delete&quot;,\n                        [&quot;key&quot;: key])\n    }\n    \n    /// Revoke cache entries by pattern\n    func revokeCache(service: String, pattern: String) async throws {\n        try await request(&quot;\\(service)/cache/revoke&quot;,\n                        [&quot;pattern&quot;: pattern])\n    }\n}\n</code></pre>\n<h3>NAT Traversal</h3>\n<p>The application implements NAT traversal using a custom STUN-like server and UDP hole punching:</p>\n<pre><code class=\"language-swift\">class NATTraversal {\n    /// Get the device&#39;s public endpoint (IP:port)\n    func getPublicEndpoint(localPort: UInt16, stunServer: String) async throws -&gt; String {\n        return try await rustFFI.getPublicEndpoint(localPort: localPort, \n                                                 stunServer: stunServer)\n    }\n    \n    /// Perform UDP hole punching to establish connectivity\n    func punchHole(localPort: UInt16, peerAddress: String) async throws {\n        try await rustFFI.punchHole(localPort: localPort, \n                                   peerAddress: peerAddress)\n    }\n}\n</code></pre>\n<h2>Discovery Mechanism</h2>\n<h3>UDP Multicast</h3>\n<p>The application implements the discovery mechanism defined in the Discovery specification:</p>\n<pre><code class=\"language-swift\">class DiscoveryService {\n    private let multicastAddress = &quot;239.255.255.250&quot;\n    private let multicastPort: UInt16 = 4445\n    \n    /// Start the discovery service\n    func start() throws {\n        try rustFFI.startDiscovery(multicastAddress: multicastAddress, \n                                  multicastPort: multicastPort)\n    }\n    \n    /// Stop the discovery service\n    func stop() {\n        rustFFI.stopDiscovery()\n    }\n    \n    /// Add a network to announce\n    func addNetwork(networkId: NetworkId, token: AccessToken) {\n        rustFFI.addNetworkToDiscovery(\n            networkId: networkId.rawRepresentation,\n            token: token.serialize()\n        )\n    }\n    \n    /// Get discovered peers for a network\n    func getDiscoveredPeers(for networkId: NetworkId) -&gt; [DiscoveredPeer] {\n        return rustFFI.getDiscoveredPeers(networkId: networkId.rawRepresentation)\n            .map { DiscoveredPeer(fromRawPeer: $0) }\n    }\n}\n</code></pre>\n<h3>Message Format</h3>\n<p>The discovery message format follows the specification:</p>\n<pre><code class=\"language-swift\">struct DiscoveryMessage: Codable {\n    let peerId: String // Base64-encoded peer ID\n    let networks: [NetworkEntry]\n    let ip: String\n    let port: UInt16\n    let timestamp: UInt64\n    let version: String\n    \n    struct NetworkEntry: Codable {\n        let networkId: String // Base64-encoded network ID\n        let token: String // Base64-encoded access token\n    }\n}\n</code></pre>\n<h3>Peer Discovery</h3>\n<p>The application discovers peers through both local network multicast and DHT routing:</p>\n<pre><code class=\"language-swift\">extension KagiNode {\n    /// Discover peers for a network\n    func discoverPeers(for networkId: NetworkId) async -&gt; [DiscoveredPeer] {\n        // Get peers from local discovery\n        let localPeers = discoveryService.getDiscoveredPeers(for: networkId)\n        \n        // Get peers from DHT\n        let dhtPeers = try? await rustFFI.dhtFindPeers(networkId: networkId.rawRepresentation)\n            .map { DiscoveredPeer(fromDHTPeer: $0) } ?? []\n        \n        // Combine and deduplicate\n        return Array(Set(localPeers + dhtPeers))\n    }\n}\n</code></pre>\n<h2>User Interface</h2>\n<h3>Structure</h3>\n<p>The application uses SwiftUI with a TabView-based interface containing the following tabs:</p>\n<ol>\n<li><strong>Networks</strong>: Manage and join P2P networks</li>\n<li><strong>Peers</strong>: View and connect to peers within selected network</li>\n<li><strong>Data</strong>: Interact with the DHT and messages</li>\n<li><strong>Settings</strong>: Configure application and manage keys</li>\n</ol>\n<h3>Screens</h3>\n<p>The application includes the following key screens:</p>\n<ul>\n<li><strong>Network List</strong>: Display joined networks with status indicators</li>\n<li><strong>Network Detail</strong>: Show peers and network information</li>\n<li><strong>Create Network</strong>: Generate a new network as an administrator</li>\n<li><strong>Join Network</strong>: Scan QR code to join an existing network</li>\n<li><strong>Peer List</strong>: Show active and discovered peers in a network</li>\n<li><strong>Peer Detail</strong>: Display information about a peer and connection status</li>\n<li><strong>Connect to Peer</strong>: Scan QR code to connect to a specific peer</li>\n<li><strong>DHT Browser</strong>: Interface for storing and retrieving data in the DHT</li>\n<li><strong>Key Management</strong>: View, export, and generate cryptographic keys</li>\n</ul>\n<h3>UX Workflows</h3>\n<p>The UI facilitates the following key workflows:</p>\n<ol>\n<li><p><strong>Network Creation</strong>:</p>\n<ul>\n<li>Generate/select master key</li>\n<li>Specify network name and settings</li>\n<li>Create network (derive network key)</li>\n<li>Display QR code for others to join</li>\n</ul>\n</li>\n<li><p><strong>Network Joining</strong>:</p>\n<ul>\n<li>Scan network QR code</li>\n<li>Generate/select peer key</li>\n<li>Request access token (display PeerId QR)</li>\n<li>Scan token QR code</li>\n<li>Complete joining process</li>\n</ul>\n</li>\n<li><p><strong>Peer Connection</strong>:</p>\n<ul>\n<li>Select peer to connect to</li>\n<li>Display/scan connection QR code</li>\n<li>Establish QUIC connection</li>\n<li>Display connected status</li>\n</ul>\n</li>\n<li><p><strong>DHT Interaction</strong>:</p>\n<ul>\n<li>Browse DHT key-value pairs</li>\n<li>Store new values</li>\n<li>Retrieve existing values</li>\n<li>Monitor DHT activity</li>\n</ul>\n</li>\n</ol>\n<h2>QR Code System</h2>\n<h3>Use Cases</h3>\n<p>The QR code system facilitates three primary use cases:</p>\n<ol>\n<li><strong>Network Sharing</strong>: Administrator shares network metadata for joining</li>\n<li><strong>Token Issuance</strong>: Administrator grants access to a peer</li>\n<li><strong>Connection Exchange</strong>: Peers share connection details for direct connection</li>\n</ol>\n<h3>Data Encoding</h3>\n<p>Each QR code type encodes specific JSON data, base64-encoded where appropriate, and cryptographically signed:</p>\n<ol>\n<li><p><strong>Network Metadata QR Code</strong>:</p>\n<pre><code class=\"language-json\">{\n  &quot;type&quot;: &quot;network&quot;,\n  &quot;network_id&quot;: &quot;&lt;base64_encoded_network_id&gt;&quot;,\n  &quot;name&quot;: &quot;&lt;network_name&gt;&quot;,\n  &quot;admin_pubkey&quot;: &quot;&lt;base64_encoded_admin_public_key&gt;&quot;,\n  &quot;signature&quot;: &quot;&lt;base64_encoded_signature&gt;&quot;\n}\n</code></pre>\n</li>\n<li><p><strong>Access Token QR Code</strong>:</p>\n<pre><code class=\"language-json\">{\n  &quot;type&quot;: &quot;token&quot;,\n  &quot;peer_id&quot;: &quot;&lt;base64_encoded_peer_id&gt;&quot;,\n  &quot;network_id&quot;: &quot;&lt;base64_encoded_network_id&gt;&quot;,\n  &quot;expiration&quot;: &quot;&lt;unix_timestamp_or_null&gt;&quot;,\n  &quot;signature&quot;: &quot;&lt;base64_encoded_signature&gt;&quot;\n}\n</code></pre>\n</li>\n<li><p><strong>Peer Connection QR Code</strong>:</p>\n<pre><code class=\"language-json\">{\n  &quot;type&quot;: &quot;peer&quot;,\n  &quot;peer_id&quot;: &quot;&lt;base64_encoded_peer_id&gt;&quot;,\n  &quot;network_id&quot;: &quot;&lt;base64_encoded_network_id&gt;&quot;,\n  &quot;address&quot;: &quot;&lt;ip:port&gt;&quot;,\n  &quot;token&quot;: &quot;&lt;base64_encoded_access_token&gt;&quot;\n}\n</code></pre>\n</li>\n</ol>\n<h3>Token Exchange Workflow</h3>\n<p>The application implements a secure token exchange workflow:</p>\n<ol>\n<li><p><strong>Administrator</strong>:</p>\n<ul>\n<li>Creates network (derives NetworkId)</li>\n<li>Displays Network Metadata QR code</li>\n</ul>\n</li>\n<li><p><strong>Joining Peer</strong>:</p>\n<ul>\n<li>Scans Network Metadata QR code</li>\n<li>Generates/selects Peer Key</li>\n<li>Displays PeerId QR code</li>\n</ul>\n</li>\n<li><p><strong>Administrator</strong>:</p>\n<ul>\n<li>Scans PeerId QR code</li>\n<li>Creates AccessToken for the peer</li>\n<li>Displays AccessToken QR code</li>\n</ul>\n</li>\n<li><p><strong>Joining Peer</strong>:</p>\n<ul>\n<li>Scans AccessToken QR code</li>\n<li>Verifies token with NetworkId</li>\n<li>Stores token for network participation</li>\n</ul>\n</li>\n</ol>\n<h3>Implementation</h3>\n<p>The QR code functionality is implemented using:</p>\n<ul>\n<li><code>CoreImage</code> for QR code generation</li>\n<li><code>AVFoundation</code> for QR code scanning</li>\n<li>Native Swift cryptography for signature verification</li>\n</ul>\n<pre><code class=\"language-swift\">class QRCodeGenerator {\n    /// Generate a QR code from data\n    func generateQRCode(from string: String) -&gt; UIImage? {\n        guard let data = string.data(using: .utf8) else { return nil }\n        \n        if let filter = CIFilter(name: &quot;CIQRCodeGenerator&quot;) {\n            filter.setValue(data, forKey: &quot;inputMessage&quot;)\n            filter.setValue(&quot;M&quot;, forKey: &quot;inputCorrectionLevel&quot;)\n            \n            if let outputImage = filter.outputImage {\n                // Scale the image\n                let transform = CGAffineTransform(scaleX: 10, y: 10)\n                let scaledImage = outputImage.transformed(by: transform)\n                \n                return UIImage(ciImage: scaledImage)\n            }\n        }\n        \n        return nil\n    }\n}\n\nclass QRCodeScanner {\n    /// Scan a QR code and return the decoded data\n    func scanQRCode() -&gt; AsyncStream&lt;String&gt; {\n        // Implementation omitted for brevity\n        // Returns AsyncStream of decoded QR code strings\n    }\n}\n</code></pre>\n<h2>Implementation Details</h2>\n<h3>Dependencies</h3>\n<p>The application uses the following dependencies:</p>\n<pre><code class=\"language-swift\">// Package.swift\ndependencies: [\n    .package(url: &quot;https://github.com/kagi/kagi-node-swift.git&quot;, from: &quot;1.0.0&quot;),\n    .package(url: &quot;https://github.com/apple/swift-metrics.git&quot;, from: &quot;2.0.0&quot;),\n    .package(url: &quot;https://github.com/apple/swift-nio.git&quot;, from: &quot;2.0.0&quot;)\n]\n</code></pre>\n<h3>Permissions</h3>\n<p>The application requires the following permissions, properly declared in Info.plist:</p>\n<ul>\n<li><code>NSCameraUsageDescription</code>: Required for QR code scanning</li>\n<li><code>NSLocalNetworkUsageDescription</code>: Required for peer discovery</li>\n<li><code>NSBonjourServices</code>: Required for service advertisement/discovery</li>\n<li><code>NSFaceIDUsageDescription</code>: Optional for securing key access with biometrics</li>\n</ul>\n<h3>Error Handling</h3>\n<p>The application implements comprehensive error handling:</p>\n<ul>\n<li>Network connectivity issues with retry logic</li>\n<li>QR code scanning/parsing errors with user feedback</li>\n<li>Cryptographic operation failures with appropriate messaging</li>\n<li>DHT operation timeouts with configurable retry policies</li>\n</ul>\n<h3>Security Measures</h3>\n<p>The application implements the following security measures:</p>\n<ul>\n<li>Secure key storage in the iOS Keychain</li>\n<li>Biometric authentication for sensitive operations</li>\n<li>Validation of all cryptographic signatures</li>\n<li>Encryption of all network traffic via QUIC</li>\n<li>Token verification before connection establishment</li>\n<li>Timestamp validation to prevent replay attacks</li>\n</ul>\n<h2>Complete Workflows</h2>\n<h3>Network Creation Workflow</h3>\n<ol>\n<li><p>Administrator generates or selects a master key</p>\n</li>\n<li><p>Administrator creates a new network:</p>\n<pre><code class=\"language-swift\">// Generate or load master key\nlet masterKey = keyStore.getMasterKey() ?? keyStore.generateMasterKey()\n\n// Derive network key (networkIndex distinguishes multiple networks)\nlet networkKey = keyDerivation.deriveNetworkKey(masterKey: masterKey, networkIndex: 0)\n\n// Create network metadata\nlet networkMetadata = NetworkMetadata(\n    networkId: NetworkId(publicKey: networkKey.publicKey),\n    name: &quot;My Personal Network&quot;,\n    adminPublicKey: masterKey.publicKey\n)\n\n// Sign the metadata\nnetworkMetadata.sign(with: masterKey.privateKey)\n\n// Generate QR code for network joining\nlet qrCode = qrGenerator.generateNetworkQR(from: networkMetadata)\n\n// Display QR code to users who want to join\ndisplayQRCodeView.showQRCode(qrCode)\n</code></pre>\n</li>\n<li><p>Administrator displays the Network Metadata QR code for peers to scan</p>\n</li>\n<li><p>When a peer requests access (by showing their PeerId QR):</p>\n<pre><code class=\"language-swift\">// Scan peer&#39;s QR code to get their PeerId\nlet peerIdString = await qrScanner.scanQRCode().first(where: { _ in true })\nlet peerId = PeerId(base64Encoded: peerIdString)\n\n// Create access token for the peer with 30-day expiration\nlet expirationDate = Calendar.current.date(byAdding: .day, value: 30, to: Date())\nlet accessToken = AccessToken.create(\n    peerId: peerId,\n    networkId: networkMetadata.networkId,\n    networkPrivateKey: networkKey.privateKey,\n    expiration: expirationDate\n)\n\n// Generate QR code with the access token\nlet tokenQR = qrGenerator.generateTokenQR(from: accessToken)\n\n// Display token QR for peer to scan\ndisplayQRCodeView.showQRCode(tokenQR)\n</code></pre>\n</li>\n</ol>\n<h3>Network Joining Workflow</h3>\n<ol>\n<li><p>Peer initiates joining process from Networks tab</p>\n</li>\n<li><p>Peer scans Network Metadata QR code:</p>\n<pre><code class=\"language-swift\">// Scan network metadata QR\nlet networkQRString = await qrScanner.scanQRCode().first(where: { _ in true })\n\n// Parse network metadata\nlet networkMetadata = try NetworkMetadata.fromQRString(networkQRString)\n\n// Verify the signature\nguard networkMetadata.verify() else {\n    throw NetworkError.invalidSignature\n}\n\n// Generate or select peer key\nlet peerKey = keyStore.getPeerKey() ?? keyStore.generatePeerKey()\nlet peerId = PeerId(publicKey: peerKey.publicKey)\n\n// Display peer ID as QR for admin to scan\nlet peerIdQR = qrGenerator.generatePeerIdQR(from: peerId)\ndisplayQRCodeView.showQRCode(peerIdQR)\n</code></pre>\n</li>\n<li><p>Peer displays PeerId QR for administrator to scan</p>\n</li>\n<li><p>Peer scans AccessToken QR provided by administrator:</p>\n<pre><code class=\"language-swift\">// Scan access token QR\nlet tokenQRString = await qrScanner.scanQRCode().first(where: { _ in true })\n\n// Parse access token\nlet accessToken = try AccessToken.fromQRString(tokenQRString)\n\n// Verify the token\nguard accessToken.peerId == peerId &amp;&amp; \n      accessToken.networkId == networkMetadata.networkId &amp;&amp;\n      accessToken.verify() else {\n    throw NetworkError.invalidToken\n}\n\n// Store the token and network metadata\nkeyStore.storeAccessToken(accessToken, for: networkMetadata.networkId)\nnetworkStore.addNetwork(networkMetadata)\n\n// Join the network\ntry await kagiNode.joinNetwork(\n    networkId: networkMetadata.networkId,\n    accessToken: accessToken\n)\n</code></pre>\n</li>\n</ol>\n<h3>Peer Connection Workflow</h3>\n<ol>\n<li><p>Peer A selects &quot;Connect to Peer&quot; from the Peers tab</p>\n</li>\n<li><p>Peer A obtains their public endpoint and generates a connection QR:</p>\n<pre><code class=\"language-swift\">// Get public endpoint via STUN\nlet publicEndpoint = try await natTraversal.getPublicEndpoint(\n    localPort: kagiNode.listeningPort,\n    stunServer: &quot;stun.example.com:3478&quot;\n)\n\n// Create connection QR data\nlet connectionData = PeerConnectionData(\n    peerId: kagiNode.peerId,\n    networkId: selectedNetwork.networkId,\n    address: publicEndpoint,\n    token: accessToken\n)\n\n// Generate and display QR\nlet connectionQR = qrGenerator.generateConnectionQR(from: connectionData)\ndisplayQRCodeView.showQRCode(connectionQR)\n</code></pre>\n</li>\n<li><p>Peer B scans the connection QR code:</p>\n<pre><code class=\"language-swift\">// Scan connection QR\nlet connectionQRString = await qrScanner.scanQRCode().first(where: { _ in true })\n\n// Parse connection data\nlet connectionData = try PeerConnectionData.fromQRString(connectionQRString)\n\n// Verify network and token\nguard connectionData.networkId == selectedNetwork.networkId &amp;&amp;\n      connectionData.token.verify() else {\n    throw ConnectionError.invalidData\n}\n\n// Perform hole punching\ntry await natTraversal.punchHole(\n    localPort: kagiNode.listeningPort,\n    peerAddress: connectionData.address\n)\n\n// Connect to the peer\nlet connection = try await kagiNode.connectToPeer(\n    peerId: connectionData.peerId,\n    networkId: connectionData.networkId,\n    address: connectionData.address\n)\n\n// Store connection for future use\npeerStore.addConnection(connection, for: connectionData.peerId)\n</code></pre>\n</li>\n</ol>\n<h3>DHT Interaction Workflow</h3>\n<ol>\n<li><p>User navigates to the Data tab</p>\n</li>\n<li><p>User stores a value in the DHT:</p>\n<pre><code class=\"language-swift\">// Create key and value\nlet key = &quot;user/profile/\\(UUID().uuidString)&quot;.data(using: .utf8)!\nlet value = try JSONEncoder().encode(userProfile)\n\n// Store in DHT\ntry await kagiNode.dhtPut(\n    networkId: selectedNetwork.networkId,\n    key: key,\n    value: value\n)\n</code></pre>\n</li>\n<li><p>User retrieves a value from the DHT:</p>\n<pre><code class=\"language-swift\">// Retrieve from DHT\nif let valueData = try await kagiNode.dhtGet(\n    networkId: selectedNetwork.networkId,\n    key: key\n) {\n    // Decode value\n    let retrievedProfile = try JSONDecoder().decode(UserProfile.self, from: valueData)\n    // Update UI\n    updateUIWithProfile(retrievedProfile)\n} else {\n    // Handle not found\n    showNotFoundMessage()\n}\n</code></pre>\n</li>\n</ol>\n<h2>Examples</h2>\n<p>This section will be expanded with practical examples.</p>\n",
    "path": "/development/mobile"
  },
  "development/macros": {
    "html": "<h1>Kagi Node Macros System</h1>\n<p>This document describes the macro system for the Kagi Node architecture. Macros are the <strong>recommended way</strong> to define services, actions, and event subscriptions in Kagi applications. They provide a declarative, concise approach that significantly reduces boilerplate code.</p>\n<h2>Table of Contents</h2>\n<ol>\n<li><a href=\"#introduction\">Introduction</a></li>\n<li><a href=\"#service-definition\">Service Definition</a><ul>\n<li><a href=\"#service-macro\"><code>#[service]</code> Macro</a></li>\n</ul>\n</li>\n<li><a href=\"#action-handlers\">Action Handlers</a><ul>\n<li><a href=\"#action-macro\"><code>#[action]</code> Macro</a></li>\n</ul>\n</li>\n<li><a href=\"#request-processing\">Request Processing</a><ul>\n<li><a href=\"#process-macro\"><code>#[process]</code> Macro</a></li>\n</ul>\n</li>\n<li><a href=\"#event-system\">Event System</a><ul>\n<li><a href=\"#subscribe-macro\"><code>#[subscribe]</code> Macro</a></li>\n<li><a href=\"#publish-macro\"><code>#[publish]</code> Macro</a></li>\n</ul>\n</li>\n<li><a href=\"#testing-with-macros\">Testing with Macros</a></li>\n<li><a href=\"#complete-example\">Complete Example</a></li>\n<li><a href=\"#future-features\">Future Features</a></li>\n</ol>\n<h2>Introduction</h2>\n<p>The Kagi Node macro system is the <strong>recommended approach</strong> for building Kagi services. It provides a declarative way to define services, actions, and event subscriptions. The macros significantly reduce boilerplate code while preserving the architectural principles of the Kagi Node system. The macros internally use the existing API, making them fully compatible with manual implementations.</p>\n<h3>Implementation Approaches</h3>\n<p>The Kagi macro system supports two implementation approaches:</p>\n<ol>\n<li><p><strong>Distributed Slices (Compile-time)</strong>: Using the <code>linkme</code> crate to register handlers, actions, and subscriptions at compile time. This approach is more efficient but requires the unstable <code>#[used(linker)]</code> attribute.</p>\n</li>\n<li><p><strong>Runtime Registration (Default)</strong>: A fallback mechanism that registers handlers, actions, and subscriptions at runtime. This approach is used when the <code>distributed_slice</code> feature is not enabled, making it compatible with stable Rust and testing environments.</p>\n</li>\n</ol>\n<blockquote>\n<p><strong>Note</strong>: Both approaches provide the same functionality and API. The runtime registration approach is used automatically when the <code>distributed_slice</code> feature is not enabled, ensuring compatibility across different environments.</p>\n</blockquote>\n<h2>Service Definition</h2>\n<h3><code>#[service]</code> Macro</h3>\n<p>The <code>#[service]</code> macro is used to define a service by decorating a struct. It automatically implements the <code>AbstractService</code> trait and its required methods.</p>\n<pre><code class=\"language-rust\">use kagi_node::prelude::*;\nuse kagi_macros::service;\n\n#[service(\n    name = &quot;data_service&quot;,\n    path = &quot;data&quot;, \n    description = &quot;A service for managing data&quot;,\n    version = &quot;1.0.0&quot;\n)]\nstruct DataService {\n    // Service fields\n    records: HashMap&lt;String, DataRecord&gt;,\n    // Other fields...\n}\n\n// Service implementation (constructor and helper methods)\nimpl DataService {\n    fn new() -&gt; Self {\n        Self {\n            records: HashMap::new(),\n            // Initialize other fields...\n        }\n    }\n    \n    // Helper methods go here...\n}\n</code></pre>\n<h4>Features</h4>\n<p>The <code>#[service]</code> macro:</p>\n<ul>\n<li>Automatically implements the <code>AbstractService</code> trait</li>\n<li>Generates <code>name()</code>, <code>path()</code>, <code>description()</code>, and <code>version()</code> methods</li>\n<li>Creates empty default implementations for <code>init()</code>, <code>start()</code>, and <code>stop()</code></li>\n<li>Works with the <code>process_request</code> method to handle service requests</li>\n</ul>\n<h4>Parameters</h4>\n<ul>\n<li><code>name</code>: The name of the service (required)</li>\n<li><code>path</code>: Custom path for the service (optional, defaults to the same value as <code>name</code>)</li>\n<li><code>description</code>: A description of the service (optional, defaults to &quot;{struct_name} service&quot;)</li>\n<li><code>version</code>: The version of the service (optional, defaults to &quot;1.0.0&quot;)</li>\n</ul>\n<h2>Action Handlers</h2>\n<h3><code>#[action]</code> Macro</h3>\n<p>The <code>#[action]</code> macro decorates methods to define them as action handlers that can be called through the service&#39;s request processing system.</p>\n<pre><code class=\"language-rust\">use kagi_macros::action;\nuse anyhow::Result;\nuse kagi_node::services::ServiceResponse;\n\nimpl DataService {\n    #[action]\n    async fn create_record(&amp;self, name: String, value: String) -&gt; Result&lt;ServiceResponse&gt; {\n        // Implementation to create a record\n        let record = DataRecord::new(&amp;name, &amp;value);\n        \n        // Store the record\n        self.records.insert(record.id.clone(), record.clone());\n        \n        // Return success response\n        Ok(ServiceResponse::success(\n            format!(&quot;Record created with ID: {}&quot;, record.id),\n            Some(ValueType::String(record.id.clone()))\n        ))\n    }\n}\n</code></pre>\n<p>The <code>#[action]</code> macro marks methods that handle specific service operations. These methods typically:</p>\n<ul>\n<li>Are asynchronous</li>\n<li>Return a <code>Result&lt;ServiceResponse&gt;</code></li>\n<li>Contain the business logic for a specific operation</li>\n</ul>\n<h4>Example: Action with Context to Publish Events</h4>\n<p>You can also define actions that receive the request context as a parameter, allowing them to trigger events directly:</p>\n<pre><code class=\"language-rust\">impl DataService {\n    #[action(name = &quot;update_record&quot;)]\n    async fn update_record(&amp;self, context: &amp;RequestContext, id: String, value: String) -&gt; Result&lt;ServiceResponse&gt; {\n        // Implementation to update a record\n        let mut records = self.records.lock().unwrap();\n        \n        if let Some(record) = records.get_mut(&amp;id) {\n            // Update the record\n            record.value = value.clone();\n            record.updated_at = Utc::now().to_rfc3339();\n            \n            // Publish an event using the context\n            let event_data = json!({\n                &quot;id&quot;: id,\n                &quot;value&quot;: value,\n                &quot;updated_at&quot;: record.updated_at\n            });\n            \n            // Publish to the &quot;data/updated&quot; topic\n            context.publish(&quot;data/updated&quot;, event_data).await?;\n            \n            // Return success response\n            Ok(ServiceResponse::success(\n                format!(&quot;Record with ID {} updated&quot;, id),\n                Some(ValueType::String(id))\n            ))\n        } else {\n            // Record not found\n            Ok(ServiceResponse::error(\n                format!(&quot;Record with ID {} not found&quot;, id),\n                None\n            ))\n        }\n    }\n}\n</code></pre>\n<p>In this example:</p>\n<ul>\n<li>The action receives a <code>context</code> parameter that provides access to the node&#39;s capabilities</li>\n<li>It uses <code>context.publish()</code> to fire an event when a record is updated</li>\n<li>Other services can subscribe to the &quot;data/updated&quot; topic to react to these changes</li>\n</ul>\n<blockquote>\n<p><strong>Note</strong>: Even if you don&#39;t define your own <code>process_request</code> method with the <code>#[process]</code> macro, the service macro automatically generates one that properly passes the context to your action methods. This means you can use actions with context parameters without needing to write your own process method.</p>\n</blockquote>\n<h2>Request Processing</h2>\n<h3><code>#[process]</code> Macro</h3>\n<p>The <code>#[process]</code> macro is used to override the default request processing method that&#39;s automatically generated by the service macro. It handles ALL operations for a service and delegates to appropriate action handlers based on the operation requested.</p>\n<pre><code class=\"language-rust\">use kagi_macros::process;\nuse anyhow::Result;\nuse kagi_node::services::{RequestContext, ServiceResponse, ValueType};\n\nimpl DataService {\n    #[process]\n    async fn process_request(&amp;self, context: &amp;RequestContext, operation: &amp;str, params: &amp;ValueType) -&gt; Result&lt;ServiceResponse&gt; {\n        match operation {\n            &quot;create_record&quot; =&gt; {\n                let name = params[&quot;name&quot;].as_str().unwrap_or_default().to_string();\n                let value = params[&quot;value&quot;].as_str().unwrap_or_default().to_string();\n                self.create_record(name, value).await\n            },\n            &quot;get_record&quot; =&gt; {\n                let id = params[&quot;id&quot;].as_str().unwrap_or_default().to_string();\n                self.get_record(id).await\n            },\n            // More operations...\n            _ =&gt; Ok(ServiceResponse::error(format!(&quot;Unknown operation: {}&quot;, operation), None)),\n        }\n    }\n}\n</code></pre>\n<h4>Important Notes About the <code>#[process]</code> Macro</h4>\n<ul>\n<li>The <code>#[process]</code> macro is applied to EXACTLY ONE method per service: <code>process_request</code></li>\n<li>It handles ALL operations for the service, not just specific ones</li>\n<li>Unlike <code>#[action]</code>, <code>#[subscribe]</code>, etc., it DOES NOT accept any parameters like <code>#[process(name = &quot;xyz&quot;)]</code></li>\n<li>Using a name parameter would be incorrect as the process method must handle all operations</li>\n<li>If you only need to handle a specific operation, use <code>#[action(name = &quot;operation&quot;)]</code> instead</li>\n<li>The process macro is only needed if you want to override the default processing logic generated by the service macro</li>\n</ul>\n<p>The <code>#[process]</code> macro is essential for service operation as it:</p>\n<ul>\n<li>Provides the entry point for ALL service requests</li>\n<li>Handles parameter extraction and routing to action methods</li>\n<li>Manages error handling for unknown operations</li>\n<li>Does NOT accept a name parameter like <code>#[process(name = &quot;xyz&quot;)]</code> since it must handle all operations</li>\n</ul>\n<blockquote>\n<p><strong>Warning</strong>: Never use <code>#[process(name = &quot;operation&quot;)]</code>. This is incorrect usage. If you need to handle a specific operation, use <code>#[action(name = &quot;operation&quot;)]</code> instead.</p>\n</blockquote>\n<h2>Event System</h2>\n<h3><code>#[subscribe]</code> Macro</h3>\n<p>The <code>#[subscribe]</code> macro defines event subscriptions that allow services to react to events from specified topics.</p>\n<pre><code class=\"language-rust\">use kagi_macros::subscribe;\nuse anyhow::Result;\nuse kagi_node::services::{RequestContext, ValueType};\n\nimpl DataService {\n    #[subscribe(&quot;data/created&quot;)]\n    async fn handle_data_created(&amp;mut self, context: &amp;RequestContext, payload: ValueType) -&gt; Result&lt;()&gt; {\n        if let ValueType::Json(data) = payload {\n            // Process the created data event\n            println!(&quot;Data created event received: {:?}&quot;, data);\n            // Potentially update service state...\n        }\n        Ok(())\n    }\n}\n</code></pre>\n<p>The <code>#[subscribe]</code> macro:</p>\n<ul>\n<li>Automatically registers a subscription for the specified topic</li>\n<li>Sets up event handlers that are called when events are published to that topic</li>\n<li>Supports mutable self references to update service state based on events</li>\n<li>Works with both distributed slices and runtime registration approaches</li>\n</ul>\n<h3><code>#[publish]</code> Macro</h3>\n<p>The <code>#[publish]</code> macro simplifies publishing events to a specific topic.</p>\n<pre><code class=\"language-rust\">use kagi_macros::publish;\n\n// Define a function that publishes events\n#[publish(&quot;data/created&quot;)]\nasync fn publish_data_created(data: DataRecord) -&gt; Result&lt;()&gt; {\n    // Prepare event payload\n    let payload = json!({\n        &quot;id&quot;: data.id,\n        &quot;name&quot;: data.name,\n        &quot;value&quot;: data.value,\n        &quot;created_at&quot;: data.created_at\n    });\n    \n    // The publish macro automatically converts this into a publish call\n    // and returns the Result from the publish operation\n    Ok(())\n}\n</code></pre>\n<blockquote>\n<p><strong>Note</strong>: The <code>#[publish]</code> macro is a convenience wrapper around the <code>context.publish()</code> method. It automatically creates the necessary code to publish an event to the specified topic.</p>\n</blockquote>\n<h2>Testing with Macros</h2>\n<p>The runtime registration approach makes testing services with macros straightforward without requiring unstable Rust features. You can write tests for your macro-based services the same way you write other tests:</p>\n<pre><code class=\"language-rust\">#[cfg(test)]\nmod tests {\n    use super::*;\n    use kagi_node::test_utils::TestNode;\n\n    #[tokio::test]\n    async fn test_create_record() {\n        // Create a test node with the service\n        let mut node = TestNode::new();\n        let service = DataService::new();\n        \n        // Register the service with the node\n        node.register_service(service).await.unwrap();\n        \n        // Test creating a record\n        let response = node.request(\n            &quot;data_service/create_record&quot;, \n            json!({\n                &quot;name&quot;: &quot;Test Record&quot;,\n                &quot;value&quot;: &quot;Test Value&quot;\n            })\n        ).await.unwrap();\n        \n        // Assert the response is successful\n        assert_eq!(response.status, ResponseStatus::Success);\n        assert!(response.data.is_some());\n    }\n}\n</code></pre>\n<p>The macros use runtime registration in test environments automatically, so you don&#39;t need to do anything special to test services defined with macros.</p>\n<h2>Complete Example</h2>\n<p>Here&#39;s a complete example of a service defined using the macro system:</p>\n<pre><code class=\"language-rust\">use kagi_node::prelude::*;\nuse kagi_macros::{service, action, process, subscribe};\nuse anyhow::Result;\nuse std::collections::HashMap;\nuse chrono::Utc;\nuse serde::{Serialize, Deserialize};\n\n// Define a record type\n#[derive(Clone, Debug, Serialize, Deserialize)]\nstruct DataRecord {\n    id: String,\n    name: String,\n    value: String,\n    created_at: String,\n    updated_at: String,\n}\n\nimpl DataRecord {\n    fn new(name: &amp;str, value: &amp;str) -&gt; Self {\n        let id = uuid::Uuid::new_v4().to_string();\n        let now = Utc::now().to_rfc3339();\n        Self {\n            id,\n            name: name.to_string(),\n            value: value.to_string(),\n            created_at: now.clone(),\n            updated_at: now,\n        }\n    }\n}\n\n// Define the service using the service macro\n#[service(\n    name = &quot;data_service&quot;,\n    path = &quot;data&quot;,\n    description = &quot;A service for managing data records&quot;,\n    version = &quot;1.0.0&quot;\n)]\nstruct DataService {\n    records: std::sync::Mutex&lt;HashMap&lt;String, DataRecord&gt;&gt;,\n}\n\nimpl DataService {\n    // Constructor\n    fn new() -&gt; Self {\n        Self {\n            records: std::sync::Mutex::new(HashMap::new()),\n        }\n    }\n    \n    // Create a record\n    #[action]\n    async fn create_record(&amp;self, context: &amp;RequestContext, name: String, value: String) -&gt; Result&lt;ServiceResponse&gt; {\n        let record = DataRecord::new(&amp;name, &amp;value);\n        let record_id = record.id.clone();\n        \n        // Store the record\n        {\n            let mut records = self.records.lock().unwrap();\n            records.insert(record_id.clone(), record.clone());\n        }\n        \n        // Publish an event\n        context.publish(&quot;data/created&quot;, json!(record)).await?;\n        \n        // Return success response\n        Ok(ServiceResponse::success(\n            format!(&quot;Record created with ID: {}&quot;, record_id),\n            Some(ValueType::String(record_id))\n        ))\n    }\n    \n    // Get a record\n    #[action]\n    async fn get_record(&amp;self, id: String) -&gt; Result&lt;ServiceResponse&gt; {\n        let records = self.records.lock().unwrap();\n        \n        if let Some(record) = records.get(&amp;id) {\n            Ok(ServiceResponse::success(\n                format!(&quot;Record retrieved: {}&quot;, id),\n                Some(ValueType::Json(serde_json::to_value(record)?))\n            ))\n        } else {\n            Ok(ServiceResponse::error(\n                format!(&quot;Record not found: {}&quot;, id),\n                None\n            ))\n        }\n    }\n    \n    // Update a record\n    #[action]\n    async fn update_record(&amp;self, context: &amp;RequestContext, id: String, value: String) -&gt; Result&lt;ServiceResponse&gt; {\n        let mut records = self.records.lock().unwrap();\n        \n        if let Some(record) = records.get_mut(&amp;id) {\n            // Update the record\n            record.value = value.clone();\n            record.updated_at = Utc::now().to_rfc3339();\n            \n            // Publish an event\n            context.publish(&quot;data/updated&quot;, json!(record)).await?;\n            \n            Ok(ServiceResponse::success(\n                format!(&quot;Record updated: {}&quot;, id),\n                Some(ValueType::String(id))\n            ))\n        } else {\n            Ok(ServiceResponse::error(\n                format!(&quot;Record not found: {}&quot;, id),\n                None\n            ))\n        }\n    }\n    \n    // Delete a record\n    #[action]\n    async fn delete_record(&amp;self, context: &amp;RequestContext, id: String) -&gt; Result&lt;ServiceResponse&gt; {\n        let mut records = self.records.lock().unwrap();\n        \n        if records.remove(&amp;id).is_some() {\n            // Publish an event\n            context.publish(&quot;data/deleted&quot;, json!({ &quot;id&quot;: id })).await?;\n            \n            Ok(ServiceResponse::success(\n                format!(&quot;Record deleted: {}&quot;, id),\n                None\n            ))\n        } else {\n            Ok(ServiceResponse::error(\n                format!(&quot;Record not found: {}&quot;, id),\n                None\n            ))\n        }\n    }\n    \n    // List all records\n    #[action]\n    async fn list_records(&amp;self) -&gt; Result&lt;ServiceResponse&gt; {\n        let records = self.records.lock().unwrap();\n        let records_vec: Vec&lt;&amp;DataRecord&gt; = records.values().collect();\n        \n        Ok(ServiceResponse::success(\n            format!(&quot;Records retrieved: {}&quot;, records_vec.len()),\n            Some(ValueType::Json(serde_json::to_value(&amp;records_vec)?))\n        ))\n    }\n    \n    // Handle data updated events\n    #[subscribe(&quot;data/updated&quot;)]\n    async fn handle_data_updated(&amp;self, context: &amp;RequestContext, payload: ValueType) -&gt; Result&lt;()&gt; {\n        println!(&quot;Data updated event received: {:?}&quot;, payload);\n        Ok(())\n    }\n    \n    // Process override for custom parameter handling (optional)\n    #[process]\n    async fn process_request(&amp;self, context: &amp;RequestContext, operation: &amp;str, params: &amp;ValueType) -&gt; Result&lt;ServiceResponse&gt; {\n        match operation {\n            &quot;create_record&quot; =&gt; {\n                let name = params[&quot;name&quot;].as_str().unwrap_or_default().to_string();\n                let value = params[&quot;value&quot;].as_str().unwrap_or_default().to_string();\n                self.create_record(context, name, value).await\n            },\n            &quot;get_record&quot; =&gt; {\n                let id = params[&quot;id&quot;].as_str().unwrap_or_default().to_string();\n                self.get_record(id).await\n            },\n            &quot;update_record&quot; =&gt; {\n                let id = params[&quot;id&quot;].as_str().unwrap_or_default().to_string();\n                let value = params[&quot;value&quot;].as_str().unwrap_or_default().to_string();\n                self.update_record(context, id, value).await\n            },\n            &quot;delete_record&quot; =&gt; {\n                let id = params[&quot;id&quot;].as_str().unwrap_or_default().to_string();\n                self.delete_record(context, id).await\n            },\n            &quot;list_records&quot; =&gt; self.list_records().await,\n            _ =&gt; Ok(ServiceResponse::error(format!(&quot;Unknown operation: {}&quot;, operation), None)),\n        }\n    }\n}\n\n// Main function to create and run a node with our service\nasync fn main() -&gt; Result&lt;()&gt; {\n    // Create a node configuration\n    let config = NodeConfig::default();\n    \n    // Create a node\n    let mut node = Node::new(config).await?;\n    \n    // Create and register our service\n    let data_service = DataService::new();\n    node.register_service(data_service).await?;\n    \n    // Start the node\n    node.start().await?;\n    \n    // Wait for shutdown signal\n    node.wait_for_shutdown().await;\n    \n    Ok(())\n}\n</code></pre>\n<p>This example demonstrates:</p>\n<ol>\n<li>A complete service with CRUD operations</li>\n<li>Action methods for each operation</li>\n<li>Event publication and subscription</li>\n<li>A custom process method for parameter handling</li>\n<li>Integration with a node instance</li>\n</ol>\n<p>All of this is accomplished with minimal boilerplate code, thanks to the macro system.</p>\n<h2>Future Features</h2>\n<p>Future enhancements to the macro system will include:</p>\n<ol>\n<li>More attribute options for actions (validation, authorization, caching)</li>\n<li>Integration with metrics collection</li>\n<li>Automatic documentation generation</li>\n<li>More sophisticated event handling capabilities</li>\n<li>Built-in parameter validation and conversion</li>\n</ol>\n<p>Stay tuned for updates to the macro system as Kagi continues to evolve. </p>\n",
    "path": "/development/macros"
  }
}